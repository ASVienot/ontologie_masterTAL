{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création des dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ce notebook permet la création des dataframes utilsées pour la création des triplets de l'ontologie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from unidecode import unidecode\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Importer les réponses du formulaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Horodateur', 'Score', 'Nom de famille', 'Prénom', 'Genre',\n",
       "       'Date de naissance', 'Nationalité',\n",
       "       'Avez-vous redoublé le master ? Si oui, indiquez quelle année et quel niveau. ',\n",
       "       'Dans quelle université étiez-vous inscrits au M1 ? ',\n",
       "       'Dans quel parcours êtes-vous inscrits au M2 ?',\n",
       "       'Disposez vous ou avez-vous disposé d'un aménagement handicap pour le master (tiers-temps, autres...) ?',\n",
       "       'Si vous êtes inscrits (ou avez été inscrits) dans un autre établissement pendant le master, indiquez lequel :\\n\\nExemple :\\nÉtudiant en M2 TAL Ingénierie Multilingue et à 42 en même temps.',\n",
       "       'Si vous avez obtenu un baccalauréat français, quelle était votre filière : ',\n",
       "       'Indiquez si cette licence appartient à l'une des mentions suivantes :',\n",
       "       'Avez-vous déjà un master ?\\nSi oui, veuillez indiquer son nom original (langue d'origine) au format :\\nNOM, UNIVERSITÉ\\n\\nExemple:\\nMaster Linguistique Anglaise, Université Sorbonne Nouvelle',\n",
       "       'Si vous travaillez (ou avez travaillé) pendant le master, indiquez sur quel poste (hors stage TAL) :\\n\\nExemple :\\nActuellement employé polyvalent à Décathlon.',\n",
       "       'Si vous avez exercé une activité professionnelle de longue durée avant le master (reconversion, reprise d'études ou autres), indiquez laquelle :\\n\\nExemple:\\nProfesseure à l'alliance française de Bogotá. ',\n",
       "       'Avez-vous eu un premier stage en NLP pendant le M1 ?',\n",
       "       'Si oui, étiez-vous en entreprise, laboratoire, ou autre ?',\n",
       "       'Quel était le nom de l'organisme d'accueil ? ',\n",
       "       'Quelle était la durée du stage ?', 'Quel était le sujet du stage ?',\n",
       "       'Si votre tuteur de stage était un enseignant du master, indiquez lequel :',\n",
       "       'Avez-vous eu un second stage en NLP pendant le M1 ?',\n",
       "       'Si oui, étiez-vous en entreprise, laboratoire, ou autre ?.1',\n",
       "       'Quel était le nom de l'organisme d'accueil ? .1',\n",
       "       'Quelle était la durée du stage ?.1',\n",
       "       'Quel était le sujet du stage ?.1',\n",
       "       'Si votre tuteur de stage était un enseignant du master, indiquez lequel :.1',\n",
       "       'Avez-vous eu un stage en NLP pendant le M2 (hors celui du second semestre à venir) ?',\n",
       "       'Si oui, étiez-vous en entreprise, laboratoire, ou autre ?.2',\n",
       "       'Quel était le nom de l'organisme d'accueil ? .2',\n",
       "       'Quelle était la durée du stage ?.2',\n",
       "       'Quel était le sujet du stage ?.2',\n",
       "       'Si votre tuteur de stage était un enseignant du master, indiquez lequel :.2',\n",
       "       'Si vous deviez noter votre expérience globale de stagiaire, quelle notre mettriez vous ? \\nStage M1 numéro 1',\n",
       "       'Si vous deviez noter votre expérience globale de stagiaire, quelle notre mettriez vous ? \\nStage M1 numéro 2',\n",
       "       'Si vous deviez noter votre expérience globale de stagiaire, quelle notre mettriez vous ? \\nStage M2',\n",
       "       'Pour les M2 en parcours recherche, IM ou TETRADOM, avez-vous déjà trouvé un stage ?',\n",
       "       'Si oui, serez-vous en entreprise, laboratoire ou autre ?',\n",
       "       'Quel est le nom de l'organisme d'accueil ?',\n",
       "       'Quelle sera la durée du stage ?',\n",
       "       'Pour les M2 en parcours recherche, le sujet de votre mémoire est-il lié à votre stage de M2 ?',\n",
       "       'Pour les M2 en parcours recherche, si vous le connaissez déjà, quel est le sujet de votre mémoire ?',\n",
       "       'Pour les M2 en parcours recherche, si vous les connaissez déjà, qui sont vos directeurs de mémoire ? ',\n",
       "       'Pour les M2 en parcours alternance, avez-vous trouvé une alternance, un stage, ou autre ?',\n",
       "       'Pour les M2 en parcours alternance ayant trouvé une alternance, dans quel organisme êtes-vous ?',\n",
       "       'Quelle sont vos missions ?',\n",
       "       'Pour les M2 en parcours alternance ayant trouvé un stage, dans quel organisme êtes-vous/serez-vous ?',\n",
       "       'Quelle est/sera la durée du stage ?',\n",
       "       'Quelles sont/seront vos missions ?',\n",
       "       'Quels cours avez-vous suivis au premier semestre du M1 ?',\n",
       "       'Quelles ont été vos options de linguistique au premier semestre du M1 ?\\nSéparer les cours par des virgules. ',\n",
       "       'Avons-nous oublié quelque cours au premier semestre du M1 ? Indiquez-le ici !\\nSéparez les cours par des virgules. ',\n",
       "       'Quels cours avez-vous suivis au second semestre du M1 ?',\n",
       "       'Avons-nous oublié quelque cours au second semestre du M1 ? Indiquez-le ici !\\nSéparez les cours par des virgules. ',\n",
       "       'Quels cours avez-vous suivis au premier semestre du M2 ?',\n",
       "       'Avons-nous oublié quelque cours au premier semestre du M2 ? Indiquez-le ici !\\nSéparez les cours par des virgules. ',\n",
       "       'Quels sont vos sujets préférés en cours ? ',\n",
       "       'Quelle(s) modalité(s) d'évaluation préférez-vous ?',\n",
       "       'Quel aspect aimeriez-vous voir plus mis en avant pendant le master ? Ça peut être un sujet en particulier, des compétences spécifiques ou autre.',\n",
       "       'Qui est votre ennemi juré dans le master parmi les élèves (soyez pas sérieux c'est pour rigoler) ? ',\n",
       "       'Sur combien notez-vous votre santé mentale avant le master ?',\n",
       "       'Sur combien notez-vous votre santé mentale après le master ? ',\n",
       "       'À quelle fréquence pleurez-vous à cause du master ?\\nex: x/mois ou x/semaine ou x/jour ...',\n",
       "       'Combien d'heures par nuit dormez-vous en moyenne ?',\n",
       "       'Sur combien notez-vous la difficulté du M1 ?',\n",
       "       'Sur combien notez-vous la difficulté du M2 parcours Recherche et Développement ?',\n",
       "       'Sur combien notez-vous la difficulté du M2 parcours Alternance ?',\n",
       "       'Sur combien notez-vous la difficulté du M2 parcours Ingénierie Multilingue ?',\n",
       "       'Sur combien notez-vous la difficulté du M2 parcours Technologies de la Traduction et Traitement des Données Multilingues ?',\n",
       "       'Pour les adeptes de Linux, voulez-vous régulièrement jeter votre ordinateur par la fenêtre ?',\n",
       "       'Pour les adeptes de Mac, voulez-vous régulièrement jeter votre ordinateur par la fenêtre ?',\n",
       "       'Si vous deviez élire le meilleur cours de tout le master, lequel choisiriez-vous ? ',\n",
       "       'Pour les étudiants de Nanterre, sur combien notez-vous l'efficacité de votre administration ?',\n",
       "       'Pour les étudiants de la Sorbonne-Nouvelle, sur combien notez-vous l'efficacité de votre administration ?',\n",
       "       'Pour les étudiants de l'INALCO, sur combien notez-vous l'efficacité de votre administration ?',\n",
       "       'Quel conseil donneriez-vous aux futurs élèves pour survivre au master TAL ?',\n",
       "       'À qui recommanderiez-vous le master TAL ?',\n",
       "       'Quel conseil donneriez-vous aux professeurs du master TAL ? ',\n",
       "       'Avez-vous eu une expérience professionnelle en lien avec le master pendant le M1 ou le M2 ? (hors alternance et stage)',\n",
       "       'Quel était le nom de l'organisme employeur ?',\n",
       "       'Quel était le type de contrat ? ', 'Quelles étaient vos missions ?',\n",
       "       'Si vous avez répondu à la question précédente et que votre diplôme est étranger, veuillez indiquer sous le même format un nom équivalent en français.\\n\\nExemple :\\nSi vous avez répondu Master in social studies, Cambridge University à la question précédente.\\n\\nVeuillez ici répondre :\\nMaster en Sciences Sociales, Université de Cambridge',\n",
       "       'Indiquez si ce master appartient à une des mentions suivantes : ',\n",
       "       'Si vous avez obtenu un autre type de diplôme (hors licence et master), indiquez son nom original (langue d'origine) au format :\\nNOM, ÉTABLISSEMENT\\n\\nExemple:\\nBTS en communication, Lycée Paul Eluard, Saint-Denis',\n",
       "       'Avez-vous déjà une licence ?\\nSi oui, veuillez indiquer son nom original (langue d'origine) au format :\\nNOM, UNIVERSITÉ\\n\\nExemple:\\nLicence en biologie, Université Paris Saclay',\n",
       "       'Si vous avez répondu à la question précédente et que votre diplôme est étranger, veuillez indiquer sous le même format un nom équivalent en français.\\n\\nExemple :\\nSi vous avez répondu Bachelor in social studies, Cambridge University à la question précédente.\\n\\nVeuillez ici répondre :\\nLicence en Sciences Sociales, Université de Cambridge',\n",
       "       'Si vous avez répondu à la question précédente et que votre diplôme est étranger, veuillez indiquer sous le même format un nom équivalent en français.\\n\\nExemple :\\nSi vous avez répondu NVQ hairstylist, Freddie Mercury High School, Cambridge à la question précédente.\\n\\nVeuillez ici répondre :\\nCAP coiffure, Lycée Freddie Mercury, Cambridge',\n",
       "       'Colonne 84'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_formulaire = pd.read_csv(\"formulaire.csv\")\n",
    "df_formulaire.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Création de la dataframe prof\n",
    "- id_prof\n",
    "- nom_prof\n",
    "- prenom_prof\n",
    "- genre\n",
    "- cours\n",
    "- directeur_de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Yoann_DUPONT#\n",
      "#Delphine_BATTISTELLI#\n",
      "#Iris_ESHKOL-TARAVELLA#\n",
      "#Loïc_GROBOL#\n",
      "#Sylvain_KAHANE#\n",
      "#Pierre_MAGISTRY#\n",
      "#Damien_NOUVEL#\n",
      "#Ilaine_WANG#\n",
      "#Cedric_GENDROT#\n",
      "#Santiago_HERRERA#\n",
      "#Xibin_WANG#\n",
      "#Caroline_BOGLIOTTI#\n",
      "#Florence_VILLEOING#\n",
      "#Armand_STRICKER#\n",
      "#Mathieu_DEHOUCK#\n",
      "#Michel_JACOBSON#\n",
      "#Eve_SAUVAGE#\n",
      "#Pierre_ZWEIGENBAUM#\n",
      "#Loulou_KOSMALA#\n",
      "#Mathieu_VALETTE#\n",
      "#Kata_GABOR#\n",
      "#Zhu_LICHAO#\n",
      "#Florent_JACQUEMARD#\n",
      "#Alexandre_ROULOIS#\n",
      "#Chloé_MONNIN-TUILLIER#\n",
      "#Pascal_AMSILI#\n",
      "#Louis_JOURDAIN#\n",
      "#Ons_AOUINA#\n",
      "#Louis_LECAILLIEZ#\n",
      "#Hatice_AKSEN#\n",
      "#Sophie_GAUMET#\n",
      "#Cyril_GROUIN#\n",
      "#Karolina_KUBIK#\n",
      "#Marie-Paule_BONNAFOUS#\n",
      "#Rim_ABROUGUI#\n",
      "#Patrick_PAROUBECK#\n",
      "#Sophie_RAINERIE#\n",
      "#Nasredine_SEMMAR#\n",
      "#Natalia_LASON#\n",
      "#Suppya_NUT#\n",
      "#Benoît_CARCENAC#\n",
      "#Kyung_LEE#\n",
      "#Christophe_HUP#\n",
      "#James_COSTA#\n",
      "#Marcel_CORI#\n",
      "#Sabine_LEHMANN#\n",
      "#Vanessa_PICCOLI#\n"
     ]
    }
   ],
   "source": [
    "dico_prof = {\"id_prof\" : [], \n",
    "             \"nom_prof\": [\n",
    "    \"DUPONT\",\n",
    "    \"BATTISTELLI\",\n",
    "    \"ESHKOL-TARAVELLA\", \n",
    "    \"GROBOL\",\n",
    "    \"KAHANE\", \n",
    "    \"MAGISTRY\", \n",
    "    \"NOUVEL\", \n",
    "    \"WANG\", \n",
    "    \"GENDROT\", \n",
    "    \"HERRERA\", \n",
    "    \"WANG\", \n",
    "    \"BOGLIOTTI\", \n",
    "    \"VILLEOING\", \n",
    "    \"STRICKER\", \n",
    "    \"DEHOUCK\", \n",
    "    \"JACOBSON\", \n",
    "    \"SAUVAGE\", \n",
    "    \"ZWEIGENBAUM\", \n",
    "    \"KOSMALA\" , \n",
    "    \"VALETTE\", \n",
    "    \"GABOR\", \n",
    "    \"LICHAO\", \n",
    "    \"JACQUEMARD\",\n",
    "    \"ROULOIS\",\n",
    "    \"MONNIN-TUILLIER\",\n",
    "    \"AMSILI\",\n",
    "    \"JOURDAIN\", \n",
    "    \"AOUINA\", \n",
    "    \"LECAILLIEZ\",\n",
    "    \"AKSEN\", \n",
    "    \"GAUMET\", \n",
    "    \"GROUIN\", \n",
    "    \"KUBIK\",\n",
    "    \"BONNAFOUS\", \n",
    "    \"ABROUGUI\", \n",
    "    \"PAROUBECK\",\n",
    "    \"RAINERIE\", \n",
    "    \"SEMMAR\",\n",
    "    \"LASON\",\n",
    "    \"NUT\",\n",
    "    \"CARCENAC\",\n",
    "    \"LEE\",\n",
    "    \"HUP\",\n",
    "    \"COSTA\",\n",
    "    \"CORI\",\n",
    "    \"LEHMANN\",\n",
    "    \"PICCOLI\"\n",
    "    ],\n",
    "        \"prenom_prof\": [\"Yoann\", \"Delphine\", \"Iris\", \"Loïc\", \"Sylvain\", \"Pierre\", \"Damien\", \"Ilaine\", \"Cedric\", \"Santiago\", \"Xibin\", \"Caroline\", \"Florence\", \"Armand\", \"Mathieu\", \"Michel\", \"Eve\", \"Pierre\", \"Loulou\", \"Mathieu\", \"Kata\", \"Zhu\",\"Florent\", \"Alexandre\", \"Chloé\", \"Pascal\", \"Louis\", \"Ons\",\"Louis\", \"Hatice\", \"Sophie\", \"Cyril\", \"Karolina\", \"Marie-Paule\", \"Rim\", \"Patrick\", \"Sophie\", \"Nasredine\", \"Natalia\", \"Suppya\", \"Benoît\", \"Kyung\", \"Christophe\", \"James\", \"Marcel\", \"Sabine\", \"Vanessa\"],\n",
    "        \"etablissement\": [\"SorbonneNouvelle\", \"Nanterre\", \"Nanterre\", \"Nanterre\", \"Nanterre\", \"Inalco\", \"Inalco\", \"Inalco\", \"SorbonneNouvelle\", \"Nanterre\", \"Nanterre\", \"Nanterre\", \"Nanterre\", \"Inalco\", \"SorbonneNouvelle\", \"SorbonneNouvelle\", \"Inalco\", \"Inalco\", \"Nanterre\", \"Inalco\", \"Inalco\", \"Inalco\",\"Inalco\", \"Inalco\", \"Inalco\", \"SorbonneNouvelle\", \"Inalco\", \"Inalco\", \"Inalco\", \"Nanterre\", \"Inalco\", \"Inalco\", \"Inalco\", \"Inalco\", \"Inalco\", \"Inalco\", \"Nanterre\", \"Inalco\", \"Inalco\", \"Inalco\", \"Nanterre\", \"Inalco\", \"Nanterre\", \"SorbonneNouvelle\", \"Nanterre\", \"Nanterre\", \"Nanterre\"],\n",
    "\t\t\"genre\" : [\n",
    "      \"Homme\",\n",
    "      \"Femme\",\n",
    "      \"Femme\",\n",
    "      \"Autre\", \n",
    "      \"Homme\", \n",
    "      \"Homme\", \n",
    "      \"Homme\", \n",
    "      \"Femme\", \n",
    "      \"Homme\", \n",
    "      \"Homme\", \n",
    "      \"Homme\",\n",
    "      \"Femme\", \n",
    "      \"Femme\", \n",
    "      \"Homme\", \n",
    "      \"Homme\", \n",
    "      \"Homme\", \n",
    "      \"Femme\", \n",
    "      \"Homme\", \n",
    "      \"Femme\", \n",
    "      \"Homme\", \n",
    "      \"Femme\", \n",
    "      \"Homme\",\n",
    "      \"Homme\",\n",
    "      \"Homme\",\n",
    "      \"Femme\",\n",
    "      \"Homme\",\n",
    "      \"Homme\", \n",
    "      \"Femme\", \n",
    "      \"Homme\",\n",
    "      \"Femme\", \n",
    "      \"Femme\", \n",
    "      \"Homme\", \n",
    "      \"Femme\", \n",
    "      \"Femme\",\n",
    "      \"Femme\",\n",
    "      \"Homme\",\n",
    "      \"Femme\",\n",
    "      \"Homme\",\n",
    "      \"Femme\",\n",
    "      \"Femme\",\n",
    "      \"Homme\",\n",
    "      \"Femme\",\n",
    "      \"Homme\",\n",
    "      \"Homme\",\n",
    "      \"Homme\",\n",
    "      \"Femme\",\n",
    "      \"Femme\",\n",
    "      ],\n",
    "\t\t\"cours\": [\n",
    "      [\"PPE1\", \"PPE2\", \"Introduction a la fouille de textes\"],\n",
    "      [\"Modelisation automatique pour l'analyse de textes\",\"Annotations semantiques et applications en recherche d'information\", \"Ingenierie des connaissances\", \"Linguistique outillee et traitements statistiques\"],\n",
    "      [\"Programmation et algorithmique 1\", \"Bases de donnees pour linguistes\", \"Enrichissement de corpus\", \"De la modelisation au traitement automatique des donnees linguistiques\", \"Ingenierie des connaissances\", \"Langages du web semantique\", \"seminaire tal et linguistique de corpus\"],\n",
    "      [\"Mathematiques pour le TAL\", \"Apprentissage automatique\", \"Arbres graphes\", \"Interfaces pour le web\"],\n",
    "      [\"Modelisation des langues\"],\n",
    "      [\"PPE1\", \"PPE2\"],\n",
    "      [\"Langages reguliers\", \"Statistiques textuelles\", \"Traitement statistique de corpus\"],\n",
    "      [\"Gest. Info Multilinguisme\", \"Ecriture et multilinguisme\"],\n",
    "      [\"Synthese de la parole\", \"CNN\", \"Phonetique physiologique et acoustique\"],\n",
    "      [\"Corpus arbores et parsing\"], \n",
    "      [\"Recueil de donnees et statistiques\"],\n",
    "      [\"Linguistique de la lsf\"], \n",
    "      [\"Morphologie\"],\n",
    "      [\"NLP in english\", \"Langues vivantes etrangeres\"], \n",
    "      [\"Programmation et algorithmique 2\"],\n",
    "      [\"Document structure\"],\n",
    "      [\"Outils de traitement de corpus\"], \n",
    "      [\"Corpus paralleles et comparables\"], \n",
    "      [\"Anglais de specialite 2\"],\n",
    "      [\"Semantique lexicale et textuelle\", \"Genres textes et usages\", \"Semantique des textes multilingues 1\"],\n",
    "      [\"Lexique et morphologie\"], \n",
    "      [\"Pratiques textuelles et traduction\", \"Traductologie 1\"],\n",
    "      [\"Programmation objet 1\", \"Programmation objet 2\"],\n",
    "      [\"Langages de script (python inalco)\", \"langages de script (roulois)\"],\n",
    "      [\"Extraction d'informations\"],\n",
    "      [\"Semantique computationnelle\"], \n",
    "      [\"Langages de script (jourdain)\"], \n",
    "      [\"Acquisition modelisation/representation\"],\n",
    "      [\"programmation orientee objet 1\"],\n",
    "      [\"Langue des signes\"], \n",
    "      [\"Conduite de projet de traduction 1\"],\n",
    "      [\"Fouille de textes 1\"], \n",
    "      [\"Outils de TAO 1\"], \n",
    "      [\"Traduction technique 1\"], \n",
    "      [\"Documents structures\"],\n",
    "      [\"Calculabilite\"],\n",
    "      [\"Large corpus linguistics\"],\n",
    "      [\"Traduction automatique et assistee\"],\n",
    "      [\"Polonais\"],\n",
    "      [\"Khmer\"],\n",
    "      [\"Gestion de projets\"],\n",
    "      [\"Coreen\"],\n",
    "      [\"Anglais pro\"],\n",
    "      [\"sociolinguistique\"],\n",
    "      [\"methodologie de la recherche\"],\n",
    "      [\"changements linguistiques\"],\n",
    "      [\"changements linguistiques\"],\n",
    "    #   [\"actualite dans le monde anglophone\"]\n",
    "    ],\n",
    "        \"directeur_memoire_de\" : [None,[\"Florian PHILIPPE\"], None, [\"Patricia AUGUSTYN\", \"Marie DELPORTE-LANDAT\", \"Florian PHILIPPE\"], [\"Ioana-Madalina SILAI\", \"Maria Paz BOTERO\"], None, None, None, [\"Lise BRISSET\"], None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n",
    "        \n",
    "}\n",
    "\n",
    "\n",
    "# print(len(prof[\"nom_prof\"]), len(prof[\"prenom_prof\"]), len(prof[\"etablissement\"]), len(prof[\"genre\"]), len(prof[\"cours\"]), len(prof[\"directeur_memoire_de\"]))\n",
    "noms_profss = dico_prof[\"nom_prof\"]\n",
    "prenoms_profss = dico_prof[\"prenom_prof\"]\n",
    "\n",
    "for nom, prenom in zip(noms_profss, prenoms_profss):\n",
    "    dico_prof[\"id_prof\"].append(f\"{prenom}_{nom}\")\n",
    "    print(f\"#{prenom}_{nom}#\")\n",
    "\n",
    "df_profs = pd.DataFrame(dico_prof)\n",
    "df_profs.to_csv(\"df_prof.csv\")\n",
    "\n",
    "# for (i, a), (j, b) in zip(enumerate(prof['prenom_prof']), enumerate(prof['genre'])):\n",
    "#     print(f\"{i, a}, {j, b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Création de la dataframe cours\n",
    "\n",
    "- id_cours\n",
    "- nom_cours\n",
    "- id_prof\n",
    "- nom_prof\n",
    "- prenom_prof\n",
    "- etablissement\n",
    "- annee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On normalise les colonnes cours en enlevant les virgules, en mettant tout en majuscule et en enlevant les accentS.\n",
    "On fait en sorte que les cours de la dataframe cours soient identiques à ceux présents dans la dataframe profs.\n",
    "Pour obtenir les professeurs qui enseignent chaque cours on va faire en sorte de modifier les colonnes \"cours\" du formulaire pour qu'elles disposent des cours avec les mêmes noms que dans la dataframe prof et qu'on puisse donc obtenir des correspondances automatiquement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalisation_m1_s1(list_courses):\n",
    "\n",
    "    ### On sépare les cours, on enlève les diacritiques et on met tout en minuscule\n",
    "    list_courses = list_courses.split(\", \")\n",
    "    list_courses = [unidecode(course.strip().lower()) for course in list_courses]\n",
    "    \n",
    "    ### On renomme ou on uniformise les cours pour une meilleure correspondance\n",
    "    dico_correspondance = {\n",
    "        \"ppe 1\" : \"ppe1\",\n",
    "        \"langages regulieres\" : \"langages reguliers\",\n",
    "        \"Langages reguliers\" : \"langages reguliers\",\n",
    "        \"gest. info multilinguisme (gim)\" : \"gest. info multilinguisme\",\n",
    "        \"programmation et algorithmique 1 (python nanterre)\" : \"programmation et algorithmique 1\",\n",
    "        \"modalisation automatique pour l'analyse de textes\" : \"modelisation automatique pour l'analyse de textes\",\n",
    "        \"programmation objet\" : \"programmation objet 1\",\n",
    "        \"pratiques textuelles\" : \"pratiques textuelles et traduction\",\n",
    "        \"langues vivantes\" : \"langues vivantes etrangeres\",\n",
    "        \"base de donnees pour linguistes\" : \"bases de donnees pour linguistes\", \n",
    "        \"langages de scripts (python inalco)\" : \"langages de script (python inalco)\",\n",
    "    }\n",
    "\n",
    "    cleaned_courses = []\n",
    "    for course in list_courses:\n",
    "        if course != \"linguistique au choix\" and course != \"principes de bases de données\":\n",
    "            if course in dico_correspondance.keys():\n",
    "                cleaned_courses.append(dico_correspondance[course])\n",
    "            else:\n",
    "                cleaned_courses.append(course)\n",
    "\n",
    "    # print(cleaned_courses)\n",
    "\n",
    "    return cleaned_courses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On crée de nouvelles colonnes qui contiennent les cours normalisés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### POUR LES COURS OBLIGATOIRES DU M1 S1\n",
    "df_formulaire[\"normalised_m1_s1_courses\"] = df_formulaire[\"Quels cours avez-vous suivis au premier semestre du M1 ?\"].apply(normalisation_m1_s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalisation_m1_s1_optional(list_courses):\n",
    "\n",
    "    if pd.isna(list_courses):\n",
    "        # print(\"[]\")\n",
    "        return []\n",
    "    list_courses = list_courses.split(\", \")\n",
    "    list_courses = [unidecode(course.strip().lower()) for course in list_courses]\n",
    "    \n",
    "    dico_correspondance = {\n",
    "        \"recueil de donnees et statistiques (nanterre)\" : \"recueil de donnees et statistiques\",\n",
    "        \"lexique et morphologie (inalco)\" : \"lexique et morphologie\",\n",
    "        \"nlp in english\" : \"langues vivantes etrangeres\",\n",
    "    }\n",
    "\n",
    "    cleaned_courses = []\n",
    "    for course in list_courses:\n",
    "        if course in dico_correspondance.keys():\n",
    "            cleaned_courses.append(dico_correspondance[course])\n",
    "        else:\n",
    "            cleaned_courses.append(course)\n",
    "\n",
    "    # print(cleaned_courses)\n",
    "    return cleaned_courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_formulaire[\"normalised_m1_s1_optionnal\"] = df_formulaire[\"Quelles ont été vos options de linguistique au premier semestre du M1 ?\\nSéparer les cours par des virgules. \"].apply(normalisation_m1_s1_optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalisation_m1_s1_extra(list_courses):\n",
    "\n",
    "    if pd.isna(list_courses):\n",
    "        # print(\"[]\")\n",
    "        return []\n",
    "    list_courses = list_courses.split(\", \")\n",
    "    list_courses = [unidecode(course.strip().lower()) for course in list_courses]\n",
    "    \n",
    "    dico_correspondance = {\n",
    "        \"recueil de donnees et statistiques (nanterre)\" : \"recueil de données et statistiques\",\n",
    "        \"lexique et morphologie (inalco)\" : \"lexique et morphologie\"\n",
    "    }\n",
    "\n",
    "    cleaned_courses = []\n",
    "    for course in list_courses:\n",
    "        if course in dico_correspondance.keys():\n",
    "            cleaned_courses.append(dico_correspondance[course])\n",
    "        else:\n",
    "            cleaned_courses.append(course)\n",
    "            \n",
    "    # print(cleaned_courses)\n",
    "    return cleaned_courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_formulaire[\"normalised_m1_s1_extra\"] = df_formulaire[\"Avons-nous oublié quelque cours au premier semestre du M1 ? Indiquez-le ici !\\nSéparez les cours par des virgules. \"].apply(normalisation_m1_s1_extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalisation_m1_s2(list_courses):\n",
    "\n",
    "    list_courses = list_courses.split(\", \")\n",
    "    list_courses = [unidecode(course.strip().lower()) for course in list_courses]\n",
    "\n",
    "    dico_correspondance = {\n",
    "        \"anglais de specialite\" : \"anglais de specialite 2\",\n",
    "        \"programmation objet\" : \"programmation objet 2\",\n",
    "        \"outil de traitement de corpus\" : \"outils de traitement de corpus\"\n",
    "    }\n",
    "\n",
    "    cleaned_courses = []\n",
    "    for course in list_courses:\n",
    "        if course in dico_correspondance.keys():\n",
    "            cleaned_courses.append(dico_correspondance[course])\n",
    "        else:\n",
    "            cleaned_courses.append(course)\n",
    "            \n",
    "    # print(cleaned_courses)\n",
    "    return cleaned_courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_formulaire[\"normalised_m1_s2_courses\"] = df_formulaire[\"Quels cours avez-vous suivis au second semestre du M1 ?\"].apply(normalisation_m1_s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalisation_m1_s2_extra(list_courses):\n",
    "\n",
    "    if pd.isna(list_courses):\n",
    "        # print(\"[]\")\n",
    "        return []\n",
    "    list_courses = list_courses.split(\", \")\n",
    "    list_courses = [unidecode(course.strip().lower()) for course in list_courses]\n",
    "\n",
    "    # print(list_courses)\n",
    "    return list_courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_formulaire[\"normalised_m1_s2_extra\"] = df_formulaire[\"Avons-nous oublié quelque cours au second semestre du M1 ? Indiquez-le ici !\\nSéparez les cours par des virgules. \"].apply(normalisation_m1_s2_extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalisation_m2_s1(list_courses):\n",
    "    \n",
    "    list_courses = list_courses.split(\", \")\n",
    "    list_courses = [unidecode(course.strip().lower()) for course in list_courses]\n",
    "\n",
    "    dico_correspondance = {\n",
    "        \"annotation semantiques et applications en recherche d'information (nanterre)\" : \"annotations semantiques et applications en recherche d'information\",\n",
    "        \"ingenierie de connaissances(nanterre)\" : \"ingenierie des connaissances\", \n",
    "        \"de la modelisation au traitement automatique des donnees linguistiques (nanterre)\" : \"de la modelisation au traitement automatique des donnees linguistiques\",\n",
    "        \"seminaire: tal et linguistique de corpus (nanterre)\" : \"seminaire tal et linguistique de corpus\",\n",
    "        \"apprentissage automatique (nanterre)\" : \"apprentissage automatique\",\n",
    "        \"arbres graphes (nanterre)\" : \"arbres graphes\",\n",
    "        \"interfaces pour le web (nanterre)\" : \"interfaces pour le web\",\n",
    "        \"modelisation des langues (nanterre)\" : \"modelisation des langues\",\n",
    "        \"langages du web semantique (nanterre)\" : \"langages du web semantique\",\n",
    "        \"linguistique outille et traitements statistiques (nanterre)\" : \"linguistique outillee et traitements statistiques\",\n",
    "        \"gestion de projets (nanterre)\" : \"gestion de projets\",\n",
    "        \"traitement automatique de corpus (inalco)\" : \"traitement statistique de corpus\",\n",
    "        \"genres textes et usages (inalco)\" : \"genres textes et usages\",\n",
    "        \"semantique des textes multilingues 1 (inalco)\" : \"semantique des textes multilingues 1\",\n",
    "        \"lexicologie terminologie et dictionnairique (inalco)\" : \"lexicologie terminologie et dictionnairique\",\n",
    "        \"acquisition modelisation/representation (inalco)\" : \"acquisition modelisation/representation\",\n",
    "        \"langages de script (inalco) (avec m.jourdain louis)\" : \"langages de script (jourdain)\",\n",
    "        \"langages de script (inalco) (avec m. roulois alexandre)\" : \"langages de script (roulois)\",\n",
    "        \"documents structures (inalco)\" : \"documents structures\",\n",
    "        \"cnn (sorbonne nouvelle)\" : \"cnn\",\n",
    "        \"calculabilite (inalco)\" : \"calculabilite\",\n",
    "        \"methodologie de la recherche (nanterre)\" : \"methodologie de la recherche\",\n",
    "        \"conduite de projet de traduction (inalco)\" : \"conduite de projet de traduction 1\",\n",
    "        \"programmation objet 1 (inalco)\" : \"programmation orientee objet 1\",\n",
    "        \"semantique computationnelle (sorbonne nouvelle)\" : \"semantique computationnelle\",\n",
    "        \"anglais (pro) (nanterre)\" : \"anglais pro\",\n",
    "        \"outils de tao 1 (inalco)\" : \"outils de tao 1\",\n",
    "        \"traductologie 1 (inalco)\" : \"traductologie 1\",\n",
    "        \"ecriture et multilinguisme (inalco)\" : \"ecriture et multilinguisme\",\n",
    "        'traduction technique 1 (inalco)': 'traduction technique 1',\n",
    "    }\n",
    "\n",
    "    cleaned_courses = []\n",
    "    for course in list_courses:\n",
    "        if course in dico_correspondance.keys():\n",
    "            cleaned_courses.append(dico_correspondance[course])\n",
    "        else:\n",
    "            cleaned_courses.append(course)\n",
    "\n",
    "    # print(cleaned_courses)\n",
    "    return cleaned_courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_formulaire[\"normalised_m2_s1_courses\"] = df_formulaire['Quels cours avez-vous suivis au premier semestre du M2 ?'].apply(normalisation_m2_s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalisation_m2_s1_extra(list_courses):\n",
    "\n",
    "    if pd.isna(list_courses):\n",
    "        # print(\"[]\")\n",
    "        return []\n",
    "    \n",
    "    list_courses = list_courses.split(\", \")\n",
    "    list_courses = [unidecode(course.strip().lower()) for course in list_courses]\n",
    "\n",
    "    dico_correspondance = {\n",
    "        \"traitement statistique de corpus (inalco)\" : \"traitement statistique de corpus\",\n",
    "        \"actualite dans le monde anglophone (anglais sorbonne nouvelle )\" : \"actualite dans le monde anglophone\",\n",
    "        \"fouille de textes (inalco)\" : \"fouille de textes 1\"\n",
    "    }\n",
    "\n",
    "    cleaned_courses = []\n",
    "    for course in list_courses:\n",
    "        if course != \"choix de linguistique\" and course != \"langue vivante\":\n",
    "            if course in dico_correspondance.keys():\n",
    "                cleaned_courses.append(dico_correspondance[course])\n",
    "            else:\n",
    "                cleaned_courses.append(course)\n",
    "\n",
    "    # print(cleaned_courses)\n",
    "    return cleaned_courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_formulaire[\"normalised_m2_s1_extra\"] = df_formulaire[\"Avons-nous oublié quelque cours au premier semestre du M2 ? Indiquez-le ici !\\nSéparez les cours par des virgules. \"].apply(normalisation_m2_s1_extra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On enregistre le formulaire avec de nouvelles colonnes dans un csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_formulaire.to_csv(\"formulaire_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut ensuite créer la dataframe cours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===== Initialisation du dictionnaire des cours =====#\n",
    "dico_cours = {\"nom_cours\": [],\n",
    "         \"id_prof\": [],\n",
    "         \"nom_prof\" : [],\n",
    "         \"prenom_prof\" : [],\n",
    "         \"etablissement\": [],\n",
    "         \"annee\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### En dessous c'est pour obtenir une liste des cours (unique) à partir de nos nouvelles colonnes normalisées !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===== Remplissage du dictionnaire des cours =====#\n",
    "\n",
    "courses_m1_s1 = df_formulaire[\"normalised_m1_s1_courses\"].to_list()\n",
    "courses_m1_s2 = df_formulaire[\"normalised_m1_s2_courses\"].to_list()\n",
    "courses_m2_s1 = df_formulaire[\"normalised_m2_s1_courses\"].to_list()\n",
    "\n",
    "mandatory_courses = courses_m1_s1 + courses_m1_s2 + courses_m2_s1\n",
    "mandatory_courses = [value for sublist in mandatory_courses for value in sublist]\n",
    "mandatory_courses = list(set(mandatory_courses))\n",
    "\n",
    "optional_courses_m1_s1 = df_formulaire[\"normalised_m1_s1_optionnal\"].dropna().to_list()\n",
    "optional_courses_m1_s1 = optional_courses_m1_s1 + df_formulaire[\"normalised_m1_s1_extra\"].dropna().to_list()\n",
    "optional_courses_m1_s2 = df_formulaire[\"normalised_m1_s2_extra\"].dropna().to_list()\n",
    "optional_courses_m2_s1 = df_formulaire[\"normalised_m2_s1_extra\"].dropna().to_list()\n",
    "optional_courses = optional_courses_m1_s1 + optional_courses_m1_s2 + optional_courses_m2_s1\n",
    "optional_courses = [value for sublist in optional_courses for value in sublist]\n",
    "optional_courses = list(set(optional_courses))\n",
    "\n",
    "cours = mandatory_courses + optional_courses\n",
    "cours = list(set(cours))\n",
    "\n",
    "if \"statistiques\" in cours:\n",
    "    cours.remove(\"statistiques\")\n",
    "dico_cours[\"nom_cours\"] = sorted(cours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dans le code en dessous en fait correspondre chaque cours à un professeur/à des professeurs pour qu'on ait la liste des profs qui enseignent chaque cours dans la df cours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for course in dico_cours[\"nom_cours\"]:\n",
    "    profs_noms = dico_prof[\"nom_prof\"]\n",
    "    profs_prenoms = dico_prof[\"prenom_prof\"]\n",
    "    courses = dico_prof[\"cours\"]\n",
    "    found = False\n",
    "    # print(\"On cherche le cours\", course)\n",
    "\n",
    "    for prof_nom, prof_prenom, subcourses in zip(profs_noms, profs_prenoms, courses):\n",
    "        # print(\"on cherche le cours\", course, \"dans la liste de cours :\")\n",
    "        subcourses = [subcourse.lower() for subcourse in subcourses]\n",
    "        # print(subcourses)\n",
    "        # print(\"qui est rattachée à:\")\n",
    "        # print(prof_nom, prof_nom)\n",
    "        if course in subcourses:\n",
    "            if found == True:\n",
    "                # print(f\"le cours {course} a été trouvé et on a déjà un prof\")\n",
    "                # print(\"donc, found est égal à \", found)\n",
    "                first_prof_nom = dico_cours[\"nom_prof\"][-1]\n",
    "                first_prof_prenom = dico_cours[\"prenom_prof\"][-1]\n",
    "                first_id_prof = dico_cours[\"id_prof\"][-1]\n",
    "                dico_cours[\"nom_prof\"].pop()\n",
    "                dico_cours[\"prenom_prof\"].pop()\n",
    "                dico_cours[\"id_prof\"].pop()\n",
    "\n",
    "                dico_cours[\"nom_prof\"].append([first_prof_nom, prof_nom])\n",
    "                dico_cours[\"prenom_prof\"].append([first_prof_prenom, prof_prenom])\n",
    "                dico_cours[\"id_prof\"].append([f\"{first_prof_prenom}_{first_prof_nom}\", f\"{prof_prenom}_{prof_nom}\"])\n",
    "            else:\n",
    "                found = True\n",
    "                dico_cours[\"nom_prof\"].append(prof_nom)\n",
    "                dico_cours[\"prenom_prof\"].append(prof_prenom)\n",
    "                dico_cours[\"id_prof\"].append(f\"{prof_prenom}_{prof_nom}\")\n",
    "\n",
    "            # for key, value in dico_cours.items():\n",
    "            #     print(key, value)\n",
    "    \n",
    "    if found == False:\n",
    "        dico_cours[\"nom_prof\"].append(\"\")\n",
    "        dico_cours[\"prenom_prof\"].append(\"\")\n",
    "        dico_cours[\"id_prof\"].append(\"\")\n",
    "    #     dico_cours[\"professeur\"].append(df_prof[\"nom_prof\"][df_prof[\"cours\"].index(course)])\n",
    "    # else:\n",
    "    #     dico_cours[\"professeur\"].append(\"Non défini\")\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acquisition modelisation/representation AOUINA Ons Ons_AOUINA\n",
      "actualite dans le monde anglophone   \n",
      "anglais de specialite 2 KOSMALA Loulou Loulou_KOSMALA\n",
      "anglais pro HUP Christophe Christophe_HUP\n",
      "annotations semantiques et applications en recherche d'information BATTISTELLI Delphine Delphine_BATTISTELLI\n",
      "apprentissage automatique GROBOL Loïc Loïc_GROBOL\n",
      "arbres graphes GROBOL Loïc Loïc_GROBOL\n",
      "bases de donnees pour linguistes ESHKOL-TARAVELLA Iris Iris_ESHKOL-TARAVELLA\n",
      "calculabilite PAROUBECK Patrick Patrick_PAROUBECK\n",
      "changements linguistiques ['LEHMANN', 'PICCOLI'] ['Sabine', 'Vanessa'] ['Sabine_LEHMANN', 'Vanessa_PICCOLI']\n",
      "cnn GENDROT Cedric Cedric_GENDROT\n",
      "conduite de projet de traduction 1 GAUMET Sophie Sophie_GAUMET\n",
      "coreen LEE Kyung Kyung_LEE\n",
      "corpus arbores et parsing HERRERA Santiago Santiago_HERRERA\n",
      "corpus paralleles et comparables ZWEIGENBAUM Pierre Pierre_ZWEIGENBAUM\n",
      "de la modelisation au traitement automatique des donnees linguistiques ESHKOL-TARAVELLA Iris Iris_ESHKOL-TARAVELLA\n",
      "document structure JACOBSON Michel Michel_JACOBSON\n",
      "documents structures ABROUGUI Rim Rim_ABROUGUI\n",
      "enrichissement de corpus ESHKOL-TARAVELLA Iris Iris_ESHKOL-TARAVELLA\n",
      "extraction d'informations MONNIN-TUILLIER Chloé Chloé_MONNIN-TUILLIER\n",
      "fouille de textes 1 GROUIN Cyril Cyril_GROUIN\n",
      "genres textes et usages VALETTE Mathieu Mathieu_VALETTE\n",
      "gest. info multilinguisme WANG Ilaine Ilaine_WANG\n",
      "gestion de projets CARCENAC Benoît Benoît_CARCENAC\n",
      "ingenierie des connaissances ['BATTISTELLI', 'ESHKOL-TARAVELLA'] ['Delphine', 'Iris'] ['Delphine_BATTISTELLI', 'Iris_ESHKOL-TARAVELLA']\n",
      "interfaces pour le web GROBOL Loïc Loïc_GROBOL\n",
      "introduction a la fouille de textes DUPONT Yoann Yoann_DUPONT\n",
      "khmer NUT Suppya Suppya_NUT\n",
      "langages de script (jourdain) JOURDAIN Louis Louis_JOURDAIN\n",
      "langages de script (python inalco) ROULOIS Alexandre Alexandre_ROULOIS\n",
      "langages du web semantique ESHKOL-TARAVELLA Iris Iris_ESHKOL-TARAVELLA\n",
      "langages reguliers NOUVEL Damien Damien_NOUVEL\n",
      "langue des signes AKSEN Hatice Hatice_AKSEN\n",
      "langues vivantes etrangeres STRICKER Armand Armand_STRICKER\n",
      "large corpus linguistics RAINERIE Sophie Sophie_RAINERIE\n",
      "lexicologie terminologie et dictionnairique   \n",
      "lexique et morphologie GABOR Kata Kata_GABOR\n",
      "linguistique de la lsf BOGLIOTTI Caroline Caroline_BOGLIOTTI\n",
      "linguistique outillee et traitements statistiques BATTISTELLI Delphine Delphine_BATTISTELLI\n",
      "mathematiques pour le tal GROBOL Loïc Loïc_GROBOL\n",
      "methodologie de la recherche CORI Marcel Marcel_CORI\n",
      "modelisation automatique pour l'analyse de textes BATTISTELLI Delphine Delphine_BATTISTELLI\n",
      "modelisation des langues KAHANE Sylvain Sylvain_KAHANE\n",
      "mooc   \n",
      "morphologie VILLEOING Florence Florence_VILLEOING\n",
      "nlp in english STRICKER Armand Armand_STRICKER\n",
      "outils de traitement de corpus SAUVAGE Eve Eve_SAUVAGE\n",
      "phonetique physiologique et acoustique GENDROT Cedric Cedric_GENDROT\n",
      "polonais LASON Natalia Natalia_LASON\n",
      "ppe1 ['DUPONT', 'MAGISTRY'] ['Yoann', 'Pierre'] ['Yoann_DUPONT', 'Pierre_MAGISTRY']\n",
      "ppe2 ['DUPONT', 'MAGISTRY'] ['Yoann', 'Pierre'] ['Yoann_DUPONT', 'Pierre_MAGISTRY']\n",
      "pratiques textuelles et traduction LICHAO Zhu Zhu_LICHAO\n",
      "principes de bases de donnees   \n",
      "programmation et algorithmique 1 ESHKOL-TARAVELLA Iris Iris_ESHKOL-TARAVELLA\n",
      "programmation et algorithmique 2 DEHOUCK Mathieu Mathieu_DEHOUCK\n",
      "programmation objet 1 JACQUEMARD Florent Florent_JACQUEMARD\n",
      "programmation objet 2 JACQUEMARD Florent Florent_JACQUEMARD\n",
      "programmation orientee objet 1 LECAILLIEZ Louis Louis_LECAILLIEZ\n",
      "recueil de donnees et statistiques WANG Xibin Xibin_WANG\n",
      "redaction professionnelle   \n",
      "semantique computationnelle AMSILI Pascal Pascal_AMSILI\n",
      "semantique des textes multilingues 1 VALETTE Mathieu Mathieu_VALETTE\n",
      "semantique lexicale et textuelle VALETTE Mathieu Mathieu_VALETTE\n",
      "seminaire tal et linguistique de corpus ESHKOL-TARAVELLA Iris Iris_ESHKOL-TARAVELLA\n",
      "sens multiple   \n",
      "sociolinguistique COSTA James James_COSTA\n",
      "statistiques textuelles NOUVEL Damien Damien_NOUVEL\n",
      "synthese de la parole GENDROT Cedric Cedric_GENDROT\n",
      "traduction automatique et assistee SEMMAR Nasredine Nasredine_SEMMAR\n",
      "traitement statistique de corpus NOUVEL Damien Damien_NOUVEL\n"
     ]
    }
   ],
   "source": [
    "cours = dico_cours[\"nom_cours\"]\n",
    "profs_noms = dico_cours[\"nom_prof\"]\n",
    "profs_prenoms = dico_cours[\"prenom_prof\"]\n",
    "id_profs = dico_cours[\"id_prof\"]\n",
    "\n",
    "for cour, nom, prenom, id_p in zip(cours, profs_noms, profs_prenoms, id_profs):\n",
    "    print(cour, nom, prenom, id_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On ajoute ensuite les années et les établissements pour chaque cours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nom_cours 70\n",
      "id_prof 70\n",
      "nom_prof 70\n",
      "prenom_prof 70\n",
      "etablissement 70\n",
      "annee 70\n",
      "acquisition modelisation/representation Inalco 2024-2025 1\n",
      "actualite dans le monde anglophone SorbonneNouvelle 2024-2025 2\n",
      "anglais de specialite 2 Nanterre 2023-2024 3\n",
      "anglais pro Nanterre 2024-2025 4\n",
      "annotations semantiques et applications en recherche d'information Nanterre 2024-2025 5\n",
      "apprentissage automatique Nanterre 2024-2025 6\n",
      "arbres graphes Nanterre 2024-2025 7\n",
      "bases de donnees pour linguistes Nanterre 2023-2024 8\n",
      "calculabilite Inalco 2024-2025 9\n",
      "changements linguistiques Nanterre 2023-2024 10\n",
      "cnn SorbonneNouvelle 2024-2025 11\n",
      "conduite de projet de traduction 1 Inalco 2024-2025 12\n",
      "coreen Inalco 2023-2024 13\n",
      "corpus arbores et parsing Nanterre 2023-2024 14\n",
      "corpus paralleles et comparables Inalco 2023-2024 15\n",
      "de la modelisation au traitement automatique des donnees linguistiques Nanterre 2024-2025 16\n",
      "document structure SorbonneNouvelle 2023-2024 17\n",
      "documents structures Inalco 2024-2025 18\n",
      "enrichissement de corpus Nanterre 2023-2024 19\n",
      "extraction d'informations Inalco 2023-2024 20\n",
      "fouille de textes 1 Inalco 2024-2025 21\n",
      "genres textes et usages Inalco 2024-2025 22\n",
      "gest. info multilinguisme Inalco 2023-2024 23\n",
      "gestion de projets Nanterre 2024-2025 24\n",
      "ingenierie des connaissances Nanterre 2024-2025 25\n",
      "interfaces pour le web Nanterre 2024-2025 26\n",
      "introduction a la fouille de textes SorbonneNouvelle 2023-2024 27\n",
      "khmer Inalco 2023-2024 28\n",
      "langages de script (jourdain) Inalco 2024-2025 29\n",
      "langages de script (python inalco) Inalco 2023-2024 30\n",
      "langages du web semantique Nanterre 2024-2025 31\n",
      "langages reguliers Inalco 2023-2024 32\n",
      "langue des signes Nanterre 2024-2025 33\n",
      "langues vivantes etrangeres Inalco 2023-2024 34\n",
      "large corpus linguistics Nanterre 2023-2024 35\n",
      "lexicologie terminologie et dictionnairique Inalco 2024-2025 36\n",
      "lexique et morphologie Inalco 2023-2024 37\n",
      "linguistique de la lsf Nanterre 2023-2024 38\n",
      "linguistique outillee et traitements statistiques Nanterre 2024-2025 39\n",
      "mathematiques pour le tal Nanterre 2023-2024 40\n",
      "methodologie de la recherche Nanterre 2024-2025 41\n",
      "modelisation automatique pour l'analyse de textes Nanterre 2023-2024 42\n",
      "modelisation des langues Nanterre 2024-2025 43\n",
      "mooc Inalco 2023-2024 44\n",
      "morphologie Nanterre 2023-2024 45\n",
      "nlp in english Inalco 2023-2024 46\n",
      "outils de traitement de corpus Inalco 2023-2024 47\n",
      "phonetique physiologique et acoustique SorbonneNouvelle 2023-2024 48\n",
      "polonais Inalco 2023-2024 49\n",
      "ppe1 SorbonneNouvelle 2023-2024 50\n",
      "ppe2 SorbonneNouvelle 2023-2024 51\n",
      "pratiques textuelles et traduction Inalco 2023-2024 52\n",
      "principes de bases de donnees Inalco 2023-2024 53\n",
      "programmation et algorithmique 1 Nanterre 2023-2024 54\n",
      "programmation et algorithmique 2 SorbonneNouvelle 2023-2024 55\n",
      "programmation objet 1 Inalco 2023-2024 56\n",
      "programmation objet 2 Inalco 2023-2024 57\n",
      "programmation orientee objet 1 Inalco 2024-2025 58\n",
      "recueil de donnees et statistiques Nanterre 2023-2024 59\n",
      "redaction professionnelle Nanterre 2023-2024 60\n",
      "semantique computationnelle SorbonneNouvelle 2024-2025 61\n",
      "semantique des textes multilingues 1 Inalco 2024-2025 62\n",
      "semantique lexicale et textuelle Inalco 2023-2024 63\n",
      "seminaire tal et linguistique de corpus Nanterre 2024-2025 64\n",
      "sens multiple SorbonneNouvelle 2023-2024 65\n",
      "sociolinguistique SorbonneNouvelle 2023-2024 66\n",
      "statistiques textuelles Inalco 2023-2024 67\n",
      "synthese de la parole SorbonneNouvelle 2023-2024 68\n",
      "traduction automatique et assistee Inalco 2023-2024 69\n",
      "traitement statistique de corpus Inalco 2024-2025 70\n"
     ]
    }
   ],
   "source": [
    "dico_cours[\"annee\"] = [ '2024-2025', '2024-2025', '2023-2024', '2024-2025', '2024-2025', '2024-2025', '2024-2025', '2023-2024',\n",
    "                        '2024-2025', '2023-2024', '2024-2025', '2024-2025', '2023-2024', '2023-2024', '2023-2024', '2024-2025',\n",
    "                        '2023-2024', '2024-2025', '2023-2024', '2023-2024', '2024-2025', '2024-2025', '2023-2024', '2024-2025',\n",
    "                        '2024-2025', '2024-2025', '2023-2024', '2023-2024', '2024-2025', '2023-2024', '2024-2025', '2023-2024',\n",
    "                        '2024-2025', '2023-2024', '2023-2024', '2024-2025', '2023-2024', '2023-2024', '2024-2025', '2023-2024',\n",
    "                        '2024-2025', '2023-2024', '2024-2025', '2023-2024', '2023-2024', '2023-2024', '2023-2024', '2023-2024',\n",
    "                        '2023-2024', '2023-2024', '2023-2024', '2023-2024', '2023-2024', '2023-2024', '2023-2024', '2023-2024',\n",
    "                        '2023-2024', '2024-2025', '2023-2024', '2023-2024', '2024-2025', '2024-2025', '2023-2024', '2024-2025',\n",
    "                        '2023-2024', '2023-2024', '2023-2024', '2023-2024', '2023-2024', '2024-2025']\n",
    "\n",
    "dico_cours[\"etablissement\"] = ['Inalco', 'SorbonneNouvelle', 'Nanterre', 'Nanterre', 'Nanterre', 'Nanterre', 'Nanterre', 'Nanterre',\n",
    "                 'Inalco', 'Nanterre', 'SorbonneNouvelle', 'Inalco', 'Inalco', 'Nanterre', 'Inalco', 'Nanterre',\n",
    "                 'SorbonneNouvelle', 'Inalco', 'Nanterre', 'Inalco', 'Inalco', 'Inalco', 'Inalco', 'Nanterre',\n",
    "                 'Nanterre', 'Nanterre', 'SorbonneNouvelle', 'Inalco', 'Inalco', 'Inalco', 'Nanterre', 'Inalco',\n",
    "                 'Nanterre', 'Inalco', 'Nanterre', 'Inalco', 'Inalco', 'Nanterre', 'Nanterre', 'Nanterre', 'Nanterre',\n",
    "                 'Nanterre', 'Nanterre', 'Inalco', 'Nanterre', 'Inalco', 'Inalco', 'SorbonneNouvelle', 'Inalco',\n",
    "                 'SorbonneNouvelle', 'SorbonneNouvelle', 'Inalco', 'Inalco', 'Nanterre', 'SorbonneNouvelle', 'Inalco',\n",
    "                 'Inalco', 'Inalco', 'Nanterre', 'Nanterre', 'SorbonneNouvelle', 'Inalco', 'Inalco', 'Nanterre',\n",
    "                 'SorbonneNouvelle', 'SorbonneNouvelle', 'Inalco', 'SorbonneNouvelle', 'Inalco', 'Inalco']\n",
    "# print(len(dico_cours[\"annee\"]), len(dico_cours[\"nom_cours\"]), len(dico_cours[\"nom_prof\"]), len(dico_cours[\"prenom_prof\"]), len(dico_cours[\"id_prof\"]), len(dico_cours[\"etablissement\"]))\n",
    "\n",
    "for key, value in dico_cours.items():\n",
    "    print(key, len(value))\n",
    "\n",
    "i = 1\n",
    "for nom_cours, etablissement, annee in zip(dico_cours[\"nom_cours\"], dico_cours[\"etablissement\"], dico_cours[\"annee\"]):\n",
    "    print(nom_cours, etablissement, annee, i)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On ajoute ensuite une colonne id_cours composée du nom et de l'année de dispense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acquisition_modelisation_representation_2024_2025', 'actualite_dans_le_monde_anglophone_2024_2025', 'anglais_de_specialite_2_2023_2024', 'anglais_pro_2024_2025', 'annotations_semantiques_et_applications_en_recherche_d_information_2024_2025', 'apprentissage_automatique_2024_2025', 'arbres_graphes_2024_2025', 'bases_de_donnees_pour_linguistes_2023_2024', 'calculabilite_2024_2025', 'changements_linguistiques_2023_2024', 'cnn_2024_2025', 'conduite_de_projet_de_traduction_1_2024_2025', 'coreen_2023_2024', 'corpus_arbores_et_parsing_2023_2024', 'corpus_paralleles_et_comparables_2023_2024', 'de_la_modelisation_au_traitement_automatique_des_donnees_linguistiques_2024_2025', 'document_structure_2023_2024', 'documents_structures_2024_2025', 'enrichissement_de_corpus_2023_2024', 'extraction_d_informations_2023_2024', 'fouille_de_textes_1_2024_2025', 'genres_textes_et_usages_2024_2025', 'gest__info_multilinguisme_2023_2024', 'gestion_de_projets_2024_2025', 'ingenierie_des_connaissances_2024_2025', 'interfaces_pour_le_web_2024_2025', 'introduction_a_la_fouille_de_textes_2023_2024', 'khmer_2023_2024', 'langages_de_script_(jourdain)_2024_2025', 'langages_de_script_(python_inalco)_2023_2024', 'langages_du_web_semantique_2024_2025', 'langages_reguliers_2023_2024', 'langue_des_signes_2024_2025', 'langues_vivantes_etrangeres_2023_2024', 'large_corpus_linguistics_2023_2024', 'lexicologie_terminologie_et_dictionnairique_2024_2025', 'lexique_et_morphologie_2023_2024', 'linguistique_de_la_lsf_2023_2024', 'linguistique_outillee_et_traitements_statistiques_2024_2025', 'mathematiques_pour_le_tal_2023_2024', 'methodologie_de_la_recherche_2024_2025', 'modelisation_automatique_pour_l_analyse_de_textes_2023_2024', 'modelisation_des_langues_2024_2025', 'mooc_2023_2024', 'morphologie_2023_2024', 'nlp_in_english_2023_2024', 'outils_de_traitement_de_corpus_2023_2024', 'phonetique_physiologique_et_acoustique_2023_2024', 'polonais_2023_2024', 'ppe1_2023_2024', 'ppe2_2023_2024', 'pratiques_textuelles_et_traduction_2023_2024', 'principes_de_bases_de_donnees_2023_2024', 'programmation_et_algorithmique_1_2023_2024', 'programmation_et_algorithmique_2_2023_2024', 'programmation_objet_1_2023_2024', 'programmation_objet_2_2023_2024', 'programmation_orientee_objet_1_2024_2025', 'recueil_de_donnees_et_statistiques_2023_2024', 'redaction_professionnelle_2023_2024', 'semantique_computationnelle_2024_2025', 'semantique_des_textes_multilingues_1_2024_2025', 'semantique_lexicale_et_textuelle_2023_2024', 'seminaire_tal_et_linguistique_de_corpus_2024_2025', 'sens_multiple_2023_2024', 'sociolinguistique_2023_2024', 'statistiques_textuelles_2023_2024', 'synthese_de_la_parole_2023_2024', 'traduction_automatique_et_assistee_2023_2024', 'traitement_statistique_de_corpus_2024_2025']\n",
      "70 70 70 70 70 70 70\n"
     ]
    }
   ],
   "source": [
    "noms_cours = dico_cours[\"nom_cours\"]\n",
    "annees_cours = dico_cours[\"annee\"]\n",
    "\n",
    "id_cours = []\n",
    "\n",
    "for nom, annee in zip(noms_cours, annees_cours):\n",
    "    nom_very_clean = nom.replace(\" \", \"_\").replace(\"'\", \"_\").replace(\"/\", \"_\").replace(\".\", \"_\")\n",
    "    annee_very_clean = annee.replace(\"-\", \"_\")\n",
    "    id_cours.append(f\"{nom_very_clean}_{annee_very_clean}\")\n",
    "\n",
    "\n",
    "dico_cours[\"id_cours\"] = id_cours\n",
    "print(dico_cours[\"id_cours\"])\n",
    "\n",
    "print(len(dico_cours[\"id_cours\"]), len(dico_cours[\"nom_cours\"]), len(dico_cours[\"nom_prof\"]), len(dico_cours[\"prenom_prof\"]), len(dico_cours[\"id_prof\"]), len(dico_cours[\"etablissement\"]), len(dico_cours[\"annee\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, on enregistre la dataframe cours !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cours = pd.DataFrame(dico_cours)\n",
    "df_cours.to_csv(\"df_cours.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Création de la dataframe élèves\n",
    "- id\n",
    "- prenom\n",
    "- nom\n",
    "- genre\n",
    "- date_naissance\n",
    "- nationalite\n",
    "- redoublement\n",
    "- inscription_m1\n",
    "- parcours_m2\n",
    "- tiers_temps\n",
    "- inscription_simultanee\n",
    "- bac\n",
    "- lience\n",
    "- mention_licence\n",
    "- autre_master\n",
    "- mention_master\n",
    "- autres-diplomes\n",
    "- job_etudiant\n",
    "- profession_avant\n",
    "- prefere_cours\n",
    "- prefere_sujet\n",
    "- prefere_evaluation\n",
    "- suggestion_maquette\n",
    "- ennemi_jure\n",
    "- sante_avant\n",
    "- sante_apres\n",
    "- quota_pleure\n",
    "- heures_sommeil\n",
    "- difficulte_m1\n",
    "- difficulte_alternance\n",
    "- difficulte_im\n",
    "- difficulte_rd\n",
    "- difficulte_tetradom\n",
    "- jeter_linux\n",
    "- jeter_mac\n",
    "- admin_nanterre\n",
    "- admin_sorbonne\n",
    "- admin_inalco\n",
    "- conseil_eleve\n",
    "- recommandation\n",
    "- conseil_prof\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "eleves = {}\n",
    "\n",
    "df_eleves = pd.DataFrame(eleves)\n",
    "\n",
    "df_eleves['id'] = df_formulaire['Prénom'].str.strip().str.replace(' ', '_') + '_' + df_formulaire['Nom de famille'].str.replace('-', '_')\n",
    "df_eleves['prenom'] = df_formulaire['Prénom']\n",
    "df_eleves['nom'] = df_formulaire['Nom de famille']\n",
    "df_eleves['genre'] = df_formulaire['Genre']\n",
    "df_eleves['date_naissance'] = df_formulaire['Date de naissance']\n",
    "df_eleves['nationalite'] = df_formulaire['Nationalité']\n",
    "df_eleves['redoublement'] = df_formulaire['Avez-vous redoublé le master ? Si oui, indiquez quelle année et quel niveau. '].str.lower()\n",
    "df_eleves['inscription_M1'] = df_formulaire['Dans quelle université étiez-vous inscrits au M1 ? ']\n",
    "df_eleves['parcours_M2'] = df_formulaire['Dans quel parcours êtes-vous inscrits au M2 ?']\n",
    "df_eleves['tiers_temps'] = df_formulaire['Disposez vous ou avez-vous disposé d\\'un aménagement handicap pour le master (tiers-temps, autres...) ?'].str.lower()\n",
    "df_eleves['inscription_simultanee'] = df_formulaire['Si vous êtes inscrits (ou avez été inscrits) dans un autre établissement pendant le master, indiquez lequel :\\n\\nExemple :\\nÉtudiant en M2 TAL Ingénierie Multilingue et à 42 en même temps.']\n",
    "df_eleves['BAC'] = df_formulaire['Si vous avez obtenu un baccalauréat français, quelle était votre filière : ']\n",
    "df_eleves['licence'] = df_formulaire['Avez-vous déjà une licence ?\\nSi oui, veuillez indiquer son nom original (langue d\\'origine) au format :\\nNOM, UNIVERSITÉ\\n\\nExemple:\\nLicence en biologie, Université Paris Saclay']\n",
    "df_eleves['mention_licence'] = df_formulaire['Indiquez si cette licence appartient à l\\'une des mentions suivantes :']\n",
    "df_eleves['autre_master'] = df_formulaire['Avez-vous déjà un master ?\\nSi oui, veuillez indiquer son nom original (langue d\\'origine) au format :\\nNOM, UNIVERSITÉ\\n\\nExemple:\\nMaster Linguistique Anglaise, Université Sorbonne Nouvelle']\n",
    "df_eleves['mention_master_precedent'] = df_formulaire['Indiquez si ce master appartient à une des mentions suivantes : ']\n",
    "df_eleves['autres_diplomes'] = df_formulaire['Si vous avez obtenu un autre type de diplôme (hors licence et master), indiquez son nom original (langue d\\'origine) au format :\\nNOM, ÉTABLISSEMENT\\n\\nExemple:\\nBTS en communication, Lycée Paul Eluard, Saint-Denis']\n",
    "df_eleves['job_etudiant'] = df_formulaire['Si vous travaillez (ou avez travaillé) pendant le master, indiquez sur quel poste (hors stage TAL) :\\n\\nExemple :\\nActuellement employé polyvalent à Décathlon.']\n",
    "df_eleves['profession_avant'] = df_formulaire['Si vous avez exercé une activité professionnelle de longue durée avant le master (reconversion, reprise d\\'études ou autres), indiquez laquelle :\\n\\nExemple:\\nProfesseure à l\\'alliance française de Bogotá. ']\n",
    "df_eleves['prefere_cours'] = df_formulaire['Si vous deviez élire le meilleur cours de tout le master, lequel choisiriez-vous ? ']\n",
    "df_eleves['prefere_sujet'] = df_formulaire['Quels sont vos sujets préférés en cours ? ']\n",
    "df_eleves['prefere_evaluation'] = df_formulaire['Quelle(s) modalité(s) d\\'évaluation préférez-vous ?']\n",
    "df_eleves['suggestion_maquette'] = df_formulaire['Quel aspect aimeriez-vous voir plus mis en avant pendant le master ? Ça peut être un sujet en particulier, des compétences spécifiques ou autre.']\n",
    "df_eleves['ennemi_jure'] = df_formulaire['Qui est votre ennemi juré dans le master parmi les élèves (soyez pas sérieux c\\'est pour rigoler) ? ']\n",
    "df_eleves['sante_avant'] = df_formulaire['Sur combien notez-vous votre santé mentale avant le master ?']\n",
    "df_eleves['sante_apres'] = df_formulaire['Sur combien notez-vous votre santé mentale après le master ? ']\n",
    "df_eleves['quota_pleure'] = df_formulaire['À quelle fréquence pleurez-vous à cause du master ?\\nex: x/mois ou x/semaine ou x/jour ...']\n",
    "df_eleves['heures_sommeil'] = df_formulaire['Combien d\\'heures par nuit dormez-vous en moyenne ?']\n",
    "df_eleves['difficulte_M1'] = df_formulaire['Sur combien notez-vous la difficulté du M1 ?']\n",
    "df_eleves['difficulte_alternance'] = df_formulaire['Sur combien notez-vous la difficulté du M2 parcours Alternance ?']\n",
    "df_eleves['difficulte_IM'] = df_formulaire['Sur combien notez-vous la difficulté du M2 parcours Ingénierie Multilingue ?']\n",
    "df_eleves['difficulte_RD'] = df_formulaire['Sur combien notez-vous la difficulté du M2 parcours Recherche et Développement ?']\n",
    "df_eleves['difficulte_tetradom'] = df_formulaire['Sur combien notez-vous la difficulté du M2 parcours Technologies de la Traduction et Traitement des Données Multilingues ?']\n",
    "df_eleves['jeter_linux'] = df_formulaire['Pour les adeptes de Linux, voulez-vous régulièrement jeter votre ordinateur par la fenêtre ?']\n",
    "df_eleves['jeter_mac'] = df_formulaire['Pour les adeptes de Mac, voulez-vous régulièrement jeter votre ordinateur par la fenêtre ?']\n",
    "df_eleves['admin_nanterre'] = df_formulaire['Pour les étudiants de Nanterre, sur combien notez-vous l\\'efficacité de votre administration ?']\n",
    "df_eleves['admin_sorbonne'] = df_formulaire['Pour les étudiants de la Sorbonne-Nouvelle, sur combien notez-vous l\\'efficacité de votre administration ?']\n",
    "df_eleves['admin_inalco'] = df_formulaire['Pour les étudiants de l\\'INALCO, sur combien notez-vous l\\'efficacité de votre administration ?']\n",
    "df_eleves['conseil_eleve'] = df_formulaire['Quel conseil donneriez-vous aux futurs élèves pour survivre au master TAL ?']\n",
    "df_eleves['recommandation'] = df_formulaire['À qui recommanderiez-vous le master TAL ?']\n",
    "df_eleves['conseil_prof'] = df_formulaire['Quel conseil donneriez-vous aux professeurs du master TAL ? ']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On ajoute ensuite les cours suivis par chaque élèves (normalisés dans le formulaire sauvegardé) dans la dataframe élèves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eleves_avec_cours = pd.merge(df_eleves, df_formulaire[[\"Nom de famille\", \"normalised_m1_s1_courses\", \"normalised_m1_s1_optionnal\", \"normalised_m1_s1_extra\", \"normalised_m1_s2_courses\", \"normalised_m1_s2_extra\", \"normalised_m2_s1_courses\", \"normalised_m2_s1_extra\"]], left_on=\"nom\", right_on=\"Nom de famille\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eleves_avec_cours.to_csv(\"eleves_avec_cours.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prenom</th>\n",
       "      <th>nom</th>\n",
       "      <th>genre</th>\n",
       "      <th>date_naissance</th>\n",
       "      <th>nationalite</th>\n",
       "      <th>redoublement</th>\n",
       "      <th>inscription_M1</th>\n",
       "      <th>parcours_M2</th>\n",
       "      <th>tiers_temps</th>\n",
       "      <th>...</th>\n",
       "      <th>recommandation</th>\n",
       "      <th>conseil_prof</th>\n",
       "      <th>Nom de famille</th>\n",
       "      <th>normalised_m1_s1_courses</th>\n",
       "      <th>normalised_m1_s1_optionnal</th>\n",
       "      <th>normalised_m1_s1_extra</th>\n",
       "      <th>normalised_m1_s2_courses</th>\n",
       "      <th>normalised_m1_s2_extra</th>\n",
       "      <th>normalised_m2_s1_courses</th>\n",
       "      <th>normalised_m2_s1_extra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pauline_DÉGEZ</td>\n",
       "      <td>Pauline</td>\n",
       "      <td>DÉGEZ</td>\n",
       "      <td>Femme</td>\n",
       "      <td>10/04/1988</td>\n",
       "      <td>FR</td>\n",
       "      <td>non</td>\n",
       "      <td>Nanterre</td>\n",
       "      <td>Alternance (Nanterre)</td>\n",
       "      <td>non</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Parlez vous pour vous coordonner (surtout quan...</td>\n",
       "      <td>DÉGEZ</td>\n",
       "      <td>[langages reguliers, gest. info multilinguisme...</td>\n",
       "      <td>[recueil de donnees et statistiques, morphologie]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[corpus paralleles et comparables, statistique...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[annotations semantiques et applications en re...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Perrine_QUENNEHEN</td>\n",
       "      <td>Perrine</td>\n",
       "      <td>QUENNEHEN</td>\n",
       "      <td>Femme</td>\n",
       "      <td>14/02/1997</td>\n",
       "      <td>FR</td>\n",
       "      <td>non</td>\n",
       "      <td>INALCO</td>\n",
       "      <td>Ingénierie Multilingue (INALCO)</td>\n",
       "      <td>non</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QUENNEHEN</td>\n",
       "      <td>[langages reguliers, gest. info multilinguisme...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[corpus paralleles et comparables, statistique...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[traitement statistique de corpus, genres text...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ashley_RATIER</td>\n",
       "      <td>Ashley</td>\n",
       "      <td>RATIER</td>\n",
       "      <td>Femme</td>\n",
       "      <td>24/11/1998</td>\n",
       "      <td>FR</td>\n",
       "      <td>non</td>\n",
       "      <td>Nanterre</td>\n",
       "      <td>Alternance (Nanterre)</td>\n",
       "      <td>non</td>\n",
       "      <td>...</td>\n",
       "      <td>À VOTRE ENNEMI JURÉ !</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RATIER</td>\n",
       "      <td>[langages reguliers, gest. info multilinguisme...</td>\n",
       "      <td>[morphologie, recueil de donnees et statistiques]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[corpus paralleles et comparables, statistique...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[annotations semantiques et applications en re...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Valentine_FLEITH</td>\n",
       "      <td>Valentine</td>\n",
       "      <td>FLEITH</td>\n",
       "      <td>Femme</td>\n",
       "      <td>06/07/2001</td>\n",
       "      <td>FR</td>\n",
       "      <td>non</td>\n",
       "      <td>Sorbonne-Nouvelle</td>\n",
       "      <td>Alternance (Nanterre)</td>\n",
       "      <td>non</td>\n",
       "      <td>...</td>\n",
       "      <td>À personne.</td>\n",
       "      <td>Fermez le master</td>\n",
       "      <td>FLEITH</td>\n",
       "      <td>[langages reguliers, gest. info multilinguisme...</td>\n",
       "      <td>[recueil de donnees et statistiques, morphologie]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[corpus paralleles et comparables, statistique...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[annotations semantiques et applications en re...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Débora_VAN_DEN_ZANDE</td>\n",
       "      <td>Débora</td>\n",
       "      <td>VAN-DEN-ZANDE</td>\n",
       "      <td>Femme</td>\n",
       "      <td>13/04/2002</td>\n",
       "      <td>FR</td>\n",
       "      <td>non</td>\n",
       "      <td>Sorbonne-Nouvelle</td>\n",
       "      <td>Alternance (Nanterre)</td>\n",
       "      <td>non</td>\n",
       "      <td>...</td>\n",
       "      <td>À personne.</td>\n",
       "      <td>EMBAUCHEZ DES GENS QUALIFIES</td>\n",
       "      <td>VAN-DEN-ZANDE</td>\n",
       "      <td>[langages reguliers, gest. info multilinguisme...</td>\n",
       "      <td>[morphologie, recueil de donnees et statistiques]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[corpus paralleles et comparables, statistique...</td>\n",
       "      <td>[coreen]</td>\n",
       "      <td>[annotations semantiques et applications en re...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Patricia_AUGUSTYN</td>\n",
       "      <td>Patricia</td>\n",
       "      <td>AUGUSTYN</td>\n",
       "      <td>Femme</td>\n",
       "      <td>22/06/2002</td>\n",
       "      <td>FR</td>\n",
       "      <td>non</td>\n",
       "      <td>Sorbonne-Nouvelle</td>\n",
       "      <td>Recherche et Développement (Sorbonne Nouvelle)</td>\n",
       "      <td>non</td>\n",
       "      <td>...</td>\n",
       "      <td>À personne.</td>\n",
       "      <td>De communiquer davantage entre vous, surtout e...</td>\n",
       "      <td>AUGUSTYN</td>\n",
       "      <td>[langages reguliers, gest. info multilinguisme...</td>\n",
       "      <td>[sociolinguistique, phonetique physiologique e...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[corpus paralleles et comparables, statistique...</td>\n",
       "      <td>[polonais]</td>\n",
       "      <td>[apprentissage automatique, modelisation des l...</td>\n",
       "      <td>[traitement statistique de corpus]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ioana_Madalina_SILAI</td>\n",
       "      <td>Ioana Madalina</td>\n",
       "      <td>SILAI</td>\n",
       "      <td>Femme</td>\n",
       "      <td>02/10/1995</td>\n",
       "      <td>RO</td>\n",
       "      <td>non</td>\n",
       "      <td>Nanterre</td>\n",
       "      <td>Recherche et Développement (Nanterre)</td>\n",
       "      <td>non</td>\n",
       "      <td>...</td>\n",
       "      <td>À personne.</td>\n",
       "      <td>Perdez moins de temps dans les cours, préparez...</td>\n",
       "      <td>SILAI</td>\n",
       "      <td>[langages reguliers, gest. info multilinguisme...</td>\n",
       "      <td>[large corpus linguistics, langues vivantes et...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[corpus paralleles et comparables, statistique...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[seminaire tal et linguistique de corpus, appr...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Marie_DELPORTE_LANDAT</td>\n",
       "      <td>Marie</td>\n",
       "      <td>DELPORTE-LANDAT</td>\n",
       "      <td>Femme</td>\n",
       "      <td>18/05/2002</td>\n",
       "      <td>FR</td>\n",
       "      <td>non</td>\n",
       "      <td>Sorbonne-Nouvelle</td>\n",
       "      <td>Recherche et Développement (Sorbonne Nouvelle)</td>\n",
       "      <td>non</td>\n",
       "      <td>...</td>\n",
       "      <td>À personne.</td>\n",
       "      <td>7 notes pour un cours c'est peut-être un peu b...</td>\n",
       "      <td>DELPORTE-LANDAT</td>\n",
       "      <td>[langages reguliers, gest. info multilinguisme...</td>\n",
       "      <td>[recueil de donnees et statistiques, phonetiqu...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[corpus paralleles et comparables, statistique...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[apprentissage automatique, modelisation des l...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Florian_PHILIPPE</td>\n",
       "      <td>Florian</td>\n",
       "      <td>PHILIPPE</td>\n",
       "      <td>Homme</td>\n",
       "      <td>12/03/2001</td>\n",
       "      <td>FR</td>\n",
       "      <td>non</td>\n",
       "      <td>Nanterre</td>\n",
       "      <td>Recherche et Développement (Nanterre)</td>\n",
       "      <td>non</td>\n",
       "      <td>...</td>\n",
       "      <td>À personne.</td>\n",
       "      <td>Savoir reconnaître quand on n'a pas les compét...</td>\n",
       "      <td>PHILIPPE</td>\n",
       "      <td>[langages reguliers, gest. info multilinguisme...</td>\n",
       "      <td>[morphologie, recueil de donnees et statistiques]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[corpus paralleles et comparables, document st...</td>\n",
       "      <td>[nlp in english]</td>\n",
       "      <td>[seminaire tal et linguistique de corpus, appr...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lydia_BELHOUL</td>\n",
       "      <td>Lydia</td>\n",
       "      <td>BELHOUL</td>\n",
       "      <td>Femme</td>\n",
       "      <td>09/08/1988</td>\n",
       "      <td>ALG</td>\n",
       "      <td>non</td>\n",
       "      <td>Nanterre</td>\n",
       "      <td>Alternance (Nanterre)</td>\n",
       "      <td>non</td>\n",
       "      <td>...</td>\n",
       "      <td>À votre meilleur copain :&gt;</td>\n",
       "      <td>Pètez un coup ça vous fera du bien</td>\n",
       "      <td>BELHOUL</td>\n",
       "      <td>[langages reguliers, gest. info multilinguisme...</td>\n",
       "      <td>[morphologie, recueil de donnees et statistiques]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[corpus paralleles et comparables, statistique...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[annotations semantiques et applications en re...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Lucile_BESSAC</td>\n",
       "      <td>Lucile</td>\n",
       "      <td>BESSAC</td>\n",
       "      <td>Femme</td>\n",
       "      <td>21/01/2000</td>\n",
       "      <td>FR</td>\n",
       "      <td>non</td>\n",
       "      <td>INALCO</td>\n",
       "      <td>Alternance (Nanterre)</td>\n",
       "      <td>non</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Prendre le temps, à chaque début de cours (1er...</td>\n",
       "      <td>BESSAC</td>\n",
       "      <td>[langages reguliers, gest. info multilinguisme...</td>\n",
       "      <td>[langues vivantes etrangeres]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[corpus paralleles et comparables, statistique...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[annotations semantiques et applications en re...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Kehina_MANSERI</td>\n",
       "      <td>Kehina</td>\n",
       "      <td>MANSERI</td>\n",
       "      <td>Femme</td>\n",
       "      <td>04/12/2001</td>\n",
       "      <td>FR</td>\n",
       "      <td>non</td>\n",
       "      <td>Nanterre</td>\n",
       "      <td>Recherche et Développement (Nanterre)</td>\n",
       "      <td>oui</td>\n",
       "      <td>...</td>\n",
       "      <td>À VOTRE ENNEMI JURÉ !</td>\n",
       "      <td>Parlez et communiquez svp merci</td>\n",
       "      <td>MANSERI</td>\n",
       "      <td>[langages reguliers, gest. info multilinguisme...</td>\n",
       "      <td>[recueil de donnees et statistiques, linguisti...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[corpus paralleles et comparables, statistique...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[seminaire tal et linguistique de corpus, appr...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Maria_Paz_BOTERO</td>\n",
       "      <td>Maria Paz</td>\n",
       "      <td>BOTERO</td>\n",
       "      <td>Femme</td>\n",
       "      <td>24/09/1996</td>\n",
       "      <td>COL</td>\n",
       "      <td>non</td>\n",
       "      <td>Nanterre</td>\n",
       "      <td>Recherche et Développement (Nanterre)</td>\n",
       "      <td>non</td>\n",
       "      <td>...</td>\n",
       "      <td>À votre meilleur copain :&gt;</td>\n",
       "      <td>Il faut être plus inclusif dans les cours, tou...</td>\n",
       "      <td>BOTERO</td>\n",
       "      <td>[langages reguliers, gest. info multilinguisme...</td>\n",
       "      <td>[recueil de donnees et statistiques, morphologie]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[corpus paralleles et comparables, statistique...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[seminaire tal et linguistique de corpus, appr...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Alix_SIRVEN_VIÉNOT</td>\n",
       "      <td>Alix</td>\n",
       "      <td>SIRVEN-VIÉNOT</td>\n",
       "      <td>Femme</td>\n",
       "      <td>08/04/2001</td>\n",
       "      <td>FR</td>\n",
       "      <td>non</td>\n",
       "      <td>Nanterre</td>\n",
       "      <td>Recherche et Développement (Nanterre)</td>\n",
       "      <td>oui</td>\n",
       "      <td>...</td>\n",
       "      <td>À VOTRE ENNEMI JURÉ !</td>\n",
       "      <td>Soyez gentils on douille ici, demandez à vos é...</td>\n",
       "      <td>SIRVEN-VIÉNOT</td>\n",
       "      <td>[langages reguliers, gest. info multilinguisme...</td>\n",
       "      <td>[morphologie, changements linguistiques]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[corpus paralleles et comparables, statistique...</td>\n",
       "      <td>[nlp in english]</td>\n",
       "      <td>[seminaire tal et linguistique de corpus, appr...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Solomiia_ KOROL</td>\n",
       "      <td>Solomiia</td>\n",
       "      <td>KOROL</td>\n",
       "      <td>Femme</td>\n",
       "      <td>19/06/1999</td>\n",
       "      <td>UKR</td>\n",
       "      <td>non</td>\n",
       "      <td>Nanterre</td>\n",
       "      <td>Alternance (Nanterre)</td>\n",
       "      <td>non</td>\n",
       "      <td>...</td>\n",
       "      <td>À votre petite soeur &lt;3</td>\n",
       "      <td>Votre matière n'est pas l'unique dans notre em...</td>\n",
       "      <td>KOROL</td>\n",
       "      <td>[langages reguliers, gest. info multilinguisme...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[corpus paralleles et comparables, statistique...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[annotations semantiques et applications en re...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Yu_ZHANG</td>\n",
       "      <td>Yu</td>\n",
       "      <td>ZHANG</td>\n",
       "      <td>Femme</td>\n",
       "      <td>25/05/2000</td>\n",
       "      <td>CH</td>\n",
       "      <td>non</td>\n",
       "      <td>Nanterre</td>\n",
       "      <td>Recherche et Développement (Nanterre)</td>\n",
       "      <td>non</td>\n",
       "      <td>...</td>\n",
       "      <td>À votre meilleur copain :&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZHANG</td>\n",
       "      <td>[langages reguliers, gest. info multilinguisme...</td>\n",
       "      <td>[morphologie]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[corpus paralleles et comparables, statistique...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[seminaire tal et linguistique de corpus, appr...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Yu_ZHANG</td>\n",
       "      <td>Yu</td>\n",
       "      <td>ZHANG</td>\n",
       "      <td>Femme</td>\n",
       "      <td>25/05/2000</td>\n",
       "      <td>CH</td>\n",
       "      <td>non</td>\n",
       "      <td>Nanterre</td>\n",
       "      <td>Recherche et Développement (Nanterre)</td>\n",
       "      <td>non</td>\n",
       "      <td>...</td>\n",
       "      <td>À votre meilleur copain :&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZHANG</td>\n",
       "      <td>[langages reguliers, gest. info multilinguisme...</td>\n",
       "      <td>[morphologie, changements linguistiques]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[corpus paralleles et comparables, statistique...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[traitement statistique de corpus, genres text...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Manon_GROUVÈS</td>\n",
       "      <td>Manon</td>\n",
       "      <td>GROUVÈS</td>\n",
       "      <td>Femme</td>\n",
       "      <td>15/10/2002</td>\n",
       "      <td>FR</td>\n",
       "      <td>non</td>\n",
       "      <td>Sorbonne-Nouvelle</td>\n",
       "      <td>Alternance (Nanterre)</td>\n",
       "      <td>non</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>essayer de faire évoluer au maximum la maquett...</td>\n",
       "      <td>GROUVÈS</td>\n",
       "      <td>[langages reguliers, gest. info multilinguisme...</td>\n",
       "      <td>[recueil de donnees et statistiques, lexique e...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[corpus paralleles et comparables, statistique...</td>\n",
       "      <td>[khmer]</td>\n",
       "      <td>[annotations semantiques et applications en re...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Keming_YI</td>\n",
       "      <td>Keming</td>\n",
       "      <td>YI</td>\n",
       "      <td>Homme</td>\n",
       "      <td>24/11/1999</td>\n",
       "      <td>CH</td>\n",
       "      <td>non</td>\n",
       "      <td>INALCO</td>\n",
       "      <td>Ingénierie Multilingue (INALCO)</td>\n",
       "      <td>non</td>\n",
       "      <td>...</td>\n",
       "      <td>À personne.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YI</td>\n",
       "      <td>[langages reguliers, gest. info multilinguisme...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[corpus paralleles et comparables, statistique...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[traitement statistique de corpus, genres text...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Xinlei_CHEN</td>\n",
       "      <td>Xinlei</td>\n",
       "      <td>CHEN</td>\n",
       "      <td>Femme</td>\n",
       "      <td>03/04/2001</td>\n",
       "      <td>CH</td>\n",
       "      <td>non</td>\n",
       "      <td>INALCO</td>\n",
       "      <td>Ingénierie Multilingue (INALCO)</td>\n",
       "      <td>non</td>\n",
       "      <td>...</td>\n",
       "      <td>À VOTRE ENNEMI JURÉ !</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHEN</td>\n",
       "      <td>[langages reguliers, gest. info multilinguisme...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[corpus paralleles et comparables, statistique...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[traitement statistique de corpus, genres text...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Lise_BRISSET</td>\n",
       "      <td>Lise</td>\n",
       "      <td>BRISSET</td>\n",
       "      <td>Femme</td>\n",
       "      <td>18/02/2002</td>\n",
       "      <td>FR</td>\n",
       "      <td>non</td>\n",
       "      <td>Sorbonne-Nouvelle</td>\n",
       "      <td>Recherche et Développement (Sorbonne Nouvelle)</td>\n",
       "      <td>non</td>\n",
       "      <td>...</td>\n",
       "      <td>À personne.</td>\n",
       "      <td>De plus discuter entre eux afin qu'ils aient d...</td>\n",
       "      <td>BRISSET</td>\n",
       "      <td>[langages reguliers, gest. info multilinguisme...</td>\n",
       "      <td>[sens multiple, phonetique physiologique et ac...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[corpus paralleles et comparables, statistique...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[apprentissage automatique, modelisation des l...</td>\n",
       "      <td>[traitement statistique de corpus, sociolingui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Nicolas_NGAUV</td>\n",
       "      <td>Nicolas</td>\n",
       "      <td>NGAUV</td>\n",
       "      <td>Homme</td>\n",
       "      <td>14/10/1995</td>\n",
       "      <td>FR</td>\n",
       "      <td>non</td>\n",
       "      <td>INALCO</td>\n",
       "      <td>Ingénierie Multilingue (INALCO)</td>\n",
       "      <td>non</td>\n",
       "      <td>...</td>\n",
       "      <td>À votre meilleur copain :&gt;</td>\n",
       "      <td>Alors, mon conseil c'est</td>\n",
       "      <td>NGAUV</td>\n",
       "      <td>[langages reguliers, gest. info multilinguisme...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[corpus paralleles et comparables, statistique...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[genres textes et usages, semantique des texte...</td>\n",
       "      <td>[fouille de textes 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Melissa_MAHMOUDI</td>\n",
       "      <td>Melissa</td>\n",
       "      <td>MAHMOUDI</td>\n",
       "      <td>Femme</td>\n",
       "      <td>30/09/1999</td>\n",
       "      <td>ALG</td>\n",
       "      <td>non</td>\n",
       "      <td>Nanterre</td>\n",
       "      <td>Alternance (Nanterre)</td>\n",
       "      <td>non</td>\n",
       "      <td>...</td>\n",
       "      <td>À personne.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MAHMOUDI</td>\n",
       "      <td>[langages reguliers, gest. info multilinguisme...</td>\n",
       "      <td>[morphologie, redaction professionnelle]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[corpus paralleles et comparables, statistique...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[annotations semantiques et applications en re...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Yuntian_SHEN</td>\n",
       "      <td>Yuntian</td>\n",
       "      <td>SHEN</td>\n",
       "      <td>Homme</td>\n",
       "      <td>04/03/2001</td>\n",
       "      <td>CH</td>\n",
       "      <td>non</td>\n",
       "      <td>INALCO</td>\n",
       "      <td>Ingénierie Multilingue (INALCO)</td>\n",
       "      <td>non</td>\n",
       "      <td>...</td>\n",
       "      <td>À personne.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SHEN</td>\n",
       "      <td>[langages reguliers, gest. info multilinguisme...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[corpus paralleles et comparables, statistique...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[traitement statistique de corpus, genres text...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Zineb_CHARIKH</td>\n",
       "      <td>Zineb</td>\n",
       "      <td>CHARIKH</td>\n",
       "      <td>Femme</td>\n",
       "      <td>03/10/1996</td>\n",
       "      <td>ALG</td>\n",
       "      <td>non</td>\n",
       "      <td>Nanterre</td>\n",
       "      <td>Alternance (Nanterre)</td>\n",
       "      <td>non</td>\n",
       "      <td>...</td>\n",
       "      <td>À VOTRE ENNEMI JURÉ !</td>\n",
       "      <td>Moins de projets SVP, et pas de présentations</td>\n",
       "      <td>CHARIKH</td>\n",
       "      <td>[langages reguliers, gest. info multilinguisme...</td>\n",
       "      <td>[morphologie, statistiques]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[corpus paralleles et comparables, document st...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[annotations semantiques et applications en re...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Baptiste_GILLET</td>\n",
       "      <td>Baptiste</td>\n",
       "      <td>GILLET</td>\n",
       "      <td>Homme</td>\n",
       "      <td>29/12/2000</td>\n",
       "      <td>FR</td>\n",
       "      <td>non</td>\n",
       "      <td>Nanterre</td>\n",
       "      <td>Alternance (Nanterre)</td>\n",
       "      <td>non</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GILLET</td>\n",
       "      <td>[langages reguliers, gest. info multilinguisme...</td>\n",
       "      <td>[morphologie]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[corpus paralleles et comparables, statistique...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[annotations semantiques et applications en re...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Weiqi_ZHANG</td>\n",
       "      <td>Weiqi</td>\n",
       "      <td>ZHANG</td>\n",
       "      <td>Ne souhaite pas l'indiquer</td>\n",
       "      <td>23/03/1999</td>\n",
       "      <td>CH</td>\n",
       "      <td>non</td>\n",
       "      <td>Nanterre</td>\n",
       "      <td>Ingénierie Multilingue (INALCO)</td>\n",
       "      <td>non</td>\n",
       "      <td>...</td>\n",
       "      <td>À personne.</td>\n",
       "      <td>(State-of-the-trash old teachers who don't hav...</td>\n",
       "      <td>ZHANG</td>\n",
       "      <td>[langages reguliers, gest. info multilinguisme...</td>\n",
       "      <td>[morphologie]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[corpus paralleles et comparables, statistique...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[seminaire tal et linguistique de corpus, appr...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Weiqi_ZHANG</td>\n",
       "      <td>Weiqi</td>\n",
       "      <td>ZHANG</td>\n",
       "      <td>Ne souhaite pas l'indiquer</td>\n",
       "      <td>23/03/1999</td>\n",
       "      <td>CH</td>\n",
       "      <td>non</td>\n",
       "      <td>Nanterre</td>\n",
       "      <td>Ingénierie Multilingue (INALCO)</td>\n",
       "      <td>non</td>\n",
       "      <td>...</td>\n",
       "      <td>À personne.</td>\n",
       "      <td>(State-of-the-trash old teachers who don't hav...</td>\n",
       "      <td>ZHANG</td>\n",
       "      <td>[langages reguliers, gest. info multilinguisme...</td>\n",
       "      <td>[morphologie, changements linguistiques]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[corpus paralleles et comparables, statistique...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[traitement statistique de corpus, genres text...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id          prenom              nom  \\\n",
       "0           Pauline_DÉGEZ         Pauline            DÉGEZ   \n",
       "1       Perrine_QUENNEHEN         Perrine        QUENNEHEN   \n",
       "2           Ashley_RATIER          Ashley           RATIER   \n",
       "3        Valentine_FLEITH      Valentine            FLEITH   \n",
       "4   Débora_VAN_DEN_ZANDE           Débora   VAN-DEN-ZANDE    \n",
       "5       Patricia_AUGUSTYN        Patricia         AUGUSTYN   \n",
       "6    Ioana_Madalina_SILAI  Ioana Madalina            SILAI   \n",
       "7   Marie_DELPORTE_LANDAT           Marie  DELPORTE-LANDAT   \n",
       "8        Florian_PHILIPPE         Florian         PHILIPPE   \n",
       "9           Lydia_BELHOUL           Lydia          BELHOUL   \n",
       "10          Lucile_BESSAC          Lucile           BESSAC   \n",
       "11         Kehina_MANSERI          Kehina          MANSERI   \n",
       "12       Maria_Paz_BOTERO       Maria Paz           BOTERO   \n",
       "13     Alix_SIRVEN_VIÉNOT            Alix    SIRVEN-VIÉNOT   \n",
       "14        Solomiia_ KOROL       Solomiia             KOROL   \n",
       "15               Yu_ZHANG              Yu            ZHANG   \n",
       "16               Yu_ZHANG              Yu            ZHANG   \n",
       "17          Manon_GROUVÈS           Manon          GROUVÈS   \n",
       "18              Keming_YI          Keming               YI   \n",
       "19            Xinlei_CHEN          Xinlei             CHEN   \n",
       "20           Lise_BRISSET            Lise          BRISSET   \n",
       "21          Nicolas_NGAUV         Nicolas            NGAUV   \n",
       "22       Melissa_MAHMOUDI         Melissa         MAHMOUDI   \n",
       "23           Yuntian_SHEN         Yuntian             SHEN   \n",
       "24          Zineb_CHARIKH           Zineb          CHARIKH   \n",
       "25       Baptiste_GILLET         Baptiste          GILLET    \n",
       "26            Weiqi_ZHANG           Weiqi            ZHANG   \n",
       "27            Weiqi_ZHANG           Weiqi            ZHANG   \n",
       "\n",
       "                         genre date_naissance nationalite redoublement  \\\n",
       "0                        Femme     10/04/1988          FR          non   \n",
       "1                        Femme     14/02/1997          FR          non   \n",
       "2                        Femme     24/11/1998          FR          non   \n",
       "3                        Femme     06/07/2001          FR          non   \n",
       "4                        Femme     13/04/2002          FR          non   \n",
       "5                        Femme     22/06/2002          FR          non   \n",
       "6                        Femme     02/10/1995          RO          non   \n",
       "7                        Femme     18/05/2002          FR          non   \n",
       "8                        Homme     12/03/2001          FR          non   \n",
       "9                        Femme     09/08/1988         ALG          non   \n",
       "10                       Femme     21/01/2000          FR          non   \n",
       "11                       Femme     04/12/2001          FR          non   \n",
       "12                       Femme     24/09/1996         COL          non   \n",
       "13                       Femme     08/04/2001          FR          non   \n",
       "14                       Femme     19/06/1999         UKR          non   \n",
       "15                       Femme     25/05/2000          CH          non   \n",
       "16                       Femme     25/05/2000          CH          non   \n",
       "17                       Femme     15/10/2002          FR          non   \n",
       "18                       Homme     24/11/1999          CH          non   \n",
       "19                       Femme     03/04/2001          CH          non   \n",
       "20                       Femme     18/02/2002          FR          non   \n",
       "21                       Homme     14/10/1995          FR          non   \n",
       "22                       Femme     30/09/1999         ALG          non   \n",
       "23                       Homme     04/03/2001          CH          non   \n",
       "24                       Femme     03/10/1996         ALG          non   \n",
       "25                       Homme     29/12/2000          FR          non   \n",
       "26  Ne souhaite pas l'indiquer     23/03/1999          CH          non   \n",
       "27  Ne souhaite pas l'indiquer     23/03/1999          CH          non   \n",
       "\n",
       "       inscription_M1                                     parcours_M2  \\\n",
       "0            Nanterre                           Alternance (Nanterre)   \n",
       "1              INALCO                 Ingénierie Multilingue (INALCO)   \n",
       "2            Nanterre                           Alternance (Nanterre)   \n",
       "3   Sorbonne-Nouvelle                           Alternance (Nanterre)   \n",
       "4   Sorbonne-Nouvelle                           Alternance (Nanterre)   \n",
       "5   Sorbonne-Nouvelle  Recherche et Développement (Sorbonne Nouvelle)   \n",
       "6            Nanterre           Recherche et Développement (Nanterre)   \n",
       "7   Sorbonne-Nouvelle  Recherche et Développement (Sorbonne Nouvelle)   \n",
       "8            Nanterre           Recherche et Développement (Nanterre)   \n",
       "9            Nanterre                           Alternance (Nanterre)   \n",
       "10             INALCO                           Alternance (Nanterre)   \n",
       "11           Nanterre           Recherche et Développement (Nanterre)   \n",
       "12           Nanterre           Recherche et Développement (Nanterre)   \n",
       "13           Nanterre           Recherche et Développement (Nanterre)   \n",
       "14           Nanterre                           Alternance (Nanterre)   \n",
       "15           Nanterre           Recherche et Développement (Nanterre)   \n",
       "16           Nanterre           Recherche et Développement (Nanterre)   \n",
       "17  Sorbonne-Nouvelle                           Alternance (Nanterre)   \n",
       "18             INALCO                 Ingénierie Multilingue (INALCO)   \n",
       "19             INALCO                 Ingénierie Multilingue (INALCO)   \n",
       "20  Sorbonne-Nouvelle  Recherche et Développement (Sorbonne Nouvelle)   \n",
       "21             INALCO                 Ingénierie Multilingue (INALCO)   \n",
       "22           Nanterre                           Alternance (Nanterre)   \n",
       "23             INALCO                 Ingénierie Multilingue (INALCO)   \n",
       "24           Nanterre                           Alternance (Nanterre)   \n",
       "25           Nanterre                           Alternance (Nanterre)   \n",
       "26           Nanterre                 Ingénierie Multilingue (INALCO)   \n",
       "27           Nanterre                 Ingénierie Multilingue (INALCO)   \n",
       "\n",
       "   tiers_temps  ...              recommandation  \\\n",
       "0          non  ...                         NaN   \n",
       "1          non  ...                         NaN   \n",
       "2          non  ...       À VOTRE ENNEMI JURÉ !   \n",
       "3          non  ...                 À personne.   \n",
       "4          non  ...                 À personne.   \n",
       "5          non  ...                 À personne.   \n",
       "6          non  ...                 À personne.   \n",
       "7          non  ...                 À personne.   \n",
       "8          non  ...                 À personne.   \n",
       "9          non  ...  À votre meilleur copain :>   \n",
       "10         non  ...                         NaN   \n",
       "11         oui  ...       À VOTRE ENNEMI JURÉ !   \n",
       "12         non  ...  À votre meilleur copain :>   \n",
       "13         oui  ...       À VOTRE ENNEMI JURÉ !   \n",
       "14         non  ...     À votre petite soeur <3   \n",
       "15         non  ...  À votre meilleur copain :>   \n",
       "16         non  ...  À votre meilleur copain :>   \n",
       "17         non  ...                         NaN   \n",
       "18         non  ...                 À personne.   \n",
       "19         non  ...       À VOTRE ENNEMI JURÉ !   \n",
       "20         non  ...                 À personne.   \n",
       "21         non  ...  À votre meilleur copain :>   \n",
       "22         non  ...                 À personne.   \n",
       "23         non  ...                 À personne.   \n",
       "24         non  ...       À VOTRE ENNEMI JURÉ !   \n",
       "25         non  ...                         NaN   \n",
       "26         non  ...                 À personne.   \n",
       "27         non  ...                 À personne.   \n",
       "\n",
       "                                         conseil_prof   Nom de famille  \\\n",
       "0   Parlez vous pour vous coordonner (surtout quan...            DÉGEZ   \n",
       "1                                                 NaN        QUENNEHEN   \n",
       "2                                                 NaN           RATIER   \n",
       "3                                   Fermez le master            FLEITH   \n",
       "4                        EMBAUCHEZ DES GENS QUALIFIES   VAN-DEN-ZANDE    \n",
       "5   De communiquer davantage entre vous, surtout e...         AUGUSTYN   \n",
       "6   Perdez moins de temps dans les cours, préparez...            SILAI   \n",
       "7   7 notes pour un cours c'est peut-être un peu b...  DELPORTE-LANDAT   \n",
       "8   Savoir reconnaître quand on n'a pas les compét...         PHILIPPE   \n",
       "9                  Pètez un coup ça vous fera du bien          BELHOUL   \n",
       "10  Prendre le temps, à chaque début de cours (1er...           BESSAC   \n",
       "11                    Parlez et communiquez svp merci          MANSERI   \n",
       "12  Il faut être plus inclusif dans les cours, tou...           BOTERO   \n",
       "13  Soyez gentils on douille ici, demandez à vos é...    SIRVEN-VIÉNOT   \n",
       "14  Votre matière n'est pas l'unique dans notre em...            KOROL   \n",
       "15                                                NaN            ZHANG   \n",
       "16                                                NaN            ZHANG   \n",
       "17  essayer de faire évoluer au maximum la maquett...          GROUVÈS   \n",
       "18                                                NaN               YI   \n",
       "19                                                NaN             CHEN   \n",
       "20  De plus discuter entre eux afin qu'ils aient d...          BRISSET   \n",
       "21                          Alors, mon conseil c'est             NGAUV   \n",
       "22                                                NaN         MAHMOUDI   \n",
       "23                                                NaN             SHEN   \n",
       "24     Moins de projets SVP, et pas de présentations           CHARIKH   \n",
       "25                                                NaN          GILLET    \n",
       "26  (State-of-the-trash old teachers who don't hav...            ZHANG   \n",
       "27  (State-of-the-trash old teachers who don't hav...            ZHANG   \n",
       "\n",
       "                             normalised_m1_s1_courses  \\\n",
       "0   [langages reguliers, gest. info multilinguisme...   \n",
       "1   [langages reguliers, gest. info multilinguisme...   \n",
       "2   [langages reguliers, gest. info multilinguisme...   \n",
       "3   [langages reguliers, gest. info multilinguisme...   \n",
       "4   [langages reguliers, gest. info multilinguisme...   \n",
       "5   [langages reguliers, gest. info multilinguisme...   \n",
       "6   [langages reguliers, gest. info multilinguisme...   \n",
       "7   [langages reguliers, gest. info multilinguisme...   \n",
       "8   [langages reguliers, gest. info multilinguisme...   \n",
       "9   [langages reguliers, gest. info multilinguisme...   \n",
       "10  [langages reguliers, gest. info multilinguisme...   \n",
       "11  [langages reguliers, gest. info multilinguisme...   \n",
       "12  [langages reguliers, gest. info multilinguisme...   \n",
       "13  [langages reguliers, gest. info multilinguisme...   \n",
       "14  [langages reguliers, gest. info multilinguisme...   \n",
       "15  [langages reguliers, gest. info multilinguisme...   \n",
       "16  [langages reguliers, gest. info multilinguisme...   \n",
       "17  [langages reguliers, gest. info multilinguisme...   \n",
       "18  [langages reguliers, gest. info multilinguisme...   \n",
       "19  [langages reguliers, gest. info multilinguisme...   \n",
       "20  [langages reguliers, gest. info multilinguisme...   \n",
       "21  [langages reguliers, gest. info multilinguisme...   \n",
       "22  [langages reguliers, gest. info multilinguisme...   \n",
       "23  [langages reguliers, gest. info multilinguisme...   \n",
       "24  [langages reguliers, gest. info multilinguisme...   \n",
       "25  [langages reguliers, gest. info multilinguisme...   \n",
       "26  [langages reguliers, gest. info multilinguisme...   \n",
       "27  [langages reguliers, gest. info multilinguisme...   \n",
       "\n",
       "                           normalised_m1_s1_optionnal normalised_m1_s1_extra  \\\n",
       "0   [recueil de donnees et statistiques, morphologie]                     []   \n",
       "1                                                  []                     []   \n",
       "2   [morphologie, recueil de donnees et statistiques]                     []   \n",
       "3   [recueil de donnees et statistiques, morphologie]                     []   \n",
       "4   [morphologie, recueil de donnees et statistiques]                     []   \n",
       "5   [sociolinguistique, phonetique physiologique e...                     []   \n",
       "6   [large corpus linguistics, langues vivantes et...                     []   \n",
       "7   [recueil de donnees et statistiques, phonetiqu...                     []   \n",
       "8   [morphologie, recueil de donnees et statistiques]                     []   \n",
       "9   [morphologie, recueil de donnees et statistiques]                     []   \n",
       "10                      [langues vivantes etrangeres]                     []   \n",
       "11  [recueil de donnees et statistiques, linguisti...                     []   \n",
       "12  [recueil de donnees et statistiques, morphologie]                     []   \n",
       "13           [morphologie, changements linguistiques]                     []   \n",
       "14                                                 []                     []   \n",
       "15                                      [morphologie]                     []   \n",
       "16           [morphologie, changements linguistiques]                     []   \n",
       "17  [recueil de donnees et statistiques, lexique e...                     []   \n",
       "18                                                 []                     []   \n",
       "19                                                 []                     []   \n",
       "20  [sens multiple, phonetique physiologique et ac...                     []   \n",
       "21                                                 []                     []   \n",
       "22           [morphologie, redaction professionnelle]                     []   \n",
       "23                                                 []                     []   \n",
       "24                        [morphologie, statistiques]                     []   \n",
       "25                                      [morphologie]                     []   \n",
       "26                                      [morphologie]                     []   \n",
       "27           [morphologie, changements linguistiques]                     []   \n",
       "\n",
       "                             normalised_m1_s2_courses normalised_m1_s2_extra  \\\n",
       "0   [corpus paralleles et comparables, statistique...                     []   \n",
       "1   [corpus paralleles et comparables, statistique...                     []   \n",
       "2   [corpus paralleles et comparables, statistique...                     []   \n",
       "3   [corpus paralleles et comparables, statistique...                     []   \n",
       "4   [corpus paralleles et comparables, statistique...               [coreen]   \n",
       "5   [corpus paralleles et comparables, statistique...             [polonais]   \n",
       "6   [corpus paralleles et comparables, statistique...                     []   \n",
       "7   [corpus paralleles et comparables, statistique...                     []   \n",
       "8   [corpus paralleles et comparables, document st...       [nlp in english]   \n",
       "9   [corpus paralleles et comparables, statistique...                     []   \n",
       "10  [corpus paralleles et comparables, statistique...                     []   \n",
       "11  [corpus paralleles et comparables, statistique...                     []   \n",
       "12  [corpus paralleles et comparables, statistique...                     []   \n",
       "13  [corpus paralleles et comparables, statistique...       [nlp in english]   \n",
       "14  [corpus paralleles et comparables, statistique...                     []   \n",
       "15  [corpus paralleles et comparables, statistique...                     []   \n",
       "16  [corpus paralleles et comparables, statistique...                     []   \n",
       "17  [corpus paralleles et comparables, statistique...                [khmer]   \n",
       "18  [corpus paralleles et comparables, statistique...                     []   \n",
       "19  [corpus paralleles et comparables, statistique...                     []   \n",
       "20  [corpus paralleles et comparables, statistique...                     []   \n",
       "21  [corpus paralleles et comparables, statistique...                     []   \n",
       "22  [corpus paralleles et comparables, statistique...                     []   \n",
       "23  [corpus paralleles et comparables, statistique...                     []   \n",
       "24  [corpus paralleles et comparables, document st...                     []   \n",
       "25  [corpus paralleles et comparables, statistique...                     []   \n",
       "26  [corpus paralleles et comparables, statistique...                     []   \n",
       "27  [corpus paralleles et comparables, statistique...                     []   \n",
       "\n",
       "                             normalised_m2_s1_courses  \\\n",
       "0   [annotations semantiques et applications en re...   \n",
       "1   [traitement statistique de corpus, genres text...   \n",
       "2   [annotations semantiques et applications en re...   \n",
       "3   [annotations semantiques et applications en re...   \n",
       "4   [annotations semantiques et applications en re...   \n",
       "5   [apprentissage automatique, modelisation des l...   \n",
       "6   [seminaire tal et linguistique de corpus, appr...   \n",
       "7   [apprentissage automatique, modelisation des l...   \n",
       "8   [seminaire tal et linguistique de corpus, appr...   \n",
       "9   [annotations semantiques et applications en re...   \n",
       "10  [annotations semantiques et applications en re...   \n",
       "11  [seminaire tal et linguistique de corpus, appr...   \n",
       "12  [seminaire tal et linguistique de corpus, appr...   \n",
       "13  [seminaire tal et linguistique de corpus, appr...   \n",
       "14  [annotations semantiques et applications en re...   \n",
       "15  [seminaire tal et linguistique de corpus, appr...   \n",
       "16  [traitement statistique de corpus, genres text...   \n",
       "17  [annotations semantiques et applications en re...   \n",
       "18  [traitement statistique de corpus, genres text...   \n",
       "19  [traitement statistique de corpus, genres text...   \n",
       "20  [apprentissage automatique, modelisation des l...   \n",
       "21  [genres textes et usages, semantique des texte...   \n",
       "22  [annotations semantiques et applications en re...   \n",
       "23  [traitement statistique de corpus, genres text...   \n",
       "24  [annotations semantiques et applications en re...   \n",
       "25  [annotations semantiques et applications en re...   \n",
       "26  [seminaire tal et linguistique de corpus, appr...   \n",
       "27  [traitement statistique de corpus, genres text...   \n",
       "\n",
       "                               normalised_m2_s1_extra  \n",
       "0                                                  []  \n",
       "1                                                  []  \n",
       "2                                                  []  \n",
       "3                                                  []  \n",
       "4                                                  []  \n",
       "5                  [traitement statistique de corpus]  \n",
       "6                                                  []  \n",
       "7                                                  []  \n",
       "8                                                  []  \n",
       "9                                                  []  \n",
       "10                                                 []  \n",
       "11                                                 []  \n",
       "12                                                 []  \n",
       "13                                                 []  \n",
       "14                                                 []  \n",
       "15                                                 []  \n",
       "16                                                 []  \n",
       "17                                                 []  \n",
       "18                                                 []  \n",
       "19                                                 []  \n",
       "20  [traitement statistique de corpus, sociolingui...  \n",
       "21                              [fouille de textes 1]  \n",
       "22                                                 []  \n",
       "23                                                 []  \n",
       "24                                                 []  \n",
       "25                                                 []  \n",
       "26                                                 []  \n",
       "27                                                 []  \n",
       "\n",
       "[28 rows x 49 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eleves_avec_cours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_formulaire = pd.read_csv(\"formulaire_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Horodateur', 'Score', 'Nom de famille', 'Prénom', 'Genre',\n",
      "       'Date de naissance', 'Nationalité',\n",
      "       'Avez-vous redoublé le master ? Si oui, indiquez quelle année et quel niveau. ',\n",
      "       'Dans quelle université étiez-vous inscrits au M1 ? ',\n",
      "       'Dans quel parcours êtes-vous inscrits au M2 ?',\n",
      "       'Disposez vous ou avez-vous disposé d'un aménagement handicap pour le master (tiers-temps, autres...) ?',\n",
      "       'Si vous êtes inscrits (ou avez été inscrits) dans un autre établissement pendant le master, indiquez lequel :\\n\\nExemple :\\nÉtudiant en M2 TAL Ingénierie Multilingue et à 42 en même temps.',\n",
      "       'Si vous avez obtenu un baccalauréat français, quelle était votre filière : ',\n",
      "       'Indiquez si cette licence appartient à l'une des mentions suivantes :',\n",
      "       'Avez-vous déjà un master ?\\nSi oui, veuillez indiquer son nom original (langue d'origine) au format :\\nNOM, UNIVERSITÉ\\n\\nExemple:\\nMaster Linguistique Anglaise, Université Sorbonne Nouvelle',\n",
      "       'Si vous travaillez (ou avez travaillé) pendant le master, indiquez sur quel poste (hors stage TAL) :\\n\\nExemple :\\nActuellement employé polyvalent à Décathlon.',\n",
      "       'Si vous avez exercé une activité professionnelle de longue durée avant le master (reconversion, reprise d'études ou autres), indiquez laquelle :\\n\\nExemple:\\nProfesseure à l'alliance française de Bogotá. ',\n",
      "       'Avez-vous eu un premier stage en NLP pendant le M1 ?',\n",
      "       'Si oui, étiez-vous en entreprise, laboratoire, ou autre ?1',\n",
      "       'Quel était le nom de l'organisme d'accueil ?1',\n",
      "       'Quelle était la durée du stage ?1', 'Quel était le sujet du stage ?1',\n",
      "       'Si votre tuteur de stage était un enseignant du master, indiquez lequel :1',\n",
      "       'Avez-vous eu un second stage en NLP pendant le M1 ?',\n",
      "       'Si oui, étiez-vous en entreprise, laboratoire, ou autre ?2',\n",
      "       'Quel était le nom de l'organisme d'accueil ?2',\n",
      "       'Quelle était la durée du stage ?2', 'Quel était le sujet du stage ?2',\n",
      "       'Si votre tuteur de stage était un enseignant du master, indiquez lequel :2',\n",
      "       'Avez-vous eu un stage en NLP pendant le M2 (hors celui du second semestre à venir) ?',\n",
      "       'Si oui, étiez-vous en entreprise, laboratoire, ou autre ?3',\n",
      "       'Quel était le nom de l'organisme d'accueil  ?3',\n",
      "       'Quelle était la durée du stage ?3', 'Quel était le sujet du stage ?3',\n",
      "       'Si votre tuteur de stage était un enseignant du master, indiquez lequel :3',\n",
      "       'Si vous deviez noter votre expérience globale de stagiaire, quelle notre mettriez vous ? \\nStage M1 numéro 1',\n",
      "       'Si vous deviez noter votre expérience globale de stagiaire, quelle notre mettriez vous ? \\nStage M1 numéro 2',\n",
      "       'Si vous deviez noter votre expérience globale de stagiaire, quelle notre mettriez vous ? \\nStage M2',\n",
      "       'Pour les M2 en parcours recherche, IM ou TETRADOM, avez-vous déjà trouvé un stage ?',\n",
      "       'Si oui, serez-vous en entreprise, laboratoire ou autre ?',\n",
      "       'Quel est le nom de l'organisme d'accueil ?',\n",
      "       'Quelle sera la durée du stage ?',\n",
      "       'Pour les M2 en parcours recherche, le sujet de votre mémoire est-il lié à votre stage de M2 ?',\n",
      "       'Pour les M2 en parcours recherche, si vous le connaissez déjà, quel est le sujet de votre mémoire ?',\n",
      "       'Pour les M2 en parcours recherche, si vous les connaissez déjà, qui sont vos directeurs de mémoire ? ',\n",
      "       'Pour les M2 en parcours alternance, avez-vous trouvé une alternance, un stage, ou autre ?',\n",
      "       'Pour les M2 en parcours alternance ayant trouvé une alternance, dans quel organisme êtes-vous ?',\n",
      "       'Quelle sont vos missions ?',\n",
      "       'Pour les M2 en parcours alternance ayant trouvé un stage, dans quel organisme êtes-vous/serez-vous ?',\n",
      "       'Quelle est/sera la durée du stage ?',\n",
      "       'Quelles sont/seront vos missions ?',\n",
      "       'Quels cours avez-vous suivis au premier semestre du M1 ?',\n",
      "       'Quelles ont été vos options de linguistique au premier semestre du M1 ?\\nSéparer les cours par des virgules. ',\n",
      "       'Avons-nous oublié quelque cours au premier semestre du M1 ? Indiquez-le ici !\\nSéparez les cours par des virgules. ',\n",
      "       'Quels cours avez-vous suivis au second semestre du M1 ?',\n",
      "       'Avons-nous oublié quelque cours au second semestre du M1 ? Indiquez-le ici !\\nSéparez les cours par des virgules. ',\n",
      "       'Quels cours avez-vous suivis au premier semestre du M2 ?',\n",
      "       'Avons-nous oublié quelque cours au premier semestre du M2 ? Indiquez-le ici !\\nSéparez les cours par des virgules. ',\n",
      "       'Quels sont vos sujets préférés en cours ? ',\n",
      "       'Quelle(s) modalité(s) d'évaluation préférez-vous ?',\n",
      "       'Quel aspect aimeriez-vous voir plus mis en avant pendant le master ? Ça peut être un sujet en particulier, des compétences spécifiques ou autre.',\n",
      "       'Qui est votre ennemi juré dans le master parmi les élèves (soyez pas sérieux c'est pour rigoler) ? ',\n",
      "       'Sur combien notez-vous votre santé mentale avant le master ?',\n",
      "       'Sur combien notez-vous votre santé mentale après le master ? ',\n",
      "       'À quelle fréquence pleurez-vous à cause du master ?\\nex: x/mois ou x/semaine ou x/jour ...',\n",
      "       'Combien d'heures par nuit dormez-vous en moyenne ?',\n",
      "       'Sur combien notez-vous la difficulté du M1 ?',\n",
      "       'Sur combien notez-vous la difficulté du M2 parcours Recherche et Développement ?',\n",
      "       'Sur combien notez-vous la difficulté du M2 parcours Alternance ?',\n",
      "       'Sur combien notez-vous la difficulté du M2 parcours Ingénierie Multilingue ?',\n",
      "       'Sur combien notez-vous la difficulté du M2 parcours Technologies de la Traduction et Traitement des Données Multilingues ?',\n",
      "       'Pour les adeptes de Linux, voulez-vous régulièrement jeter votre ordinateur par la fenêtre ?',\n",
      "       'Pour les adeptes de Mac, voulez-vous régulièrement jeter votre ordinateur par la fenêtre ?',\n",
      "       'Si vous deviez élire le meilleur cours de tout le master, lequel choisiriez-vous ? ',\n",
      "       'Pour les étudiants de Nanterre, sur combien notez-vous l'efficacité de votre administration ?',\n",
      "       'Pour les étudiants de la Sorbonne-Nouvelle, sur combien notez-vous l'efficacité de votre administration ?',\n",
      "       'Pour les étudiants de l'INALCO, sur combien notez-vous l'efficacité de votre administration ?',\n",
      "       'Quel conseil donneriez-vous aux futurs élèves pour survivre au master TAL ?',\n",
      "       'À qui recommanderiez-vous le master TAL ?',\n",
      "       'Quel conseil donneriez-vous aux professeurs du master TAL ? ',\n",
      "       'Avez-vous eu une expérience professionnelle en lien avec le master pendant le M1 ou le M2 ? (hors alternance et stage)',\n",
      "       'Quel était le nom de l'organisme employeur ?',\n",
      "       'Quel était le type de contrat ? ', 'Quelles étaient vos missions ?',\n",
      "       'Si vous avez répondu à la question précédente et que votre diplôme est étranger, veuillez indiquer sous le même format un nom équivalent en français.\\n\\nExemple :\\nSi vous avez répondu Master in social studies, Cambridge University à la question précédente.\\n\\nVeuillez ici répondre :\\nMaster en Sciences Sociales, Université de Cambridge',\n",
      "       'Indiquez si ce master appartient à une des mentions suivantes : ',\n",
      "       'Si vous avez obtenu un autre type de diplôme (hors licence et master), indiquez son nom original (langue d'origine) au format :\\nNOM, ÉTABLISSEMENT\\n\\nExemple:\\nBTS en communication, Lycée Paul Eluard, Saint-Denis',\n",
      "       'Avez-vous déjà une licence ?\\nSi oui, veuillez indiquer son nom original (langue d'origine) au format :\\nNOM, UNIVERSITÉ\\n\\nExemple:\\nLicence en biologie, Université Paris Saclay',\n",
      "       'Si vous avez répondu à la question précédente et que votre diplôme est étranger, veuillez indiquer sous le même format un nom équivalent en français.\\n\\nExemple :\\nSi vous avez répondu Bachelor in social studies, Cambridge University à la question précédente.\\n\\nVeuillez ici répondre :\\nLicence en Sciences Sociales, Université de Cambridge',\n",
      "       'Si vous avez répondu à la question précédente et que votre diplôme est étranger, veuillez indiquer sous le même format un nom équivalent en français.\\n\\nExemple :\\nSi vous avez répondu NVQ hairstylist, Freddie Mercury High School, Cambridge à la question précédente.\\n\\nVeuillez ici répondre :\\nCAP coiffure, Lycée Freddie Mercury, Cambridge',\n",
      "       'Colonne 84', 'normalised_m1_s1_courses', 'normalised_m1_s1_optionnal',\n",
      "       'normalised_m1_s1_extra', 'normalised_m1_s2_courses',\n",
      "       'normalised_m1_s2_extra', 'normalised_m2_s1_courses',\n",
      "       'normalised_m2_s1_extra'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_formulaire.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Quel était le nom de l'organisme d'accueil ?3\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Downloads/yes/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Quel était le nom de l'organisme d'accueil ?3\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m m_2_1 \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOui\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     41\u001b[0m     dico_stages[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstages_m2_type_orga\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(df_formulaire[df_formulaire[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrénom\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m nom][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSi oui, étiez-vous en entreprise, laboratoire, ou autre ?3\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m---> 42\u001b[0m     dico_stages[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstages_m2_nom_orga\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(df_formulaire[df_formulaire[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrénom\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m nom][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuel était le nom de l\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morganisme d\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccueil ?3\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     43\u001b[0m     dico_stages[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstages_m2_duree\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(df_formulaire[df_formulaire[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrénom\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m nom][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuelle était la durée du stage ?3\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     44\u001b[0m     dico_stages[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstages_m2_sujet\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(df_formulaire[df_formulaire[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrénom\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m nom][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuel était le sujet du stage ?3\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/Downloads/yes/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Downloads/yes/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Quel était le nom de l'organisme d'accueil ?3\""
     ]
    }
   ],
   "source": [
    "### go pas prendre en compte les deuxièmes stages pour l'instant\n",
    "\n",
    "dico_stages = defaultdict(list)\n",
    "\n",
    "dico_stages[\"id_eleves\"] = df_eleves_avec_cours[\"id\"].to_list()\n",
    "dico_stages[\"nom_eleves\"] = df_eleves_avec_cours[\"nom\"].to_list()\n",
    "dico_stages[\"prenom_eleves\"] = df_eleves_avec_cours[\"prenom\"].to_list()\n",
    "\n",
    "for nom in dico_stages[\"prenom_eleves\"]:\n",
    "\n",
    "    m_1_1 = df_formulaire[df_formulaire[\"Prénom\"] == nom][\"Avez-vous eu un premier stage en NLP pendant le M1 ?\"].values[0]\n",
    "    m_1_2 = df_formulaire[df_formulaire[\"Prénom\"] == nom][\"Avez-vous eu un second stage en NLP pendant le M1 ?\"].values[0]\n",
    "\n",
    "    if m_1_1 == \"Oui\" and m_1_2 == \"Oui\":\n",
    "        dico_stages[\"stages_m1_type_orga\"].append([df_formulaire[df_formulaire[\"Prénom\"] == nom][\"Si oui, étiez-vous en entreprise, laboratoire, ou autre ?1\"].values[0], df_formulaire[df_formulaire[\"Prénom\"] == nom][\"Si oui, étiez-vous en entreprise, laboratoire, ou autre ?2\"].values[0]])\n",
    "        dico_stages[\"stages_m1_nom_orga\"].append([df_formulaire[df_formulaire[\"Prénom\"] == nom][\"Quel était le nom de l'organisme d'accueil ?1\"].values[0], df_formulaire[df_formulaire[\"Prénom\"] == nom][\"Quel était le nom de l'organisme d'accueil ?2\"].values[0]])\n",
    "        dico_stages[\"stages_m1_duree\"].append([df_formulaire[df_formulaire[\"Prénom\"] == nom][\"Quelle était la durée du stage ?1\"].values[0], df_formulaire[df_formulaire[\"Prénom\"] == nom][\"Quelle était la durée du stage ?2\"].values[0]])\n",
    "        dico_stages[\"stages_m1_sujet\"].append([df_formulaire[df_formulaire[\"Prénom\"] == nom][\"Quel était le sujet du stage ?1\"].values[0], df_formulaire[df_formulaire[\"Prénom\"] == nom][\"Quel était le sujet du stage ?2\"].values[0]])\n",
    "        dico_stages[\"stages_m1_tuteur\"].append([df_formulaire[df_formulaire[\"Prénom\"] == nom][\"Si votre tuteur de stage était un enseignant du master, indiquez lequel :1\"].values[0], df_formulaire[df_formulaire[\"Prénom\"] == nom][\"Si votre tuteur de stage était un enseignant du master, indiquez lequel :2\"].values[0]])\n",
    "        dico_stages[\"stages_m1_note\"].append([df_formulaire[df_formulaire[\"Prénom\"] == nom][\"Si vous deviez noter votre expérience globale de stagiaire, quelle notre mettriez vous ? \\nStage M1 numéro 1\"].values[0], df_formulaire[df_formulaire[\"Prénom\"] == nom][\"Si vous deviez noter votre expérience globale de stagiaire, quelle notre mettriez vous ? \\nStage M1 numéro 2\"].values[0]])\n",
    "    \n",
    "    if m_1_1 == \"Oui\" and m_1_2 == \"Non\":\n",
    "        dico_stages[\"stages_m1_type_orga\"].append(df_formulaire[df_formulaire[\"Prénom\"] == nom][\"Si oui, étiez-vous en entreprise, laboratoire, ou autre ?1\"].values[0])\n",
    "        dico_stages[\"stages_m1_nom_orga\"].append(df_formulaire[df_formulaire[\"Prénom\"] == nom][\"Quel était le nom de l'organisme d'accueil ?1\"].values[0])\n",
    "        dico_stages[\"stages_m1_duree\"].append(df_formulaire[df_formulaire[\"Prénom\"] == nom][\"Quelle était la durée du stage ?1\"].values[0])\n",
    "        dico_stages[\"stages_m1_sujet\"].append(df_formulaire[df_formulaire[\"Prénom\"] == nom][\"Quel était le sujet du stage ?1\"].values[0])\n",
    "        dico_stages[\"stages_m1_tuteur\"].append(df_formulaire[df_formulaire[\"Prénom\"] == nom][\"Si votre tuteur de stage était un enseignant du master, indiquez lequel :1\"].values[0])\n",
    "        dico_stages[\"stages_m1_note\"].append(df_formulaire[df_formulaire[\"Prénom\"] == nom][\"Si vous deviez noter votre expérience globale de stagiaire, quelle notre mettriez vous ? \\nStage M1 numéro 1\"].values[0])\n",
    "    \n",
    "    else:\n",
    "        dico_stages[\"stages_m1_type_orga\"].append(None)\n",
    "        dico_stages[\"stages_m1_nom_orga\"].append(None)\n",
    "        dico_stages[\"stages_m1_duree\"].append(None)\n",
    "        dico_stages[\"stages_m1_sujet\"].append(None)\n",
    "        dico_stages[\"stages_m1_tuteur\"].append(None)\n",
    "        dico_stages[\"stages_m1_note\"].append(None)\n",
    "\n",
    "    m_2_1 = df_formulaire[df_formulaire[\"Prénom\"] == nom][\"Avez-vous eu un stage en NLP pendant le M2 (hors celui du second semestre à venir) ?\"].values[0]\n",
    "\n",
    "    if m_2_1 == \"Oui\":\n",
    "        dico_stages[\"stages_m2_type_orga\"].append(df_formulaire[df_formulaire[\"Prénom\"] == nom][\"Si oui, étiez-vous en entreprise, laboratoire, ou autre ?3\"].values[0])\n",
    "        dico_stages[\"stages_m2_nom_orga\"].append(df_formulaire[df_formulaire[\"Prénom\"] == nom][\"Quel était le nom de l'organisme d'accueil  ?3\"].values[0])\n",
    "        dico_stages[\"stages_m2_duree\"].append(df_formulaire[df_formulaire[\"Prénom\"] == nom][\"Quelle était la durée du stage ?3\"].values[0])\n",
    "        dico_stages[\"stages_m2_sujet\"].append(df_formulaire[df_formulaire[\"Prénom\"] == nom][\"Quel était le sujet du stage ?3\"].values[0])\n",
    "        dico_stages[\"stages_m2_tuteur\"].append(df_formulaire[df_formulaire[\"Prénom\"] == nom][\"Si votre tuteur de stage était un enseignant du master, indiquez lequel :3\"].values[0])\n",
    "        dico_stages[\"stages_m2_note\"].append(df_formulaire[df_formulaire[\"Prénom\"] == nom][\"Si vous deviez noter votre expérience globale de stagiaire, quelle notre mettriez vous ? \\nStage M2\"].values[0])\n",
    "\n",
    "    else:\n",
    "        dico_stages[\"stages_m2_type_orga\"].append(None)\n",
    "        dico_stages[\"stages_m2_nom_orga\"].append(None)\n",
    "        dico_stages[\"stages_m2_duree\"].append(None)\n",
    "        dico_stages[\"stages_m2_sujet\"].append(None)\n",
    "        dico_stages[\"stages_m2_tuteur\"].append(None)\n",
    "        dico_stages[\"stages_m2_note\"].append(None)\n",
    "\n",
    "    m2_tetrarechim = df_formulaire[df_formulaire[\"Prénom\"] == nom][\"Pour les M2 en parcours recherche, IM ou TETRADOM, avez-vous déjà trouvé un stage ?\"].values[0]\n",
    "\n",
    "    if m2_tetrarechim == \"Oui\":\n",
    "        dico_stages[\"stages_m2_tetrarechim_type_orga\"].append(df_formulaire[df_formulaire[\"Prénom\"] == nom][\"Si oui, serez-vous en entreprise, laboratoire ou autre ?\"].values[0])\n",
    "        dico_stages[\"stages_m2_tetrarechim_nom_orga\"].append(df_formulaire[df_formulaire[\"Prénom\"] == nom][\"Quel est le nom de l'organisme d'accueil ?\"].values[0])\n",
    "        dico_stages[\"stages_m2_tetrarechim_duree\"].append(df_formulaire[df_formulaire[\"Prénom\"] == nom][\"Quelle sera la durée du stage ?\"].values[0])\n",
    "        dico_stages[\"stages_m2_tetrarechim_sujet\"].append(df_formulaire[df_formulaire[\"Prénom\"] == nom][\"Pour les M2 en parcours recherche, le sujet de votre mémoire est-il lié à votre stage de M2 ?\"].values[0])\n",
    "        dico_stages[\"stages_m2_tetrarechim_memoire\"].append(df_formulaire[df_formulaire[\"Prénom\"] == nom][\"Pour les M2 en parcours recherche, si vous le connaissez déjà, quel est le sujet de votre mémoire ?\"].values[0])\n",
    "        dico_stages[\"stages_m2_tetrarechim_tuteur\"].append(df_formulaire[df_formulaire[\"Prénom\"] == nom][\"Pour les M2 en parcours recherche, si vous les connaissez déjà, qui sont vos directeurs de mémoire ? \"].values[0])\n",
    "\n",
    "    else:\n",
    "\n",
    "        dico_stages[\"stages_m2_tetrarechim_type_orga\"].append(None)\n",
    "        dico_stages[\"stages_m2_tetrarechim_nom_orga\"].append(None)\n",
    "        dico_stages[\"stages_m2_tetrarechim_duree\"].append(None)\n",
    "        dico_stages[\"stages_m2_tetrarechim_sujet\"].append(None)\n",
    "        dico_stages[\"stages_m2_tetrarechim_memoire\"].append(None)\n",
    "        dico_stages[\"stages_m2_tetrarechim_tuteur\"].append(None)\n",
    "\n",
    "\n",
    "    m2_alternance = df_formulaire[df_formulaire[\"Prénom\"] == nom][\"Pour les M2 en parcours alternance, avez-vous trouvé une alternance, un stage, ou autre ?\"].values[0]    \n",
    "\n",
    "    if m2_alternance == \"Stage\" or m2_alternance == \"Alternance\":\n",
    "        dico_stages[\"stages_m2_alternance_contrat\"].append(df_formulaire[df_formulaire[\"Prénom\"] == nom][\"Pour les M2 en parcours alternance, avez-vous trouvé une alternance, un stage, ou autre ?\"].values[0])\n",
    "        \n",
    "        if m2_alternance == \"Stage\":\n",
    "            dico_stages[\"stages_m2_alternance_type_org_stage\"].append(df_formulaire[df_formulaire[\"Prénom\"] == nom][\"Pour les M2 en parcours alternance ayant trouvé un stage, dans quel organisme êtes-vous/serez-vous ?\"].values[0])\n",
    "            dico_stages[\"stages_m2_alternance_duree_stage\"].append(df_formulaire[df_formulaire[\"Prénom\"] == nom][\"Quelle est/sera la durée du stage ?\"].values[0])\n",
    "            dico_stages[\"stages_m2_alternance_missions_stage\"].append(df_formulaire[df_formulaire[\"Prénom\"] == nom][\"Quelles sont/seront vos missions ?\"].values[0])\n",
    "            dico_stages[\"stages_m2_alternance_type_org_alt\"].append(None)\n",
    "            dico_stages[\"stages_m2_alternance_missions_alt\"].append(None)\n",
    "\n",
    "        if m2_alternance == \"Alternance\":\n",
    "            dico_stages[\"stages_m2_alternance_type_org_alt\"].append(df_formulaire[df_formulaire[\"Prénom\"] == nom][\"Pour les M2 en parcours alternance ayant trouvé une alternance, dans quel organisme êtes-vous ?\"].values[0])\n",
    "            dico_stages[\"stages_m2_alternance_missions_alt\"].append(df_formulaire[df_formulaire[\"Prénom\"] == nom][\"Quelle sont vos missions ?\"].values[0])\n",
    "            dico_stages[\"stages_m2_alternance_type_org_stage\"].append(None)\n",
    "            dico_stages[\"stages_m2_alternance_duree_stage\"].append(None)\n",
    "            dico_stages[\"stages_m2_alternance_missions_stage\"].append(None)\n",
    "    \n",
    "    else:\n",
    "        dico_stages[\"stages_m2_alternance_contrat\"].append(None)\n",
    "        dico_stages[\"stages_m2_alternance_type_org_stage\"].append(None)\n",
    "        dico_stages[\"stages_m2_alternance_duree_stage\"].append(None)\n",
    "        dico_stages[\"stages_m2_alternance_missions_stage\"].append(None)\n",
    "        dico_stages[\"stages_m2_alternance_type_org_alt\"].append(None)\n",
    "        dico_stages[\"stages_m2_alternance_missions_alt\"].append(None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_eleves 28\n",
      "nom_eleves 28\n",
      "prenom_eleves 28\n",
      "stages_m1_type_orga 30\n",
      "stages_m1_nom_orga 30\n",
      "stages_m1_duree 30\n",
      "stages_m1_sujet 30\n",
      "stages_m1_tuteur 30\n",
      "stages_m1_note 30\n",
      "stages_m2_type_orga 28\n",
      "stages_m2_nom_orga 28\n",
      "stages_m2_duree 28\n",
      "stages_m2_sujet 28\n",
      "stages_m2_tuteur 28\n",
      "stages_m2_note 28\n",
      "stages_m2_tetrarechim_type_orga 28\n",
      "stages_m2_tetrarechim_nom_orga 28\n",
      "stages_m2_tetrarechim_duree 28\n",
      "stages_m2_tetrarechim_sujet 28\n",
      "stages_m2_tetrarechim_memoire 28\n",
      "stages_m2_tetrarechim_tuteur 28\n",
      "stages_m2_alternance_contrat 28\n",
      "stages_m2_alternance_type_org_stage 28\n",
      "stages_m2_alternance_duree_stage 28\n",
      "stages_m2_alternance_missions_stage 28\n",
      "stages_m2_alternance_type_org_alt 28\n",
      "stages_m2_alternance_missions_alt 28\n",
      "id_m_1 28\n",
      "id_m_2 28\n",
      "id_m_2_alt_stage 28\n",
      "id_m_2_alt_alt 28\n",
      "id_m_2_tetrarechim 28\n"
     ]
    }
   ],
   "source": [
    "noms = dico_stages[\"nom_eleves\"]\n",
    "prenoms = dico_stages[\"prenom_eleves\"]\n",
    "m_1_1_lieux = dico_stages[\"stages_m1_nom_orga\"]\n",
    "m2_1_lieux = dico_stages[\"stages_m2_nom_orga\"]\n",
    "m2_alt_stages = dico_stages[\"stages_m2_alternance_type_org_stage\"]\n",
    "m2_alt_alts = dico_stages[\"stages_m2_alternance_type_org_alt\"]\n",
    "m2_tetrarechim_lieux = dico_stages[\"stages_m2_tetrarechim_nom_orga\"]\n",
    "\n",
    "for nom, prenom, m_1_lieu, m2_1_lieu, m2_alt_stage, m2_alt_alt, m2_tetrarechim_lieu in zip(noms, prenoms, m_1_1_lieux, m2_1_lieux, m2_alt_stages, m2_alt_alts, m2_tetrarechim_lieux):\n",
    "    if m_1_lieu != None:\n",
    "        id_m_1 = f\"{prenom}_{nom}_stage_m1_1\"\n",
    "        dico_stages[\"id_m_1\"].append(id_m_1)\n",
    "    else:\n",
    "        dico_stages[\"id_m_1\"].append(None)\n",
    "\n",
    "    if m2_1_lieu != None:\n",
    "        id_m_2 = f\"{prenom}_{nom}_stage_m2\"\n",
    "        dico_stages[\"id_m_2\"].append(id_m_2)\n",
    "    else:\n",
    "        dico_stages[\"id_m_2\"].append(None)\n",
    "    \n",
    "    if m2_alt_stage != None:\n",
    "        id_m_2_alt_stage = f\"{prenom}_{nom}_stage_m2_alt_stage\"\n",
    "        dico_stages[\"id_m_2_alt_stage\"].append(id_m_2_alt_stage)\n",
    "    else:\n",
    "        dico_stages[\"id_m_2_alt_stage\"].append(None)\n",
    "    \n",
    "    if m2_alt_alt != None:\n",
    "        id_m_2_alt_alt = f\"{prenom}_{nom}_alt_m2_alt\"\n",
    "        dico_stages[\"id_m_2_alt_alt\"].append(id_m_2_alt_alt)\n",
    "    else:\n",
    "        dico_stages[\"id_m_2_alt_alt\"].append(None)\n",
    "\n",
    "    if m2_tetrarechim_lieu != None:\n",
    "        id_m_2_tetrarechim = f\"{prenom}_{nom}_stage_m2_tetrarechim\"\n",
    "        dico_stages[\"id_m_2_tetrarechim\"].append(id_m_2_tetrarechim)\n",
    "    else:\n",
    "        dico_stages[\"id_m_2_tetrarechim\"].append(None)\n",
    "\n",
    "\n",
    "for key, value in dico_stages.items():\n",
    "    print(key, len(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_eleves</th>\n",
       "      <th>nom_eleves</th>\n",
       "      <th>prenom_eleves</th>\n",
       "      <th>stages_m1_type_orga</th>\n",
       "      <th>stages_m1_nom_orga</th>\n",
       "      <th>stages_m1_duree</th>\n",
       "      <th>stages_m1_sujet</th>\n",
       "      <th>stages_m1_tuteur</th>\n",
       "      <th>stages_m1_note</th>\n",
       "      <th>stages_m2_type_orga</th>\n",
       "      <th>...</th>\n",
       "      <th>stages_m2_alternance_type_org_stage</th>\n",
       "      <th>stages_m2_alternance_duree_stage</th>\n",
       "      <th>stages_m2_alternance_missions_stage</th>\n",
       "      <th>stages_m2_alternance_type_org_alt</th>\n",
       "      <th>stages_m2_alternance_missions_alt</th>\n",
       "      <th>id_m_1</th>\n",
       "      <th>id_m_2</th>\n",
       "      <th>id_m_2_alt_stage</th>\n",
       "      <th>id_m_2_alt_alt</th>\n",
       "      <th>id_m_2_tetrarechim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pauline_DÉGEZ</td>\n",
       "      <td>DÉGEZ</td>\n",
       "      <td>Pauline</td>\n",
       "      <td>Laboratoire</td>\n",
       "      <td>MODYCO, CNRS</td>\n",
       "      <td>3 mois</td>\n",
       "      <td>Enrichissement de treebanks du francais</td>\n",
       "      <td>Sylvain Kahane</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Pauline_DÉGEZ_stage_m1_1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Perrine_QUENNEHEN</td>\n",
       "      <td>QUENNEHEN</td>\n",
       "      <td>Perrine</td>\n",
       "      <td>Laboratoire</td>\n",
       "      <td>MODYCO, CNRS</td>\n",
       "      <td>4 mois</td>\n",
       "      <td>Augmentation du corpus Naija de façon automatique</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Perrine_QUENNEHEN_stage_m1_1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Perrine_QUENNEHEN_stage_m2_tetrarechim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ashley_RATIER</td>\n",
       "      <td>RATIER</td>\n",
       "      <td>Ashley</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Valentine_FLEITH</td>\n",
       "      <td>FLEITH</td>\n",
       "      <td>Valentine</td>\n",
       "      <td>Laboratoire</td>\n",
       "      <td>Télécom Paris</td>\n",
       "      <td>3 mois</td>\n",
       "      <td>Évaluation automatique de la qualité d'une pri...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Entreprise</td>\n",
       "      <td>...</td>\n",
       "      <td>Encore indéfini entre 2 boîtes je reviendrai p...</td>\n",
       "      <td>6 mois</td>\n",
       "      <td>A priori IA/NLP/DevOps/MLops mais pareil je po...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Valentine _FLEITH_stage_m1_1</td>\n",
       "      <td>Valentine _FLEITH_stage_m2</td>\n",
       "      <td>Valentine _FLEITH_stage_m2_alt_stage</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Débora_VAN_DEN_ZANDE</td>\n",
       "      <td>VAN-DEN-ZANDE</td>\n",
       "      <td>Débora</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Entreprise</td>\n",
       "      <td>Améliorer les algorithmes de machine learning ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Débora_VAN-DEN-ZANDE _alt_m2_alt</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Patricia_AUGUSTYN</td>\n",
       "      <td>AUGUSTYN</td>\n",
       "      <td>Patricia</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ioana_Madalina_SILAI</td>\n",
       "      <td>SILAI</td>\n",
       "      <td>Ioana Madalina</td>\n",
       "      <td>Laboratoire</td>\n",
       "      <td>MODYCO, CNRS</td>\n",
       "      <td>3 mois</td>\n",
       "      <td>Génération automatique des grammaires contrast...</td>\n",
       "      <td>Sylvain Kahane</td>\n",
       "      <td>4.0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Ioana Madalina_SILAI_stage_m1_1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Ioana Madalina_SILAI_stage_m2_tetrarechim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Marie_DELPORTE_LANDAT</td>\n",
       "      <td>DELPORTE-LANDAT</td>\n",
       "      <td>Marie</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Marie_DELPORTE-LANDAT_stage_m2_tetrarechim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Florian_PHILIPPE</td>\n",
       "      <td>PHILIPPE</td>\n",
       "      <td>Florian</td>\n",
       "      <td>Laboratoire</td>\n",
       "      <td>MODYCO, CNRS</td>\n",
       "      <td>3 mois</td>\n",
       "      <td>Reconnaissance des adverbiaux temporels dans l...</td>\n",
       "      <td>Delphine Battistelli</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Florian_PHILIPPE_stage_m1_1</td>\n",
       "      <td>Florian_PHILIPPE_stage_m2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Florian_PHILIPPE_stage_m2_tetrarechim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lydia_BELHOUL</td>\n",
       "      <td>BELHOUL</td>\n",
       "      <td>Lydia</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Liza_FRETEL</td>\n",
       "      <td>FRETEL</td>\n",
       "      <td>Liza</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Entreprise</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Liza_FRETEL_stage_m2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Lucile_BESSAC</td>\n",
       "      <td>BESSAC</td>\n",
       "      <td>Lucile</td>\n",
       "      <td>Laboratoire</td>\n",
       "      <td>CNRS Pouchet, UMR SFL (structures formelles du...</td>\n",
       "      <td>2 mois</td>\n",
       "      <td>Création d'un outil pour l'extraction, la visu...</td>\n",
       "      <td>Sarra El Ayari</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Mollow</td>\n",
       "      <td>stratégie de référencement du site web (SEO ma...</td>\n",
       "      <td>Lucile_BESSAC_stage_m1_1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Lucile_BESSAC_alt_m2_alt</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Kehina_MANSERI</td>\n",
       "      <td>MANSERI</td>\n",
       "      <td>Kehina</td>\n",
       "      <td>Laboratoire</td>\n",
       "      <td>MODYCO, CNRS</td>\n",
       "      <td>2 mois</td>\n",
       "      <td>Création de jeux sérieux pour l'apprentissage ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Kehina_MANSERI_stage_m1_1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Kehina_MANSERI_stage_m2_tetrarechim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Maria_Paz_BOTERO</td>\n",
       "      <td>BOTERO</td>\n",
       "      <td>Maria Paz</td>\n",
       "      <td>Laboratoire</td>\n",
       "      <td>MODYCO, CNRS</td>\n",
       "      <td>3 mois</td>\n",
       "      <td>L'étude de l'interface syntaxe-prosodie en fra...</td>\n",
       "      <td>Sylvain Kahane</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Laboratoire</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Maria Paz_BOTERO_stage_m1_1</td>\n",
       "      <td>Maria Paz_BOTERO_stage_m2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Alix_SIRVEN_VIÉNOT</td>\n",
       "      <td>SIRVEN-VIÉNOT</td>\n",
       "      <td>Alix</td>\n",
       "      <td>Laboratoire</td>\n",
       "      <td>MODYCO, CNRS</td>\n",
       "      <td>3 mois</td>\n",
       "      <td>Analyse et annotation de la prise en charge da...</td>\n",
       "      <td>Delphine Battistelli</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Alix_SIRVEN-VIÉNOT_stage_m1_1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Alix_SIRVEN-VIÉNOT_stage_m2_tetrarechim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Solomiia_ KOROL</td>\n",
       "      <td>KOROL</td>\n",
       "      <td>Solomiia</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Yu_ZHANG</td>\n",
       "      <td>ZHANG</td>\n",
       "      <td>Yu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Manon_GROUVÈS</td>\n",
       "      <td>GROUVÈS</td>\n",
       "      <td>Manon</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Keming_YI</td>\n",
       "      <td>YI</td>\n",
       "      <td>Keming</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Xinlei_CHEN</td>\n",
       "      <td>CHEN</td>\n",
       "      <td>Xinlei</td>\n",
       "      <td>Laboratoire</td>\n",
       "      <td>ERTIM</td>\n",
       "      <td>5 mois</td>\n",
       "      <td>annotation syntaxique sur le mandarin et hokkien</td>\n",
       "      <td>Magistry Pierre</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Xinlei_CHEN_stage_m1_1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Lise_BRISSET</td>\n",
       "      <td>BRISSET</td>\n",
       "      <td>Lise</td>\n",
       "      <td>Laboratoire</td>\n",
       "      <td>Laboratoire de Phonétique et Phonologie</td>\n",
       "      <td>3 mois</td>\n",
       "      <td>Analyse de l'âge</td>\n",
       "      <td>Cédric Gendrot</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Lise_BRISSET_stage_m1_1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Lise_BRISSET_stage_m2_tetrarechim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Nicolas_NGAUV</td>\n",
       "      <td>NGAUV</td>\n",
       "      <td>Nicolas</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Melissa_MAHMOUDI</td>\n",
       "      <td>MAHMOUDI</td>\n",
       "      <td>Melissa</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Laboratoire</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Melissa_MAHMOUDI_stage_m2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Yuntian_SHEN</td>\n",
       "      <td>SHEN</td>\n",
       "      <td>Yuntian</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Zineb_CHARIKH</td>\n",
       "      <td>CHARIKH</td>\n",
       "      <td>Zineb</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id_eleves       nom_eleves   prenom_eleves  \\\n",
       "0           Pauline_DÉGEZ            DÉGEZ         Pauline   \n",
       "1       Perrine_QUENNEHEN        QUENNEHEN         Perrine   \n",
       "2           Ashley_RATIER           RATIER          Ashley   \n",
       "3        Valentine_FLEITH           FLEITH      Valentine    \n",
       "4   Débora_VAN_DEN_ZANDE    VAN-DEN-ZANDE           Débora   \n",
       "5       Patricia_AUGUSTYN         AUGUSTYN        Patricia   \n",
       "6    Ioana_Madalina_SILAI            SILAI  Ioana Madalina   \n",
       "7   Marie_DELPORTE_LANDAT  DELPORTE-LANDAT           Marie   \n",
       "8        Florian_PHILIPPE         PHILIPPE         Florian   \n",
       "9           Lydia_BELHOUL          BELHOUL           Lydia   \n",
       "10            Liza_FRETEL           FRETEL            Liza   \n",
       "11          Lucile_BESSAC           BESSAC          Lucile   \n",
       "12         Kehina_MANSERI          MANSERI          Kehina   \n",
       "13       Maria_Paz_BOTERO           BOTERO       Maria Paz   \n",
       "14     Alix_SIRVEN_VIÉNOT    SIRVEN-VIÉNOT            Alix   \n",
       "15        Solomiia_ KOROL            KOROL       Solomiia    \n",
       "16               Yu_ZHANG            ZHANG              Yu   \n",
       "17          Manon_GROUVÈS          GROUVÈS           Manon   \n",
       "18              Keming_YI               YI          Keming   \n",
       "19            Xinlei_CHEN             CHEN          Xinlei   \n",
       "20           Lise_BRISSET          BRISSET            Lise   \n",
       "21          Nicolas_NGAUV            NGAUV         Nicolas   \n",
       "22       Melissa_MAHMOUDI         MAHMOUDI         Melissa   \n",
       "23           Yuntian_SHEN             SHEN         Yuntian   \n",
       "24          Zineb_CHARIKH          CHARIKH           Zineb   \n",
       "\n",
       "   stages_m1_type_orga                                 stages_m1_nom_orga  \\\n",
       "0          Laboratoire                                       MODYCO, CNRS   \n",
       "1          Laboratoire                                       MODYCO, CNRS   \n",
       "2                 None                                               None   \n",
       "3          Laboratoire                                     Télécom Paris    \n",
       "4                 None                                               None   \n",
       "5                 None                                               None   \n",
       "6          Laboratoire                                       MODYCO, CNRS   \n",
       "7                 None                                               None   \n",
       "8          Laboratoire                                       MODYCO, CNRS   \n",
       "9                 None                                               None   \n",
       "10                None                                               None   \n",
       "11         Laboratoire  CNRS Pouchet, UMR SFL (structures formelles du...   \n",
       "12         Laboratoire                                       MODYCO, CNRS   \n",
       "13         Laboratoire                                       MODYCO, CNRS   \n",
       "14         Laboratoire                                       MODYCO, CNRS   \n",
       "15                None                                               None   \n",
       "16                None                                               None   \n",
       "17                None                                               None   \n",
       "18                None                                               None   \n",
       "19         Laboratoire                                              ERTIM   \n",
       "20         Laboratoire            Laboratoire de Phonétique et Phonologie   \n",
       "21                None                                               None   \n",
       "22                None                                               None   \n",
       "23                None                                               None   \n",
       "24                None                                               None   \n",
       "\n",
       "   stages_m1_duree                                    stages_m1_sujet  \\\n",
       "0           3 mois           Enrichissement de treebanks du francais    \n",
       "1           4 mois  Augmentation du corpus Naija de façon automatique   \n",
       "2             None                                               None   \n",
       "3           3 mois  Évaluation automatique de la qualité d'une pri...   \n",
       "4             None                                               None   \n",
       "5             None                                               None   \n",
       "6           3 mois  Génération automatique des grammaires contrast...   \n",
       "7             None                                               None   \n",
       "8           3 mois  Reconnaissance des adverbiaux temporels dans l...   \n",
       "9             None                                               None   \n",
       "10            None                                               None   \n",
       "11          2 mois  Création d'un outil pour l'extraction, la visu...   \n",
       "12          2 mois  Création de jeux sérieux pour l'apprentissage ...   \n",
       "13          3 mois  L'étude de l'interface syntaxe-prosodie en fra...   \n",
       "14          3 mois  Analyse et annotation de la prise en charge da...   \n",
       "15            None                                               None   \n",
       "16            None                                               None   \n",
       "17            None                                               None   \n",
       "18            None                                               None   \n",
       "19          5 mois   annotation syntaxique sur le mandarin et hokkien   \n",
       "20          3 mois                                  Analyse de l'âge    \n",
       "21            None                                               None   \n",
       "22            None                                               None   \n",
       "23            None                                               None   \n",
       "24            None                                               None   \n",
       "\n",
       "        stages_m1_tuteur  stages_m1_note stages_m2_type_orga  ...  \\\n",
       "0         Sylvain Kahane             3.0                None  ...   \n",
       "1                    NaN             4.0                None  ...   \n",
       "2                   None             NaN                None  ...   \n",
       "3                    NaN             4.0          Entreprise  ...   \n",
       "4                   None             NaN                None  ...   \n",
       "5                   None             NaN                None  ...   \n",
       "6         Sylvain Kahane             4.0                None  ...   \n",
       "7                   None             NaN                None  ...   \n",
       "8   Delphine Battistelli             3.0                 NaN  ...   \n",
       "9                   None             NaN                None  ...   \n",
       "10                  None             NaN          Entreprise  ...   \n",
       "11        Sarra El Ayari             5.0                None  ...   \n",
       "12                   NaN             3.0                None  ...   \n",
       "13        Sylvain Kahane             5.0         Laboratoire  ...   \n",
       "14  Delphine Battistelli             NaN                None  ...   \n",
       "15                  None             NaN                None  ...   \n",
       "16                  None             NaN                None  ...   \n",
       "17                  None             NaN                None  ...   \n",
       "18                  None             NaN                None  ...   \n",
       "19       Magistry Pierre             3.0                None  ...   \n",
       "20       Cédric Gendrot              3.0                None  ...   \n",
       "21                  None             NaN                None  ...   \n",
       "22                  None             NaN         Laboratoire  ...   \n",
       "23                  None             NaN                None  ...   \n",
       "24                  None             NaN                None  ...   \n",
       "\n",
       "                  stages_m2_alternance_type_org_stage  \\\n",
       "0                                                None   \n",
       "1                                                None   \n",
       "2                                                None   \n",
       "3   Encore indéfini entre 2 boîtes je reviendrai p...   \n",
       "4                                                None   \n",
       "5                                                None   \n",
       "6                                                None   \n",
       "7                                                None   \n",
       "8                                                None   \n",
       "9                                                None   \n",
       "10                                               None   \n",
       "11                                               None   \n",
       "12                                               None   \n",
       "13                                               None   \n",
       "14                                               None   \n",
       "15                                               None   \n",
       "16                                               None   \n",
       "17                                               None   \n",
       "18                                               None   \n",
       "19                                               None   \n",
       "20                                               None   \n",
       "21                                               None   \n",
       "22                                               None   \n",
       "23                                               None   \n",
       "24                                               None   \n",
       "\n",
       "   stages_m2_alternance_duree_stage  \\\n",
       "0                              None   \n",
       "1                              None   \n",
       "2                              None   \n",
       "3                            6 mois   \n",
       "4                              None   \n",
       "5                              None   \n",
       "6                              None   \n",
       "7                              None   \n",
       "8                              None   \n",
       "9                              None   \n",
       "10                             None   \n",
       "11                             None   \n",
       "12                             None   \n",
       "13                             None   \n",
       "14                             None   \n",
       "15                             None   \n",
       "16                             None   \n",
       "17                             None   \n",
       "18                             None   \n",
       "19                             None   \n",
       "20                             None   \n",
       "21                             None   \n",
       "22                             None   \n",
       "23                             None   \n",
       "24                             None   \n",
       "\n",
       "                  stages_m2_alternance_missions_stage  \\\n",
       "0                                                None   \n",
       "1                                                None   \n",
       "2                                                None   \n",
       "3   A priori IA/NLP/DevOps/MLops mais pareil je po...   \n",
       "4                                                None   \n",
       "5                                                None   \n",
       "6                                                None   \n",
       "7                                                None   \n",
       "8                                                None   \n",
       "9                                                None   \n",
       "10                                               None   \n",
       "11                                               None   \n",
       "12                                               None   \n",
       "13                                               None   \n",
       "14                                               None   \n",
       "15                                               None   \n",
       "16                                               None   \n",
       "17                                               None   \n",
       "18                                               None   \n",
       "19                                               None   \n",
       "20                                               None   \n",
       "21                                               None   \n",
       "22                                               None   \n",
       "23                                               None   \n",
       "24                                               None   \n",
       "\n",
       "   stages_m2_alternance_type_org_alt  \\\n",
       "0                               None   \n",
       "1                               None   \n",
       "2                               None   \n",
       "3                               None   \n",
       "4                         Entreprise   \n",
       "5                               None   \n",
       "6                               None   \n",
       "7                               None   \n",
       "8                               None   \n",
       "9                               None   \n",
       "10                              None   \n",
       "11                            Mollow   \n",
       "12                              None   \n",
       "13                              None   \n",
       "14                              None   \n",
       "15                              None   \n",
       "16                              None   \n",
       "17                              None   \n",
       "18                              None   \n",
       "19                              None   \n",
       "20                              None   \n",
       "21                              None   \n",
       "22                              None   \n",
       "23                              None   \n",
       "24                              None   \n",
       "\n",
       "                    stages_m2_alternance_missions_alt  \\\n",
       "0                                                None   \n",
       "1                                                None   \n",
       "2                                                None   \n",
       "3                                                None   \n",
       "4   Améliorer les algorithmes de machine learning ...   \n",
       "5                                                None   \n",
       "6                                                None   \n",
       "7                                                None   \n",
       "8                                                None   \n",
       "9                                                None   \n",
       "10                                               None   \n",
       "11  stratégie de référencement du site web (SEO ma...   \n",
       "12                                               None   \n",
       "13                                               None   \n",
       "14                                               None   \n",
       "15                                               None   \n",
       "16                                               None   \n",
       "17                                               None   \n",
       "18                                               None   \n",
       "19                                               None   \n",
       "20                                               None   \n",
       "21                                               None   \n",
       "22                                               None   \n",
       "23                                               None   \n",
       "24                                               None   \n",
       "\n",
       "                             id_m_1                      id_m_2  \\\n",
       "0          Pauline_DÉGEZ_stage_m1_1                        None   \n",
       "1      Perrine_QUENNEHEN_stage_m1_1                        None   \n",
       "2                              None                        None   \n",
       "3      Valentine _FLEITH_stage_m1_1  Valentine _FLEITH_stage_m2   \n",
       "4                              None                        None   \n",
       "5                              None                        None   \n",
       "6   Ioana Madalina_SILAI_stage_m1_1                        None   \n",
       "7                              None                        None   \n",
       "8       Florian_PHILIPPE_stage_m1_1   Florian_PHILIPPE_stage_m2   \n",
       "9                              None                        None   \n",
       "10                             None        Liza_FRETEL_stage_m2   \n",
       "11         Lucile_BESSAC_stage_m1_1                        None   \n",
       "12        Kehina_MANSERI_stage_m1_1                        None   \n",
       "13      Maria Paz_BOTERO_stage_m1_1   Maria Paz_BOTERO_stage_m2   \n",
       "14    Alix_SIRVEN-VIÉNOT_stage_m1_1                        None   \n",
       "15                             None                        None   \n",
       "16                             None                        None   \n",
       "17                             None                        None   \n",
       "18                             None                        None   \n",
       "19           Xinlei_CHEN_stage_m1_1                        None   \n",
       "20          Lise_BRISSET_stage_m1_1                        None   \n",
       "21                             None                        None   \n",
       "22                             None   Melissa_MAHMOUDI_stage_m2   \n",
       "23                             None                        None   \n",
       "24                             None                        None   \n",
       "\n",
       "                        id_m_2_alt_stage                    id_m_2_alt_alt  \\\n",
       "0                                   None                              None   \n",
       "1                                   None                              None   \n",
       "2                                   None                              None   \n",
       "3   Valentine _FLEITH_stage_m2_alt_stage                              None   \n",
       "4                                   None  Débora_VAN-DEN-ZANDE _alt_m2_alt   \n",
       "5                                   None                              None   \n",
       "6                                   None                              None   \n",
       "7                                   None                              None   \n",
       "8                                   None                              None   \n",
       "9                                   None                              None   \n",
       "10                                  None                              None   \n",
       "11                                  None          Lucile_BESSAC_alt_m2_alt   \n",
       "12                                  None                              None   \n",
       "13                                  None                              None   \n",
       "14                                  None                              None   \n",
       "15                                  None                              None   \n",
       "16                                  None                              None   \n",
       "17                                  None                              None   \n",
       "18                                  None                              None   \n",
       "19                                  None                              None   \n",
       "20                                  None                              None   \n",
       "21                                  None                              None   \n",
       "22                                  None                              None   \n",
       "23                                  None                              None   \n",
       "24                                  None                              None   \n",
       "\n",
       "                            id_m_2_tetrarechim  \n",
       "0                                         None  \n",
       "1       Perrine_QUENNEHEN_stage_m2_tetrarechim  \n",
       "2                                         None  \n",
       "3                                         None  \n",
       "4                                         None  \n",
       "5                                         None  \n",
       "6    Ioana Madalina_SILAI_stage_m2_tetrarechim  \n",
       "7   Marie_DELPORTE-LANDAT_stage_m2_tetrarechim  \n",
       "8        Florian_PHILIPPE_stage_m2_tetrarechim  \n",
       "9                                         None  \n",
       "10                                        None  \n",
       "11                                        None  \n",
       "12         Kehina_MANSERI_stage_m2_tetrarechim  \n",
       "13                                        None  \n",
       "14     Alix_SIRVEN-VIÉNOT_stage_m2_tetrarechim  \n",
       "15                                        None  \n",
       "16                                        None  \n",
       "17                                        None  \n",
       "18                                        None  \n",
       "19                                        None  \n",
       "20           Lise_BRISSET_stage_m2_tetrarechim  \n",
       "21                                        None  \n",
       "22                                        None  \n",
       "23                                        None  \n",
       "24                                        None  \n",
       "\n",
       "[25 rows x 32 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stages = pd.DataFrame(dico_stages)\n",
    "df_stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_stages_par_stage = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
