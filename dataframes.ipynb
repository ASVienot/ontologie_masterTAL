{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création des dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ce notebook permet la création des dataframes utilsées pour la création des triplets de l'ontologie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from unidecode import unidecode\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Importer les réponses du formulaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Horodateur', 'Score', 'Nom de famille', 'Prénom', 'Genre',\n",
       "       'Date de naissance', 'Nationalité',\n",
       "       'Avez-vous redoublé le master ? Si oui, indiquez quelle année et quel niveau. ',\n",
       "       'Dans quelle université étiez-vous inscrits au M1 ? ',\n",
       "       'Dans quel parcours êtes-vous inscrits au M2 ?',\n",
       "       'Disposez vous ou avez-vous disposé d'un aménagement handicap pour le master (tiers-temps, autres...) ?',\n",
       "       'Si vous êtes inscrits (ou avez été inscrits) dans un autre établissement pendant le master, indiquez lequel :\\n\\nExemple :\\nÉtudiant en M2 TAL Ingénierie Multilingue et à 42 en même temps.',\n",
       "       'Si vous avez obtenu un baccalauréat français, quelle était votre filière : ',\n",
       "       'Indiquez si cette licence appartient à l'une des mentions suivantes :',\n",
       "       'Avez-vous déjà un master ?\\nSi oui, veuillez indiquer son nom original (langue d'origine) au format :\\nNOM, UNIVERSITÉ\\n\\nExemple:\\nMaster Linguistique Anglaise, Université Sorbonne Nouvelle',\n",
       "       'Si vous travaillez (ou avez travaillé) pendant le master, indiquez sur quel poste (hors stage TAL) :\\n\\nExemple :\\nActuellement employé polyvalent à Décathlon.',\n",
       "       'Si vous avez exercé une activité professionnelle de longue durée avant le master (reconversion, reprise d'études ou autres), indiquez laquelle :\\n\\nExemple:\\nProfesseure à l'alliance française de Bogotá. ',\n",
       "       'Avez-vous eu un premier stage en NLP pendant le M1 ?',\n",
       "       'Si oui, étiez-vous en entreprise, laboratoire, ou autre ?1',\n",
       "       'Quel était le nom de l'organisme d'accueil ?1',\n",
       "       'Quelle était la durée du stage ?1', 'Quel était le sujet du stage ?1',\n",
       "       'Si votre tuteur de stage était un enseignant du master, indiquez lequel :1',\n",
       "       'Avez-vous eu un second stage en NLP pendant le M1 ?',\n",
       "       'Si oui, étiez-vous en entreprise, laboratoire, ou autre ?2',\n",
       "       'Quel était le nom de l'organisme d'accueil ?2 ',\n",
       "       'Quelle était la durée du stage ?2', 'Quel était le sujet du stage ?2',\n",
       "       'Si votre tuteur de stage était un enseignant du master, indiquez lequel :2',\n",
       "       'Avez-vous eu un stage en NLP pendant le M2 (hors celui du second semestre à venir) ?',\n",
       "       'Si oui, étiez-vous en entreprise, laboratoire, ou autre ?3',\n",
       "       'Quel était le nom de l'organisme d'accueil ?3 ',\n",
       "       'Quelle était la durée du stage ?3', 'Quel était le sujet du stage ?3',\n",
       "       'Si votre tuteur de stage était un enseignant du master, indiquez lequel :3',\n",
       "       'Si vous deviez noter votre expérience globale de stagiaire, quelle notre mettriez vous ? \\nStage M1 numéro 1',\n",
       "       'Si vous deviez noter votre expérience globale de stagiaire, quelle notre mettriez vous ? \\nStage M1 numéro 2',\n",
       "       'Si vous deviez noter votre expérience globale de stagiaire, quelle notre mettriez vous ? \\nStage M2',\n",
       "       'Pour les M2 en parcours recherche, IM ou TETRADOM, avez-vous déjà trouvé un stage ?',\n",
       "       'Si oui, serez-vous en entreprise, laboratoire ou autre ?',\n",
       "       'Quel est le nom de l'organisme d'accueil ?',\n",
       "       'Quelle sera la durée du stage ?',\n",
       "       'Pour les M2 en parcours recherche, le sujet de votre mémoire est-il lié à votre stage de M2 ?',\n",
       "       'Pour les M2 en parcours recherche, si vous le connaissez déjà, quel est le sujet de votre mémoire ?',\n",
       "       'Pour les M2 en parcours recherche, si vous les connaissez déjà, qui sont vos directeurs de mémoire ? ',\n",
       "       'Pour les M2 en parcours alternance, avez-vous trouvé une alternance, un stage, ou autre ?',\n",
       "       'Pour les M2 en parcours alternance ayant trouvé une alternance, dans quel organisme êtes-vous ?',\n",
       "       'Quelle sont vos missions ?',\n",
       "       'Pour les M2 en parcours alternance ayant trouvé un stage, dans quel organisme êtes-vous/serez-vous ?',\n",
       "       'Quelle est/sera la durée du stage ?',\n",
       "       'Quelles sont/seront vos missions ?',\n",
       "       'Quels cours avez-vous suivis au premier semestre du M1 ?',\n",
       "       'Quelles ont été vos options de linguistique au premier semestre du M1 ?\\nSéparer les cours par des virgules. ',\n",
       "       'Avons-nous oublié quelque cours au premier semestre du M1 ? Indiquez-le ici !\\nSéparez les cours par des virgules. ',\n",
       "       'Quels cours avez-vous suivis au second semestre du M1 ?',\n",
       "       'Avons-nous oublié quelque cours au second semestre du M1 ? Indiquez-le ici !\\nSéparez les cours par des virgules. ',\n",
       "       'Quels cours avez-vous suivis au premier semestre du M2 ?',\n",
       "       'Avons-nous oublié quelque cours au premier semestre du M2 ? Indiquez-le ici !\\nSéparez les cours par des virgules. ',\n",
       "       'Quels sont vos sujets préférés en cours ? ',\n",
       "       'Quelle(s) modalité(s) d'évaluation préférez-vous ?',\n",
       "       'Quel aspect aimeriez-vous voir plus mis en avant pendant le master ? Ça peut être un sujet en particulier, des compétences spécifiques ou autre.',\n",
       "       'Qui est votre ennemi juré dans le master parmi les élèves (soyez pas sérieux c'est pour rigoler) ? ',\n",
       "       'Sur combien notez-vous votre santé mentale avant le master ?',\n",
       "       'Sur combien notez-vous votre santé mentale après le master ? ',\n",
       "       'À quelle fréquence pleurez-vous à cause du master ?\\nex: x/mois ou x/semaine ou x/jour ...',\n",
       "       'Combien d'heures par nuit dormez-vous en moyenne ?',\n",
       "       'Sur combien notez-vous la difficulté du M1 ?',\n",
       "       'Sur combien notez-vous la difficulté du M2 parcours Recherche et Développement ?',\n",
       "       'Sur combien notez-vous la difficulté du M2 parcours Alternance ?',\n",
       "       'Sur combien notez-vous la difficulté du M2 parcours Ingénierie Multilingue ?',\n",
       "       'Sur combien notez-vous la difficulté du M2 parcours Technologies de la Traduction et Traitement des Données Multilingues ?',\n",
       "       'Pour les adeptes de Linux, voulez-vous régulièrement jeter votre ordinateur par la fenêtre ?',\n",
       "       'Pour les adeptes de Mac, voulez-vous régulièrement jeter votre ordinateur par la fenêtre ?',\n",
       "       'Si vous deviez élire le meilleur cours de tout le master, lequel choisiriez-vous ? ',\n",
       "       'Pour les étudiants de Nanterre, sur combien notez-vous l'efficacité de votre administration ?',\n",
       "       'Pour les étudiants de la Sorbonne-Nouvelle, sur combien notez-vous l'efficacité de votre administration ?',\n",
       "       'Pour les étudiants de l'INALCO, sur combien notez-vous l'efficacité de votre administration ?',\n",
       "       'Quel conseil donneriez-vous aux futurs élèves pour survivre au master TAL ?',\n",
       "       'À qui recommanderiez-vous le master TAL ?',\n",
       "       'Quel conseil donneriez-vous aux professeurs du master TAL ? ',\n",
       "       'Avez-vous eu une expérience professionnelle en lien avec le master pendant le M1 ou le M2 ? (hors alternance et stage)',\n",
       "       'Quel était le nom de l'organisme employeur ?',\n",
       "       'Quel était le type de contrat ? ',\n",
       "       'Quelles étaient vos missions lors de cette expérience ?\\n',\n",
       "       'Si vous avez répondu à la question précédente et que votre diplôme est étranger, veuillez indiquer sous le même format un nom équivalent en français.\\n\\nExemple :\\nSi vous avez répondu Master in social studies, Cambridge University à la question précédente.\\n\\nVeuillez ici répondre :\\nMaster en Sciences Sociales, Université de Cambridge',\n",
       "       'Indiquez si ce master appartient à une des mentions suivantes : ',\n",
       "       'Si vous avez obtenu un autre type de diplôme (hors licence et master), indiquez son nom original (langue d'origine) au format :\\nNOM, ÉTABLISSEMENT\\n\\nExemple:\\nBTS en communication, Lycée Paul Eluard, Saint-Denis',\n",
       "       'Avez-vous déjà une licence ?\\nSi oui, veuillez indiquer son nom original (langue d'origine) au format :\\nNOM, UNIVERSITÉ\\n\\nExemple:\\nLicence en biologie, Université Paris Saclay',\n",
       "       'Si vous avez répondu à la question précédente et que votre diplôme est étranger, veuillez indiquer sous le même format un nom équivalent en français.\\n\\nExemple :\\nSi vous avez répondu Bachelor in social studies, Cambridge University à la question précédente.\\n\\nVeuillez ici répondre :\\nLicence en Sciences Sociales, Université de Cambridge',\n",
       "       'Si vous avez répondu à la question précédente et que votre diplôme est étranger, veuillez indiquer sous le même format un nom équivalent en français.\\n\\nExemple :\\nSi vous avez répondu NVQ hairstylist, Freddie Mercury High School, Cambridge à la question précédente.\\n\\nVeuillez ici répondre :\\nCAP coiffure, Lycée Freddie Mercury, Cambridge',\n",
       "       'Colonne 84'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_formulaire = pd.read_csv(\"formulaire.csv\")\n",
    "df_formulaire.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Création de la dataframe prof\n",
    "- id_prof\n",
    "- nom_prof\n",
    "- prenom_prof\n",
    "- genre\n",
    "- cours\n",
    "- directeur_de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_prof = {\"nom_prof\": [\n",
    "    \"DUPONT\",\n",
    "    \"BATTISTELLI\",\n",
    "    \"ESHKOL-TARAVELLA\", \n",
    "    \"GROBOL\",\n",
    "    \"KAHANE\", \n",
    "    \"MAGISTRY\", \n",
    "    \"NOUVEL\", \n",
    "    \"WANG\", \n",
    "    \"GENDROT\", \n",
    "    \"HERRERA\", \n",
    "    \"WANG\", \n",
    "    \"BOGLIOTTI\", \n",
    "    \"VILLEOING\", \n",
    "    \"STRICKER\", \n",
    "    \"DEHOUCK\", \n",
    "    \"JACOBSON\", \n",
    "    \"SAUVAGE\", \n",
    "    \"ZWEIGENBAUM\", \n",
    "    \"KOSMALA\" , \n",
    "    \"VALETTE\", \n",
    "    \"GABOR\", \n",
    "    \"LICHAO\", \n",
    "    \"JACQUEMARD\",\n",
    "    \"ROULOIS\",\n",
    "    \"MONNIN-TUILLIER\",\n",
    "    \"AMSILI\",\n",
    "    \"JOURDAIN\", \n",
    "    \"AOUINA\", \n",
    "    \"LECAILLIEZ\",\n",
    "    \"AKSEN\", \n",
    "    \"GAUMET\", \n",
    "    \"GROUIN\", \n",
    "    \"KUBIK\",\n",
    "    \"BONNAFOUS\", \n",
    "    \"ABROUGUI\", \n",
    "    \"PAROUBECK\",\n",
    "    \"RAINERIE\", \n",
    "    \"SEMMAR\",\n",
    "    \"LASON\",\n",
    "    \"NUT\",\n",
    "    \"CARCENAC\",\n",
    "    \"LEE\",\n",
    "    \"HUP\",\n",
    "    \"COSTA\",\n",
    "    \"CORI\",\n",
    "    \"LEHMANN\",\n",
    "    \"PICCOLI\"\n",
    "    ],\n",
    "        \"prenom_prof\": [\"Yoann\", \"Delphine\", \"Iris\", \"Loïc\", \"Sylvain\", \"Pierre\", \"Damien\", \"Ilaine\", \"Cedric\", \"Santiago\", \"Xibin\", \"Caroline\", \"Florence\", \"Armand\", \"Mathieu\", \"Michel\", \"Eve\", \"Pierre\", \"Loulou\", \"Mathieu\", \"Kata\", \"Zhu\",\"Florent\", \"Alexandre\", \"Chloé\", \"Pascal\", \"Louis\", \"Ons\",\"Louis\", \"Hatice\", \"Sophie\", \"Cyril\", \"Karolina\", \"Marie-Paule\", \"Rim\", \"Patrick\", \"Sophie\", \"Nasredine\", \"Natalia\", \"Suppya\", \"Benoît\", \"Kyung\", \"Christophe\", \"James\", \"Marcel\", \"Sabine\", \"Vanessa\"],\n",
    "        \"etablissement\": [\"SorbonneNouvelle\", \"Nanterre\", \"Nanterre\", \"Nanterre\", \"Nanterre\", \"Inalco\", \"Inalco\", \"Inalco\", \"SorbonneNouvelle\", \"Nanterre\", \"Nanterre\", \"Nanterre\", \"Nanterre\", \"Inalco\", \"SorbonneNouvelle\", \"SorbonneNouvelle\", \"Inalco\", \"Inalco\", \"Nanterre\", \"Inalco\", \"Inalco\", \"Inalco\",\"Inalco\", \"Inalco\", \"Inalco\", \"SorbonneNouvelle\", \"Inalco\", \"Inalco\", \"Inalco\", \"Nanterre\", \"Inalco\", \"Inalco\", \"Inalco\", \"Inalco\", \"Inalco\", \"Inalco\", \"Nanterre\", \"Inalco\", \"Inalco\", \"Inalco\", \"Nanterre\", \"Inalco\", \"Nanterre\", \"SorbonneNouvelle\", \"Nanterre\", \"Nanterre\", \"Nanterre\"],\n",
    "\t\t\"genre\" : [\n",
    "      \"Homme\",\n",
    "      \"Femme\",\n",
    "      \"Femme\",\n",
    "      \"Autre\", \n",
    "      \"Homme\", \n",
    "      \"Homme\", \n",
    "      \"Homme\", \n",
    "      \"Femme\", \n",
    "      \"Homme\", \n",
    "      \"Homme\", \n",
    "      \"Homme\",\n",
    "      \"Femme\", \n",
    "      \"Femme\", \n",
    "      \"Homme\", \n",
    "      \"Homme\", \n",
    "      \"Homme\", \n",
    "      \"Femme\", \n",
    "      \"Homme\", \n",
    "      \"Femme\", \n",
    "      \"Homme\", \n",
    "      \"Femme\", \n",
    "      \"Homme\",\n",
    "      \"Homme\",\n",
    "      \"Homme\",\n",
    "      \"Femme\",\n",
    "      \"Homme\",\n",
    "      \"Homme\", \n",
    "      \"Femme\", \n",
    "      \"Homme\",\n",
    "      \"Femme\", \n",
    "      \"Femme\", \n",
    "      \"Homme\", \n",
    "      \"Femme\", \n",
    "      \"Femme\",\n",
    "      \"Femme\",\n",
    "      \"Homme\",\n",
    "      \"Femme\",\n",
    "      \"Homme\",\n",
    "      \"Femme\",\n",
    "      \"Femme\",\n",
    "      \"Homme\",\n",
    "      \"Femme\",\n",
    "      \"Homme\",\n",
    "      \"Homme\",\n",
    "      \"Homme\",\n",
    "      \"Femme\",\n",
    "      \"Femme\",\n",
    "      ],\n",
    "\t\t\"cours\": [\n",
    "      [\"PPE1\", \"PPE2\", \"Introduction a la fouille de textes\"],\n",
    "      [\"Modelisation automatique pour l'analyse de textes\",\"Annotations semantiques et applications en recherche d'information\", \"Ingenierie des connaissances\", \"Linguistique outillee et traitements statistiques\"],\n",
    "      [\"Programmation et algorithmique 1\", \"Bases de donnees pour linguistes\", \"Enrichissement de corpus\", \"De la modelisation au traitement automatique des donnees linguistiques\", \"Ingenierie des connaissances\", \"Langages du web semantique\", \"seminaire: tal et linguistique de corpus\"],\n",
    "      [\"Mathematiques pour le TAL\", \"Apprentissage automatique\", \"Arbres graphes\", \"Interfaces pour le web\"],\n",
    "      [\"Modelisation des langues\"],\n",
    "      [\"PPE1\", \"PPE2\"],\n",
    "      [\"Langages reguliers\", \"Statistiques textuelles\", \"Traitement statistique de corpus\"],\n",
    "      [\"Gest. Info Multilinguisme\", \"Ecriture et multilinguisme\"],\n",
    "      [\"Synthese de la parole\", \"CNN\", \"Phonetique physiologique et acoustique\"],\n",
    "      [\"Corpus arbores et parsing\"], \n",
    "      [\"Recueil de donnees et statistiques\"],\n",
    "      [\"Linguistique de la lsf\"], \n",
    "      [\"Morphologie\"],\n",
    "      [\"NLP in english\", \"Langues vivantes etrangeres\"], \n",
    "      [\"Programmation et algorithmique 2\"],\n",
    "      [\"Document structure\"],\n",
    "      [\"Outils de traitement de corpus\"], \n",
    "      [\"Corpus paralleles et comparables\"], \n",
    "      [\"Anglais de specialite 2\"],\n",
    "      [\"Semantique lexicale et textuelle\", \"Genres textes et usages\", \"Semantique des textes multilingues 1\"],\n",
    "      [\"Lexique et morphologie\"], \n",
    "      [\"Pratiques textuelles et traduction\", \"Traductologie 1\"],\n",
    "      [\"Programmation objet 1\", \"Programmation objet 2\"],\n",
    "      [\"Langages de script (python inalco)\", \"langages de script (roulois)\"],\n",
    "      [\"Extraction d'informations\"],\n",
    "      [\"Semantique computationnelle\"], \n",
    "      [\"Langages de script (jourdain)\"], \n",
    "      [\"Acquisition modelisation/representation\"],\n",
    "      [\"programmation orientee objet 1\"],\n",
    "      [\"Langue des signes\"], \n",
    "      [\"Conduite de projet de traduction 1\"],\n",
    "      [\"Fouille de textes 1\"], \n",
    "      [\"Outils de TAO 1\"], \n",
    "      [\"Traduction technique 1\"], \n",
    "      [\"Documents structures\"],\n",
    "      [\"Calculabilite\"],\n",
    "      [\"Large corpus linguistics\"],\n",
    "      [\"Traduction automatique et assistee\"],\n",
    "      [\"Polonais\"],\n",
    "      [\"Khmer\"],\n",
    "      [\"Gestion de projets\"],\n",
    "      [\"Coreen\"],\n",
    "      [\"Anglais pro\"],\n",
    "      [\"sociolinguistique\"],\n",
    "      [\"methodologie de la recherche\"],\n",
    "      [\"changements linguistiques\"],\n",
    "      [\"changements linguistiques\"],\n",
    "    #   [\"actualite dans le monde anglophone\"]\n",
    "    ],\n",
    "        \"directeur_memoire_de\" : [None,[\"Florian PHILIPPE\"], None, [\"Patricia AUGUSTYN\", \"Marie DELPORTE-LANDAT\", \"Florian PHILIPPE\"], [\"Ioana-Madalina SILAI\", \"Maria Paz BOTERO\"], None, None, None, [\"Lise BRISSET\"], None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n",
    "        \n",
    "}\n",
    "\n",
    "# print(len(prof[\"nom_prof\"]), len(prof[\"prenom_prof\"]), len(prof[\"etablissement\"]), len(prof[\"genre\"]), len(prof[\"cours\"]), len(prof[\"directeur_memoire_de\"]))\n",
    "\n",
    "df_prof = pd.DataFrame(dico_prof)\n",
    "df_prof.to_csv(\"df_prof.csv\", index=False)\n",
    "# for cle, value in prof.items():\n",
    "#     print(len(value))\n",
    "\n",
    "# for (i, a), (j, b) in zip(enumerate(prof['prenom_prof']), enumerate(prof['genre'])):\n",
    "#     print(f\"{i, a}, {j, b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Création de la dataframe cours\n",
    "\n",
    "- id_cours\n",
    "- nom_cours\n",
    "- id_prof\n",
    "- nom_prof\n",
    "- prenom_prof\n",
    "- etablissement\n",
    "- annee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On normalise les colonnes cours en enlevant les virgules, en mettant tout en majuscule et en enlevant les accentS.\n",
    "On fait en sorte que les cours de la dataframe cours soient identiques à ceux présents dans la dataframe profs.\n",
    "Pour obtenir les professeurs qui enseignent chaque cours on va faire en sorte de modifier les colonnes \"cours\" du formulaire pour qu'elles disposent des cours avec les mêmes noms que dans la dataframe prof et qu'on puisse donc obtenir des correspondances automatiquement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalisation_m1_s1(list_courses):\n",
    "\n",
    "    ### On sépare les cours, on enlève les diacritiques et on met tout en minuscule\n",
    "    list_courses = list_courses.split(\", \")\n",
    "    list_courses = [unidecode(course.strip().lower()) for course in list_courses]\n",
    "    \n",
    "    ### On renomme ou on uniformise les cours pour une meilleure correspondance\n",
    "    dico_correspondance = {\n",
    "        \"ppe 1\" : \"ppe1\",\n",
    "        \"langages regulieres\" : \"langages reguliers\",\n",
    "        \"Langages reguliers\" : \"langages reguliers\",\n",
    "        \"gest. info multilinguisme (gim)\" : \"gest. info multilinguisme\",\n",
    "        \"programmation et algorithmique 1 (python nanterre)\" : \"programmation et algorithmique 1\",\n",
    "        \"modalisation automatique pour l'analyse de textes\" : \"modelisation automatique pour l'analyse de textes\",\n",
    "        \"programmation objet\" : \"programmation objet 1\",\n",
    "        \"pratiques textuelles\" : \"pratiques textuelles et traduction\",\n",
    "        \"langues vivantes\" : \"langues vivantes etrangeres\",\n",
    "        \"base de donnees pour linguistes\" : \"bases de donnees pour linguistes\", \n",
    "        \"langages de scripts (python inalco)\" : \"langages de script (python inalco)\",\n",
    "    }\n",
    "\n",
    "    cleaned_courses = []\n",
    "    for course in list_courses:\n",
    "        if course != \"linguistique au choix\" and course != \"principes de bases de données\":\n",
    "            if course in dico_correspondance.keys():\n",
    "                cleaned_courses.append(dico_correspondance[course])\n",
    "            else:\n",
    "                cleaned_courses.append(course)\n",
    "\n",
    "    # print(cleaned_courses)\n",
    "\n",
    "    return cleaned_courses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On crée de nouvelles colonnes qui contiennent les cours normalisés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### POUR LES COURS OBLIGATOIRES DU M1 S1\n",
    "df_formulaire[\"normalised_m1_s1_courses\"] = df_formulaire[\"Quels cours avez-vous suivis au premier semestre du M1 ?\"].apply(normalisation_m1_s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalisation_m1_s1_optional(list_courses):\n",
    "\n",
    "    if pd.isna(list_courses):\n",
    "        # print(\"[]\")\n",
    "        return []\n",
    "    list_courses = list_courses.split(\", \")\n",
    "    list_courses = [unidecode(course.strip().lower()) for course in list_courses]\n",
    "    \n",
    "    dico_correspondance = {\n",
    "        \"recueil de donnees et statistiques (nanterre)\" : \"recueil de donnees et statistiques\",\n",
    "        \"lexique et morphologie (inalco)\" : \"lexique et morphologie\",\n",
    "        \"nlp in english\" : \"langues vivantes etrangeres\",\n",
    "    }\n",
    "\n",
    "    cleaned_courses = []\n",
    "    for course in list_courses:\n",
    "        if course in dico_correspondance.keys():\n",
    "            cleaned_courses.append(dico_correspondance[course])\n",
    "        else:\n",
    "            cleaned_courses.append(course)\n",
    "\n",
    "    # print(cleaned_courses)\n",
    "    return cleaned_courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_formulaire[\"normalised_m1_s1_optionnal\"] = df_formulaire[\"Quelles ont été vos options de linguistique au premier semestre du M1 ?\\nSéparer les cours par des virgules. \"].apply(normalisation_m1_s1_optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalisation_m1_s1_extra(list_courses):\n",
    "\n",
    "    if pd.isna(list_courses):\n",
    "        # print(\"[]\")\n",
    "        return []\n",
    "    list_courses = list_courses.split(\", \")\n",
    "    list_courses = [unidecode(course.strip().lower()) for course in list_courses]\n",
    "    \n",
    "    dico_correspondance = {\n",
    "        \"recueil de donnees et statistiques (nanterre)\" : \"recueil de données et statistiques\",\n",
    "        \"lexique et morphologie (inalco)\" : \"lexique et morphologie\"\n",
    "    }\n",
    "\n",
    "    cleaned_courses = []\n",
    "    for course in list_courses:\n",
    "        if course in dico_correspondance.keys():\n",
    "            cleaned_courses.append(dico_correspondance[course])\n",
    "        else:\n",
    "            cleaned_courses.append(course)\n",
    "            \n",
    "    # print(cleaned_courses)\n",
    "    return cleaned_courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_formulaire[\"normalised_m1_s1_extra\"] = df_formulaire[\"Avons-nous oublié quelque cours au premier semestre du M1 ? Indiquez-le ici !\\nSéparez les cours par des virgules. \"].apply(normalisation_m1_s1_extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalisation_m1_s2(list_courses):\n",
    "\n",
    "    list_courses = list_courses.split(\", \")\n",
    "    list_courses = [unidecode(course.strip().lower()) for course in list_courses]\n",
    "\n",
    "    dico_correspondance = {\n",
    "        \"anglais de specialite\" : \"anglais de specialite 2\",\n",
    "        \"programmation objet\" : \"programmation objet 2\",\n",
    "        \"outil de traitement de corpus\" : \"outils de traitement de corpus\"\n",
    "    }\n",
    "\n",
    "    cleaned_courses = []\n",
    "    for course in list_courses:\n",
    "        if course in dico_correspondance.keys():\n",
    "            cleaned_courses.append(dico_correspondance[course])\n",
    "        else:\n",
    "            cleaned_courses.append(course)\n",
    "            \n",
    "    # print(cleaned_courses)\n",
    "    return cleaned_courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_formulaire[\"normalised_m1_s2_courses\"] = df_formulaire[\"Quels cours avez-vous suivis au second semestre du M1 ?\"].apply(normalisation_m1_s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalisation_m1_s2_extra(list_courses):\n",
    "\n",
    "    if pd.isna(list_courses):\n",
    "        # print(\"[]\")\n",
    "        return []\n",
    "    list_courses = list_courses.split(\", \")\n",
    "    list_courses = [unidecode(course.strip().lower()) for course in list_courses]\n",
    "\n",
    "    # print(list_courses)\n",
    "    return list_courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_formulaire[\"normalised_m1_s2_extra\"] = df_formulaire[\"Avons-nous oublié quelque cours au second semestre du M1 ? Indiquez-le ici !\\nSéparez les cours par des virgules. \"].apply(normalisation_m1_s2_extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalisation_m2_s1(list_courses):\n",
    "    \n",
    "    list_courses = list_courses.split(\", \")\n",
    "    list_courses = [unidecode(course.strip().lower()) for course in list_courses]\n",
    "\n",
    "    dico_correspondance = {\n",
    "        \"annotation semantiques et applications en recherche d'information (nanterre)\" : \"annotations semantiques et applications en recherche d'information\",\n",
    "        \"ingenierie de connaissances(nanterre)\" : \"ingenierie des connaissances\", \n",
    "        \"de la modelisation au traitement automatique des donnees linguistiques (nanterre)\" : \"de la modelisation au traitement automatique des donnees linguistiques\",\n",
    "        \"seminaire: tal et linguistique de corpus (nanterre)\" : \"seminaire: tal et linguistique de corpus\",\n",
    "        \"apprentissage automatique (nanterre)\" : \"apprentissage automatique\",\n",
    "        \"arbres graphes (nanterre)\" : \"arbres graphes\",\n",
    "        \"interfaces pour le web (nanterre)\" : \"interfaces pour le web\",\n",
    "        \"modelisation des langues (nanterre)\" : \"modelisation des langues\",\n",
    "        \"langages du web semantique (nanterre)\" : \"langages du web semantique\",\n",
    "        \"linguistique outille et traitements statistiques (nanterre)\" : \"linguistique outillee et traitements statistiques\",\n",
    "        \"gestion de projets (nanterre)\" : \"gestion de projets\",\n",
    "        \"traitement automatique de corpus (inalco)\" : \"traitement statistique de corpus\",\n",
    "        \"genres textes et usages (inalco)\" : \"genres textes et usages\",\n",
    "        \"semantique des textes multilingues 1 (inalco)\" : \"semantique des textes multilingues 1\",\n",
    "        \"lexicologie terminologie et dictionnairique (inalco)\" : \"lexicologie terminologie et dictionnairique\",\n",
    "        \"acquisition modelisation/representation (inalco)\" : \"acquisition modelisation/representation\",\n",
    "        \"langages de script (inalco) (avec m.jourdain louis)\" : \"langages de script (jourdain)\",\n",
    "        \"langages de script (inalco) (avec m. roulois alexandre)\" : \"langages de script (roulois)\",\n",
    "        \"documents structures (inalco)\" : \"documents structures\",\n",
    "        \"cnn (sorbonne nouvelle)\" : \"cnn\",\n",
    "        \"calculabilite (inalco)\" : \"calculabilite\",\n",
    "        \"methodologie de la recherche (nanterre)\" : \"methodologie de la recherche\",\n",
    "        \"conduite de projet de traduction (inalco)\" : \"conduite de projet de traduction 1\",\n",
    "        \"programmation objet 1 (inalco)\" : \"programmation orientee objet 1\",\n",
    "        \"semantique computationnelle (sorbonne nouvelle)\" : \"semantique computationnelle\",\n",
    "        \"anglais (pro) (nanterre)\" : \"anglais pro\",\n",
    "        \"outils de tao 1 (inalco)\" : \"outils de tao 1\",\n",
    "        \"traductologie 1 (inalco)\" : \"traductologie 1\",\n",
    "        \"ecriture et multilinguisme (inalco)\" : \"ecriture et multilinguisme\",\n",
    "        'traduction technique 1 (inalco)': 'traduction technique 1',\n",
    "    }\n",
    "\n",
    "    cleaned_courses = []\n",
    "    for course in list_courses:\n",
    "        if course in dico_correspondance.keys():\n",
    "            cleaned_courses.append(dico_correspondance[course])\n",
    "        else:\n",
    "            cleaned_courses.append(course)\n",
    "\n",
    "    # print(cleaned_courses)\n",
    "    return cleaned_courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_formulaire[\"normalised_m2_s1_courses\"] = df_formulaire['Quels cours avez-vous suivis au premier semestre du M2 ?'].apply(normalisation_m2_s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalisation_m2_s1_extra(list_courses):\n",
    "\n",
    "    if pd.isna(list_courses):\n",
    "        # print(\"[]\")\n",
    "        return []\n",
    "    \n",
    "    list_courses = list_courses.split(\", \")\n",
    "    list_courses = [unidecode(course.strip().lower()) for course in list_courses]\n",
    "\n",
    "    dico_correspondance = {\n",
    "        \"traitement statistique de corpus (inalco)\" : \"traitement statistique de corpus\",\n",
    "        \"actualite dans le monde anglophone (anglais sorbonne nouvelle )\" : \"actualite dans le monde anglophone\",\n",
    "        \"fouille de textes (inalco)\" : \"fouille de textes 1\"\n",
    "    }\n",
    "\n",
    "    cleaned_courses = []\n",
    "    for course in list_courses:\n",
    "        if course != \"choix de linguistique\" and course != \"langue vivante\":\n",
    "            if course in dico_correspondance.keys():\n",
    "                cleaned_courses.append(dico_correspondance[course])\n",
    "            else:\n",
    "                cleaned_courses.append(course)\n",
    "\n",
    "    # print(cleaned_courses)\n",
    "    return cleaned_courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_formulaire[\"normalised_m2_s1_extra\"] = df_formulaire[\"Avons-nous oublié quelque cours au premier semestre du M2 ? Indiquez-le ici !\\nSéparez les cours par des virgules. \"].apply(normalisation_m2_s1_extra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On enregistre le formulaire avec de nouvelles colonnes dans un csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_formulaire.to_csv(\"formulaire_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut ensuite créer la dataframe cours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===== Initialisation du dictionnaire des cours =====#\n",
    "dico_cours = {\"nom_cours\": [],\n",
    "         \"id_prof\": [],\n",
    "         \"nom_prof\" : [],\n",
    "         \"prenom_prof\" : [],\n",
    "         \"etablissement\": [],\n",
    "         \"annee\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### En dessous c'est pour obtenir une liste des cours (unique) à partir de nos nouvelles colonnes normalisées !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===== Remplissage du dictionnaire des cours =====#\n",
    "\n",
    "courses_m1_s1 = df_formulaire[\"normalised_m1_s1_courses\"].to_list()\n",
    "courses_m1_s2 = df_formulaire[\"normalised_m1_s2_courses\"].to_list()\n",
    "courses_m2_s1 = df_formulaire[\"normalised_m2_s1_courses\"].to_list()\n",
    "\n",
    "mandatory_courses = courses_m1_s1 + courses_m1_s2 + courses_m2_s1\n",
    "mandatory_courses = [value for sublist in mandatory_courses for value in sublist]\n",
    "mandatory_courses = list(set(mandatory_courses))\n",
    "\n",
    "optional_courses_m1_s1 = df_formulaire[\"normalised_m1_s1_optionnal\"].dropna().to_list()\n",
    "optional_courses_m1_s1 = optional_courses_m1_s1 + df_formulaire[\"normalised_m1_s1_extra\"].dropna().to_list()\n",
    "optional_courses_m1_s2 = df_formulaire[\"normalised_m1_s2_extra\"].dropna().to_list()\n",
    "optional_courses_m2_s1 = df_formulaire[\"normalised_m2_s1_extra\"].dropna().to_list()\n",
    "optional_courses = optional_courses_m1_s1 + optional_courses_m1_s2 + optional_courses_m2_s1\n",
    "optional_courses = [value for sublist in optional_courses for value in sublist]\n",
    "optional_courses = list(set(optional_courses))\n",
    "\n",
    "cours = mandatory_courses + optional_courses\n",
    "cours = list(set(cours))\n",
    "\n",
    "if \"statistiques\" in cours:\n",
    "    cours.remove(\"statistiques\")\n",
    "dico_cours[\"nom_cours\"] = sorted(cours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dans le code en dessous en fait correspondre chaque cours à un professeur/à des professeurs pour qu'on ait la liste des profs qui enseignent chaque cours dans la df cours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for course in dico_cours[\"nom_cours\"]:\n",
    "    profs_noms = dico_prof[\"nom_prof\"]\n",
    "    profs_prenoms = dico_prof[\"prenom_prof\"]\n",
    "    courses = dico_prof[\"cours\"]\n",
    "    found = False\n",
    "    # print(\"On cherche le cours\", course)\n",
    "\n",
    "    for prof_nom, prof_prenom, subcourses in zip(profs_noms, profs_prenoms, courses):\n",
    "        # print(\"on cherche le cours\", course, \"dans la liste de cours :\")\n",
    "        subcourses = [subcourse.lower() for subcourse in subcourses]\n",
    "        # print(subcourses)\n",
    "        # print(\"qui est rattachée à:\")\n",
    "        # print(prof_nom, prof_nom)\n",
    "        if course in subcourses:\n",
    "            if found == True:\n",
    "                # print(f\"le cours {course} a été trouvé et on a déjà un prof\")\n",
    "                # print(\"donc, found est égal à \", found)\n",
    "                first_prof_nom = dico_cours[\"nom_prof\"][-1]\n",
    "                first_prof_prenom = dico_cours[\"prenom_prof\"][-1]\n",
    "                first_id_prof = dico_cours[\"id_prof\"][-1]\n",
    "                dico_cours[\"nom_prof\"].pop()\n",
    "                dico_cours[\"prenom_prof\"].pop()\n",
    "                dico_cours[\"id_prof\"].pop()\n",
    "\n",
    "                dico_cours[\"nom_prof\"].append([first_prof_nom, prof_nom])\n",
    "                dico_cours[\"prenom_prof\"].append([first_prof_prenom, prof_prenom])\n",
    "                dico_cours[\"id_prof\"].append([f\"{first_prof_prenom}_{first_prof_nom}\", f\"{prof_prenom}_{prof_nom}\"])\n",
    "            else:\n",
    "                found = True\n",
    "                dico_cours[\"nom_prof\"].append(prof_nom)\n",
    "                dico_cours[\"prenom_prof\"].append(prof_prenom)\n",
    "                dico_cours[\"id_prof\"].append(f\"{prof_prenom}_{prof_nom}\")\n",
    "\n",
    "            # for key, value in dico_cours.items():\n",
    "            #     print(key, value)\n",
    "    \n",
    "    if found == False:\n",
    "        dico_cours[\"nom_prof\"].append(\"\")\n",
    "        dico_cours[\"prenom_prof\"].append(\"\")\n",
    "        dico_cours[\"id_prof\"].append(\"\")\n",
    "    #     dico_cours[\"professeur\"].append(df_prof[\"nom_prof\"][df_prof[\"cours\"].index(course)])\n",
    "    # else:\n",
    "    #     dico_cours[\"professeur\"].append(\"Non défini\")\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acquisition modelisation/representation AOUINA Ons Ons_AOUINA\n",
      "actualite dans le monde anglophone   \n",
      "anglais de specialite 2 KOSMALA Loulou Loulou_KOSMALA\n",
      "anglais pro HUP Christophe Christophe_HUP\n",
      "annotations semantiques et applications en recherche d'information BATTISTELLI Delphine Delphine_BATTISTELLI\n",
      "apprentissage automatique GROBOL Loïc Loïc_GROBOL\n",
      "arbres graphes GROBOL Loïc Loïc_GROBOL\n",
      "bases de donnees pour linguistes ESHKOL-TARAVELLA Iris Iris_ESHKOL-TARAVELLA\n",
      "calculabilite PAROUBECK Patrick Patrick_PAROUBECK\n",
      "changements linguistiques ['LEHMANN', 'PICCOLI'] ['Sabine', 'Vanessa'] ['Sabine_LEHMANN', 'Vanessa_PICCOLI']\n",
      "cnn GENDROT Cedric Cedric_GENDROT\n",
      "conduite de projet de traduction 1 GAUMET Sophie Sophie_GAUMET\n",
      "coreen LEE Kyung Kyung_LEE\n",
      "corpus arbores et parsing HERRERA Santiago Santiago_HERRERA\n",
      "corpus paralleles et comparables ZWEIGENBAUM Pierre Pierre_ZWEIGENBAUM\n",
      "de la modelisation au traitement automatique des donnees linguistiques ESHKOL-TARAVELLA Iris Iris_ESHKOL-TARAVELLA\n",
      "document structure JACOBSON Michel Michel_JACOBSON\n",
      "documents structures ABROUGUI Rim Rim_ABROUGUI\n",
      "ecriture et multilinguisme WANG Ilaine Ilaine_WANG\n",
      "enrichissement de corpus ESHKOL-TARAVELLA Iris Iris_ESHKOL-TARAVELLA\n",
      "extraction d'informations MONNIN-TUILLIER Chloé Chloé_MONNIN-TUILLIER\n",
      "fouille de textes 1 GROUIN Cyril Cyril_GROUIN\n",
      "genres textes et usages VALETTE Mathieu Mathieu_VALETTE\n",
      "gest. info multilinguisme WANG Ilaine Ilaine_WANG\n",
      "gestion de projets CARCENAC Benoît Benoît_CARCENAC\n",
      "ingenierie des connaissances ['BATTISTELLI', 'ESHKOL-TARAVELLA'] ['Delphine', 'Iris'] ['Delphine_BATTISTELLI', 'Iris_ESHKOL-TARAVELLA']\n",
      "interfaces pour le web GROBOL Loïc Loïc_GROBOL\n",
      "introduction a la fouille de textes DUPONT Yoann Yoann_DUPONT\n",
      "khmer NUT Suppya Suppya_NUT\n",
      "langages de script (jourdain) JOURDAIN Louis Louis_JOURDAIN\n",
      "langages de script (python inalco) ROULOIS Alexandre Alexandre_ROULOIS\n",
      "langages de script (roulois) ROULOIS Alexandre Alexandre_ROULOIS\n",
      "langages du web semantique ESHKOL-TARAVELLA Iris Iris_ESHKOL-TARAVELLA\n",
      "langages reguliers NOUVEL Damien Damien_NOUVEL\n",
      "langue des signes AKSEN Hatice Hatice_AKSEN\n",
      "langues vivantes etrangeres STRICKER Armand Armand_STRICKER\n",
      "large corpus linguistics RAINERIE Sophie Sophie_RAINERIE\n",
      "lexicologie terminologie et dictionnairique   \n",
      "lexique et morphologie GABOR Kata Kata_GABOR\n",
      "linguistique de la lsf BOGLIOTTI Caroline Caroline_BOGLIOTTI\n",
      "linguistique outillee et traitements statistiques BATTISTELLI Delphine Delphine_BATTISTELLI\n",
      "mathematiques pour le tal GROBOL Loïc Loïc_GROBOL\n",
      "methodologie de la recherche CORI Marcel Marcel_CORI\n",
      "modelisation automatique pour l'analyse de textes BATTISTELLI Delphine Delphine_BATTISTELLI\n",
      "modelisation des langues KAHANE Sylvain Sylvain_KAHANE\n",
      "mooc   \n",
      "morphologie VILLEOING Florence Florence_VILLEOING\n",
      "nlp in english STRICKER Armand Armand_STRICKER\n",
      "outils de tao 1 KUBIK Karolina Karolina_KUBIK\n",
      "outils de traitement de corpus SAUVAGE Eve Eve_SAUVAGE\n",
      "phonetique physiologique et acoustique GENDROT Cedric Cedric_GENDROT\n",
      "polonais LASON Natalia Natalia_LASON\n",
      "ppe1 ['DUPONT', 'MAGISTRY'] ['Yoann', 'Pierre'] ['Yoann_DUPONT', 'Pierre_MAGISTRY']\n",
      "ppe2 ['DUPONT', 'MAGISTRY'] ['Yoann', 'Pierre'] ['Yoann_DUPONT', 'Pierre_MAGISTRY']\n",
      "pratiques textuelles et traduction LICHAO Zhu Zhu_LICHAO\n",
      "principes de bases de donnees   \n",
      "programmation et algorithmique 1 ESHKOL-TARAVELLA Iris Iris_ESHKOL-TARAVELLA\n",
      "programmation et algorithmique 2 DEHOUCK Mathieu Mathieu_DEHOUCK\n",
      "programmation objet 1 JACQUEMARD Florent Florent_JACQUEMARD\n",
      "programmation objet 2 JACQUEMARD Florent Florent_JACQUEMARD\n",
      "programmation orientee objet 1 LECAILLIEZ Louis Louis_LECAILLIEZ\n",
      "recueil de donnees et statistiques WANG Xibin Xibin_WANG\n",
      "redaction professionnelle   \n",
      "semantique computationnelle AMSILI Pascal Pascal_AMSILI\n",
      "semantique des textes multilingues 1 VALETTE Mathieu Mathieu_VALETTE\n",
      "semantique lexicale et textuelle VALETTE Mathieu Mathieu_VALETTE\n",
      "seminaire: tal et linguistique de corpus ESHKOL-TARAVELLA Iris Iris_ESHKOL-TARAVELLA\n",
      "sens multiple   \n",
      "sociolinguistique COSTA James James_COSTA\n",
      "statistiques textuelles NOUVEL Damien Damien_NOUVEL\n",
      "synthese de la parole GENDROT Cedric Cedric_GENDROT\n",
      "traduction automatique et assistee SEMMAR Nasredine Nasredine_SEMMAR\n",
      "traduction technique 1 BONNAFOUS Marie-Paule Marie-Paule_BONNAFOUS\n",
      "traductologie 1 LICHAO Zhu Zhu_LICHAO\n",
      "traitement statistique de corpus NOUVEL Damien Damien_NOUVEL\n"
     ]
    }
   ],
   "source": [
    "cours = dico_cours[\"nom_cours\"]\n",
    "profs_noms = dico_cours[\"nom_prof\"]\n",
    "profs_prenoms = dico_cours[\"prenom_prof\"]\n",
    "id_profs = dico_cours[\"id_prof\"]\n",
    "\n",
    "for cour, nom, prenom, id_p in zip(cours, profs_noms, profs_prenoms, id_profs):\n",
    "    print(cour, nom, prenom, id_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On ajoute ensuite les années et les établissements pour chaque cours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_cours[\"annee\"] = [\"2024-2025\", \"2024-2025\", \"2023-2024\", \"2024-2025\", \"2024-2025\", \"2024-2025\", \"2024-2025\", \"2023-2024\", \"2024-2025\", \"2023-2024\", \"2024-2025\", \"2024-2025\", \"2023-2024\", \"2023-2024\", \"2023-2024\", \"2024-2025\", \"2023-2024\", \"2024-2025\", \"2024-2025\", \"2023-2024\", \"2023-2024\", \"2024-2025\", \"2024-2025\", \"2023-2024\", \"2024-2025\", \"2024-2025\", \"2024-2025\", \"2023-2024\", \"2023-2024\", \"2024-2025\", \"2023-2024\", \"2024-2025\", \"2024-2025\", \"2023-2024\", \"2024-2025\", \"2023-2024\", \"2023-2024\", \"2024-2025\", \"2023-2024\", \"2023-2024\", \"2024-2025\", \"2023-2024\", \"2024-2025\", \"2023-2024\", \"2024-2025\", \"2023-2024\", \"2023-2024\", \"2023-2024\", \"2024-2025\", \"2023-2024\", \"2023-2024\", \"2023-2024\", \"2023-2024\", \"2023-2024\", \"2023-2024\", \"2023-2024\", \"2023-2024\", \"2023-2024\", \"2023-2024\", \"2023-2024\", \"2024-2025\", \"2023-2024\", \"2023-2024\", \"2024-2025\", \"2024-2025\", \"2023-2024\", \"2024-2025\", \"2023-2024\", \"2023-2024\", \"2023-2024\", \"2023-2024\", \"2023-2024\", \"2024-2025\", \"2024-2025\", \"2024-2025\"]\n",
    "dico_cours[\"etablissement\"] = [\"Inalco\", \"SorbonneNouvelle\", \"Nanterre\", \"Nanterre\", \"Nanterre\", \"Nanterre\", \"Nanterre\", \"Nanterre\", \"Inalco\", \"Nanterre\", \"SorbonneNouvelle\", \"Inalco\", \"Inalco\", \"Nanterre\", \"Inalco\", \"Nanterre\", \"SorbonneNouvelle\", \"Inalco\", \"Inalco\", \"Nanterre\", \"Inalco\", \"Inalco\", \"Inalco\", \"Inalco\", \"Nanterre\", \"Nanterre\", \"Nanterre\", \"SorbonneNouvelle\", \"Inalco\", \"Inalco\", \"Inalco\", \"Inalco\", \"Nanterre\", \"Inalco\", \"Nanterre\", \"Inalco\", \"Nanterre\", \"Inalco\", \"Inalco\", \"Inalco\", \"Nanterre\", \"Nanterre\", \"Nanterre\", \"Nanterre\", \"Nanterre\", \"Nanterre\", \"Inalco\", \"Nanterre\", \"Inalco\", \"Inalco\", \"Inalco\", \"SorbonneNouvelle\", \"Inalco\", \"SorbonneNouvelle\", \"SorbonneNouvelle\", \"Inalco\", \"Inalco\", \"Nanterre\", \"SorbonneNouvelle\", \"Inalco\", \"Inalco\", \"Inalco\", \"Nanterre\", \"SorbonneNouvelle\", \"Inalco\", \"Inalco\", \"Nanterre\", \"SorbonneNouvelle\", \"SorbonneNouvelle\", \"Inalco\", \"Inalco\", \"Inalco\", \"Inalco\", \"Inalco\", \"Inalco\"]\n",
    "\n",
    "# print(len(dico_cours[\"annee\"]), len(dico_cours[\"nom_cours\"]), len(dico_cours[\"nom_prof\"]), len(dico_cours[\"prenom_prof\"]), len(dico_cours[\"id_prof\"]), len(dico_cours[\"etablissement\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On ajoute ensuite une colonne id_cours composée du nom et de l'année de dispense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acquisition_modelisation_representation_2024_2025', 'actualite_dans_le_monde_anglophone_2024_2025', 'anglais_de_specialite_2_2023_2024', 'anglais_pro_2024_2025', 'annotations_semantiques_et_applications_en_recherche_d_information_2024_2025', 'apprentissage_automatique_2024_2025', 'arbres_graphes_2024_2025', 'bases_de_donnees_pour_linguistes_2023_2024', 'calculabilite_2024_2025', 'changements_linguistiques_2023_2024', 'cnn_2024_2025', 'conduite_de_projet_de_traduction_1_2024_2025', 'coreen_2023_2024', 'corpus_arbores_et_parsing_2023_2024', 'corpus_paralleles_et_comparables_2023_2024', 'de_la_modelisation_au_traitement_automatique_des_donnees_linguistiques_2024_2025', 'document_structure_2023_2024', 'documents_structures_2024_2025', 'ecriture_et_multilinguisme_2024_2025', 'enrichissement_de_corpus_2023_2024', 'extraction_d_informations_2023_2024', 'fouille_de_textes_1_2024_2025', 'genres_textes_et_usages_2024_2025', 'gest__info_multilinguisme_2023_2024', 'gestion_de_projets_2024_2025', 'ingenierie_des_connaissances_2024_2025', 'interfaces_pour_le_web_2024_2025', 'introduction_a_la_fouille_de_textes_2023_2024', 'khmer_2023_2024', 'langages_de_script_(jourdain)_2024_2025', 'langages_de_script_(python_inalco)_2023_2024', 'langages_de_script_(roulois)_2024_2025', 'langages_du_web_semantique_2024_2025', 'langages_reguliers_2023_2024', 'langue_des_signes_2024_2025', 'langues_vivantes_etrangeres_2023_2024', 'large_corpus_linguistics_2023_2024', 'lexicologie_terminologie_et_dictionnairique_2024_2025', 'lexique_et_morphologie_2023_2024', 'linguistique_de_la_lsf_2023_2024', 'linguistique_outillee_et_traitements_statistiques_2024_2025', 'mathematiques_pour_le_tal_2023_2024', 'methodologie_de_la_recherche_2024_2025', 'modelisation_automatique_pour_l_analyse_de_textes_2023_2024', 'modelisation_des_langues_2024_2025', 'mooc_2023_2024', 'morphologie_2023_2024', 'nlp_in_english_2023_2024', 'outils_de_tao_1_2024_2025', 'outils_de_traitement_de_corpus_2023_2024', 'phonetique_physiologique_et_acoustique_2023_2024', 'polonais_2023_2024', 'ppe1_2023_2024', 'ppe2_2023_2024', 'pratiques_textuelles_et_traduction_2023_2024', 'principes_de_bases_de_donnees_2023_2024', 'programmation_et_algorithmique_1_2023_2024', 'programmation_et_algorithmique_2_2023_2024', 'programmation_objet_1_2023_2024', 'programmation_objet_2_2023_2024', 'programmation_orientee_objet_1_2024_2025', 'recueil_de_donnees_et_statistiques_2023_2024', 'redaction_professionnelle_2023_2024', 'semantique_computationnelle_2024_2025', 'semantique_des_textes_multilingues_1_2024_2025', 'semantique_lexicale_et_textuelle_2023_2024', 'seminaire:_tal_et_linguistique_de_corpus_2024_2025', 'sens_multiple_2023_2024', 'sociolinguistique_2023_2024', 'statistiques_textuelles_2023_2024', 'synthese_de_la_parole_2023_2024', 'traduction_automatique_et_assistee_2023_2024', 'traduction_technique_1_2024_2025', 'traductologie_1_2024_2025', 'traitement_statistique_de_corpus_2024_2025']\n"
     ]
    }
   ],
   "source": [
    "noms_cours = dico_cours[\"nom_cours\"]\n",
    "annees_cours = dico_cours[\"annee\"]\n",
    "\n",
    "id_cours = []\n",
    "\n",
    "for nom, annee in zip(noms_cours, annees_cours):\n",
    "    nom_very_clean = nom.replace(\" \", \"_\").replace(\"'\", \"_\").replace(\"/\", \"_\").replace(\".\", \"_\")\n",
    "    annee_very_clean = annee.replace(\"-\", \"_\")\n",
    "    id_cours.append(f\"{nom_very_clean}_{annee_very_clean}\")\n",
    "\n",
    "\n",
    "dico_cours[\"id_cours\"] = id_cours\n",
    "print(dico_cours[\"id_cours\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, on enregistre la dataframe cours !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cours = pd.DataFrame(dico_cours)\n",
    "df_cours.to_csv(\"df_cours.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Création de la dataframe élèves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      id      prenom             nom  genre date_naissance  \\\n",
      "0          Pauline_DÉGEZ     Pauline           DÉGEZ  Femme     10/04/1988   \n",
      "1      Perrine_QUENNEHEN     Perrine       QUENNEHEN  Femme     14/02/1997   \n",
      "2          Ashley_RATIER      Ashley          RATIER  Femme     24/11/1998   \n",
      "3       Valentine_FLEITH  Valentine           FLEITH  Femme     06/07/2001   \n",
      "4  Débora_VAN_DEN_ZANDE       Débora  VAN-DEN-ZANDE   Femme     13/04/2002   \n",
      "\n",
      "  nationalite redoublement     inscription_M1  \\\n",
      "0          FR          non           Nanterre   \n",
      "1          FR          non             INALCO   \n",
      "2          FR          non           Nanterre   \n",
      "3          FR          non  Sorbonne-Nouvelle   \n",
      "4          FR          non  Sorbonne-Nouvelle   \n",
      "\n",
      "                       parcours_M2 tiers_temps  ... difficulte_RD  \\\n",
      "0            Alternance (Nanterre)         non  ...           NaN   \n",
      "1  Ingénierie Multilingue (INALCO)         non  ...           NaN   \n",
      "2            Alternance (Nanterre)         non  ...           NaN   \n",
      "3            Alternance (Nanterre)         non  ...           NaN   \n",
      "4            Alternance (Nanterre)         non  ...           NaN   \n",
      "\n",
      "  difficulte_tetradom                                  jeter_linux  \\\n",
      "0                 NaN                                    Ça arrive   \n",
      "1                 4.0                                          NaN   \n",
      "2                 NaN                                          NaN   \n",
      "3                 NaN  Non rien à dire moi et Linux on est besties   \n",
      "4                 NaN                                TOUT LE TEMPS   \n",
      "\n",
      "                                   jeter_mac admin_nanterre admin_sorbonne  \\\n",
      "0                                        NaN            4.0            NaN   \n",
      "1                                  Ça arrive            NaN            NaN   \n",
      "2  Non rien à dire moi et Mac on est besties            3.0            NaN   \n",
      "3                                        NaN            3.0            1.0   \n",
      "4                                        NaN            3.0            3.0   \n",
      "\n",
      "  admin_inalco                  conseil_eleve         recommandation  \\\n",
      "0          NaN  Buvez des cappucinos noisette                    NaN   \n",
      "1          4.0                            NaN                    NaN   \n",
      "2          NaN                            NaN  À VOTRE ENNEMI JURÉ !   \n",
      "3          4.0                  Ne venez pas             À personne.   \n",
      "4          NaN                   Ne pas venir            À personne.   \n",
      "\n",
      "                                        conseil_prof  \n",
      "0  Parlez vous pour vous coordonner (surtout quan...  \n",
      "1                                                NaN  \n",
      "2                                                NaN  \n",
      "3                                  Fermez le master   \n",
      "4                       EMBAUCHEZ DES GENS QUALIFIES  \n",
      "\n",
      "[5 rows x 41 columns]\n"
     ]
    }
   ],
   "source": [
    "df_eleves = pd.read_csv(\"dataframe_eleves.csv\")\n",
    "print(df_eleves.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eleves_avec_cours = pd.merge(df_eleves, df_formulaire[[\"Nom de famille\", \"normalised_m1_s1_courses\", \"normalised_m1_s1_optionnal\", \"normalised_m1_s1_extra\", \"normalised_m1_s2_courses\", \"normalised_m1_s2_extra\", \"normalised_m2_s1_courses\", \"normalised_m2_s1_extra\"]], left_on=\"nom\", right_on=\"Nom de famille\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eleves_avec_cours.to_csv(\"eleves_avec_cours.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
